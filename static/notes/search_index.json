[
["index.html", "Notes 笔记概述 笔记目录（已完成）", " Notes Miao YU 2017-01-12 笔记概述 这里的笔记主要来自于公开课笔记与相关教材的读书笔记，主题相对分散，但这些知识应该为当今科研人员的基本技能。 首先科研人员要有一定的数学与统计学功底，这是最最基本的工具学科。微积分、线性代数与数值方法是必须的数学工具，统计学工具则至少明白如何进行统计推断与预测。其余的要看应用，例如数论对密码学而言就是基础。 然后就是编程技能，编程方面首先要熟悉编程的思维方法，例如递归、迭代、条件语句等，也就是知道机器怎么运转。其次就是掌握一门高级语言，例如R、python或matlab，这样你可以快速实现自己的想法。 之后就是模型思维，懂得将实际问题抽象成一个概念问题或统计问题或仿真问题，用解析或数值方法去求解模型或模拟，回答实际问题。 最后是专业知识，各个学科都有自己的概念，有些是可以抽象相通的，有些则属于特有的，要能把其他学科知识整合到自己的理论体系里。 我看好的方向： 人类非常态全解析：从基因组-转录组-蛋白组-代谢组-暴露组-心理学-流行病学全流程分析某种病例或不正常状态，探讨机理与解决方案 复杂科学：探索显示复杂现象中的数理规律与工程应用，例如仿生、动力学跟信息论等 决策方法：探索个体间互动过程中的行为决策方法，这是个体面向社会的融入指南，入门学科是博弈论 笔记目录（已完成） 01 数据分析知识框架 02-10 数据科学系列课程 11 统计学习导论 12 基因组学数据分析 13 latex入门 14 生物信息学 15 流行病学 16 环境与健康 17 心理学 18 抑郁 19 贝叶斯统计 20 生存分析 21 数据科学与python简介 22 因果分析 23 系统思考 24 博弈论 25 复杂系统 "],
["section-1.html", "笔记 1 简明数据分析知识框架 1.1 概率与分布 1.2 统计量 1.3 统计推断 1.4 线性模型 1.5 其他主题 1.6 应用", " 笔记 1 简明数据分析知识框架 1.1 概率与分布 从可能性到独立事件概率计算 从联合概率到条件概率到贝叶斯公式 事件的发生空间到分布 多事件发生概率比较到标准化分布-z值 正态分布评价拟合 贝努利分布 二项分布，固定总数，成功概率，二项分布可用正态分布近似求值，也可用二项分布取精确值，求区间概率要扩大 负二项分布，固定成功次数概率 几何分布，最后一次成功概率 超几何分布，不放回抽样，成功概率 泊松分布，实验次数多，概率小，发生概率，泊松过程 1.2 统计量 总体到样本 多个事件的描述到众数 中位数 再到期望 描述多个事件的变动到方差 取样方法：随机，分层，分类 样本独立性:简单随机取样，样本数少于10%的总体可认为独立样本 估计的偏差为标准误 点估计到区间估计 标准误只针对样本均值，理解为样本均值的估计标准差 置信区间为对所有样本进行区间估计，95%的区间包含真值，是对总体参数的估计，近似认为样本符合某分布 中心极限法则：样本均值的分布为正态分布 1.3 统计推断 假设检验 不拒绝H0不代表H0是对的，拒绝H0代表HA可能正确，观察数值的区间重叠状况 使用双重否定进行描述 type I 假阳性 type II 假阴性 置信水平反映两种错误的可能性 p值描述某数值在H0（一般为等式）中出现的可能性，通常与置信水平对比，两边与单边 构建符合某分布的统计量进行参数估计，通过标准误计算p值，进行假设检验过程 功效表示HA拒绝H0的可能性，功效高，检验可靠 统计差异显著不代表实际差异显著，甚至没有实际意义 均值比较（连续） 配对数据 均值比较 t分布与自由度及小样本均值的标准误估计 置信区间与p值 样本均值的t检验 多组数据均值的方差分析与F检验 多重比较的假阳性问题 样本数足够可用统计模拟的方法进行检验，数据存在层级结构则不可直接模拟 比例比较（计数） 比例检验，计算基于H0的标准误，计算z值，计算p值，可反推样品量 比例差异检验，H0为比例相等，估计混合概率，计算标准误进行检验 记分检验与Wald检验 优度拟合 分布检验到卡方检验 独立性检验 精确检验 1.4 线性模型 变量关系到线性回归到线性诊断 参数估计到关系解释及误差分析 多元回归 模型选择 方差分析 非线性模型与平滑 logistic模型到广义线性模型 线性混合模型 主成分分析与因子分析 1.5 其他主题 非参数统计 贝叶斯统计 判别分析 岭回归与lasso 广义加性模型 鲁棒模型 决策树到随机森林 人工神经网络 支持向量机 蒙特卡洛分析到统计模拟 图论 1.6 应用 实验设计 模式识别 流行病学 生物信息学 化学信息学 心理学 空间数据分析 时间序列分析与信号处理 量化投资 "],
["section-2.html", "笔记 2 数据科学家工具箱 2.1 链接", " 笔记 2 数据科学家工具箱 CLT name of root is represented by a slash: / home directory is represented by a tilde: ~ pwd print working directory recipe: command -flags arguments clear: clear out the commands in your current CLI window ls lists files and folders in the current directory -a lists hidden and unhidden files and folders -al lists details for hidden and unhidden files and folders cd stands for “change directory” cd takes as an argument the directory you want to visit cd with no argument takes you to your home directory cd .. allows you to chnage directory to one level above your current directory mkdir stands for “make directory” touch creates an empty file cp stands for “copy” cp takes as its first argument a file, and as its second argument the path to where you want the file to be copied cp can also be used for copying the contents of directories, but you must use the -r flag rm stands for “remove” use rm to delete entire directories and their contents by using the -r flag mv stands for “move” move files between directories use mv to rename files echo will print whatever arguments you provide date will print today’s date git $ git config --global user.name &quot;Your Name Here&quot; # 输入用户名 $ git config --global user.email &quot;your_email@example.com&quot; # 输入邮箱 $ git config --list # 检查 $ git init # 初始化目录 $ git add . # 添加新文件 $ git add -u # 更新改名或删除的文件 $ git add -A|git add --all # 添加所有改动 $ git commit -m &quot;your message goes here&quot; # 描述并缓存本地工作区改动到上一次commit $ git log # 查看commit记录 用Q退出 $ git status # 查看状态 $ git remote add # 添加服务器端地址 $ git remote -v # 查看远端状态 $ git push # 将本地commit推送到github服务器端 $ git pull|fetch|merge|clone # 本地获取远端repo $ exit # 退出 Git = Local (on your computer); GitHub = Remote (on the web) 基本问题 描述分析：对数据进行描述但不解释 探索分析：寻找未知的变量间关系 （相关不代表因果） 推断分析：用小样本推断总体 统计模型的目标 强依赖采样过程 预测分析：用一组变量预测另一变量 不一定有因果关系 因果分析：改变一个变量引发另一个变量变化的分析 随机实验 平均效果 机理分析：对个体改变一个变量所导致另一个变量的精确变化 公式模拟与参数拟合 数据次于问题 大数据依赖科学而不是数据 实验设计 重视可重复性随机与分组 预测与推断不同 不要选数据 2.1 链接 统计问题 R问题 R mailling ist 数据分享 "],
["r.html", "笔记 3 R语言编程 3.1 R语言概述 3.2 获得帮助 3.3 数据类型及基本运算 3.4 环境／文件操作 3.5 截取数据 3.6 读取数据 3.7 控制结构 3.8 函数 3.9 编程标准 3.10 范围规则 3.11 向量化操作 3.12 日期与时间 3.13 循环 3.14 模拟 3.15 调试 3.16 分析代码", " 笔记 3 R语言编程 3.1 R语言概述 R语言是S语言的一种方言 1976年S是John Chambers等在贝尔实验室作为Fortran的扩展库开发出来的 1988年用C语言重写 S3方法 白皮书 1993年StatSci从贝尔实验室获得S语言的独家开发售卖许可 1998年S4方法 绿皮书 之后S语言稳定 获得Association for Computing Machinery’s Software System Award 2004年Insightful（原StatSci）从Lucent收购了S语言 2006年Alcatel收购了Lucent成立Alcatel-Lucent 2008年TIBCO收购Insightful 之前Insightful开发并售卖S-PLUS 1991年Ross Ihaka与Robert GentlemanNew在Zealand开发了R 1993年发布R第一份许可 1995年R作为自由软件发放GUN许可 1996年R邮件列表创立 1997年R Core成立 控制R源码 2000年R version 1.0.0 放出 2013年R version 3.0.2 放出 R由CRAN掌控的base包与其他包组成 其余参考R主页 3.2 获得帮助 help() ?command # 提问给出以下信息 version str(.Platform) 3.3 数据类型及基本运算 所有数据都是对象 所有对象都有类型 基本类型包括：字符“” 数字 整数L 复数(Re实部 Im虚部) 逻辑 向量储存同一类型数据 list存储不同类型数据 [[*]]引用相应向量 unlist 可用做紧凑输出 对象可以有属性attributes 对象赋值符号为 &lt;- 赋值同时展示加括号或直接输入对象名 可累加赋值 a &lt;- b &lt;- c #表示注释 不执行 : 用来产生整数序列 也可以用seq生成 向量用c产生 空向量用vector()函数建立 向量中类型不同的对象元素会被强制转换为同一类型 字符优先级最高 其次数字 其次逻辑(0 or 1) 也可以用来串联字符 可使用as.*来强制转化数据类型 对象可以用names命名 变量名开头不能是数字和. 大小写敏感 下划线不要出现在名字里 分割用. 变量名中不能有空格 保留字符 FALSE Inf NA NaN NULL TRUE break else for function if in next repeat while 清空rm(list = ls()) 矩阵 带有dimension属性的向量为矩阵 矩阵的生成次序为upper-left matrix(1:6,nrow=2,ncol=3)表示建一个2行3列矩阵 从1到6 先列后行赋值 可用 byrow = T 来更改 可用c给dim赋值行和列数 这样可把一个向量转为一个矩阵 m&lt;-1:6;dim(m)&lt;-c(2,3) 矩阵可以用rbind或cbind生成 t对矩阵转置 因子变量表示分类数据 用标签名区分 用level来命名排序 默认是字母排序 有些函数对顺序敏感可用 levels = c() 来命名 ( 例如低中高的排序 ) 数字表示 drop = T 表示显示截取数据的水平 nlevels给出个数 NaN表未定义或缺失值 NA表示无意义转换或缺失值 NaN可以是NA反之不可以 NA有数据类型 is.NaN与is.NA 可用来检验 数据框 特殊list 每个元素长度相等 每一列类型相同 矩阵所有数据类型相同 特殊属性row.names 转为矩阵data.matrix 变量名自动转化 可以不同 因子变量保持为字符可以用 I data.frame(x,y,I(c)) 数组 表示更高维度的数据 dim() = c(x,y,z) 三维数组表示一组数 dimnames 给数组命名 数组调用如果只有一行 需要drop = F 否则 不会按照数组分类 ts 产生时间序列对象 .Last.value 引用前一个数值 取整数 用round(x,n) n表示保留几位小数 截取整数 trunc 开平方 sqrt 绝对值 abs 指数函数 exp 自然对数函数 log 以 10 为底的对数函数 log10 三角函数 sin cos tan asin acos atan 常用的逻辑运算符有: 大于 &gt; 小于 &lt; 等于 == 小于或等于 &lt;= 大于或等于 &gt;= 与 &amp; 非 ! 或| 判断向量x中是否与y中元素相等 x %in% y 结果返回逻辑值 sum 求和 prod 求连乘 range 给极值范围 duplicated 给出有重复的值 unique 给出无重复的值 向量操作 union 并集 intersect 交集 setdiff 除了交集的部分 rep 用向量循环生成向量 x &lt;- 1:4 # puts c(1,2,3,4) into x i &lt;- rep(2, 4) # puts c(2,2,2,2) into i y &lt;- rep(x, 2) # puts c(1,2,3,4,1,2,3,4) into y z &lt;- rep(x, i) # puts c(1,1,2,2,3,3,4,4) into z w &lt;- rep(x, x) # puts c(1,2,2,3,3,3,4,4,4,4) into w 整型变量后面加上L x&lt;-10L Inf代表1/0 同样1/Inf运算结果为0 3.4 环境／文件操作 getwd() setwd() 设置工作目录 ls() 列举环境中bianliang list.files() 或 dir() 列举当前目录下文件 args() 列举函数默认变量 dir.create() 创建文件目录 加上recursive=T可创建多级目录 file.create() 创建文件 file.exists() 检查文件是否存在 file.info() 检查文件信息 file.rename() 文件重命名 file.copy() 文件复制 file.path() 文件路径 多个文件组成多级路径 unlink() 删除文件 3.5 截取数据 []截取数据 可以用[x,y]提取特定数值 [-1,-2]可剔除第一行第二列 [[]]用来从list或者frame里提取元素 类型固定 可提取序列x[[1]][[3]] 可部分匹配 exact=FALSE $用名字提取元素 可部分匹配 提取矩阵时默认只能提取向量 但可以提取1*1矩阵x[1,2,drop=FALSE] 先用is.NA()提取 用!排除 缺失值可用is.element(x,y)来处理很多表示NA值的数字 返回x %in% y的逻辑值 用complete.cases()提取有效数据用[]提取可用数据 head(x,n) n表示从头截取多少行 tail(x,n) n表示从尾截取多少行 subset(x,f) x表示数据 f表示表达式 条件筛选中获得一个变量多个数值的数据使用 [is.element(x,c(' ',' ',' ')),] 或者[x%in%c(' ',' ',' '),] 使用x == c( ' ' , ' ' , ' ' ) 会报错 循环查找三个变量 x!='t' 可能会把空白值输入 应该使用is.element(x,'t') ifelse(con,yes,no) 利用条件筛选 返回yes 或者no 的值 支持正则表达式 3.6 读取数据 read.table read.csv 读取表格 反之write.table readLines 读取文本行 反之writeLines source 读取R代码 反之dump dget 读取多个R代码 反之dput load 读取保存的工作区 反之save unserialize 读取二进制R对象 反之serialize ?read.table 大数据读取提速 计算内存 comment.char = &quot;&quot; 不扫描注释 设定nrows 设定colClasses initial &lt;- read.table(&quot;datatable.txt&quot;, nrows = 100) classes &lt;- sapply(initial, class) tabAll &lt;- read.table(&quot;datatable.txt&quot;, colClasses = classes) 使用connections与file等保存外部文件指向 3.7 控制结构 if else 条件 if(&lt;condition&gt;) { ## do something } else { ## do something else } if(&lt;condition1&gt;) { ## do something } else if(&lt;condition2&gt;) { ## do something different } else { ## do something different } `for‵ 执行固定次数的循环 嵌套不超过2层 for(i in 1:10) { print(i) } while 条件为真执行循环 条件从左到右执行 count &lt;- 0 while(count &lt; 10) { print(count) count &lt;- count + 1 } repeat 执行无限循环 配合break 中断并跳出循环 next 跳出当前循环继续执行 for(i in 1:100) { if(i &lt;= 20) { ## Skip the first 20 iterations next } ## Do something here } return 退出函数 避免使用无限循环 可用apply替代 3.8 函数 f &lt;- function(&lt;arguments&gt;) { ## Do something interesting } 函数中参数默认值可用formals()显示 参数匹配 先检查命名参数 然后检查部分匹配 最后检查位置匹配 定义函数时可以定义默认值或者设为NULL 懒惰执行：只执行需要执行的语句 ... 向其他函数传参 之后参数不可部分匹配 3.9 编程标准 使用文本文档与文本编辑器 使用缩进 限制代码行宽 80为宜 限制单个函数长度 3.10 范围规则 自由变量采用静态搜索 环境是由数值符号对组成 每个环境都有母环境 函数与环境组成环境闭包 首先从函数环境中寻找变量 之后搜索母环境 最高层为工作区 之后按搜寻列表从扩展包中寻找变量 最后为空环境 之后报错 可以函数内定义函数 S都存在工作区 函数定义一致 R存在内存 可根据需要调用函数环境 3.11 向量化操作 向量操作针对元素 矩阵操作也针对元素 %*% 表示矩阵操作 3.12 日期与时间 日期以data类型存储 时间以POSIXct 或 POSIXlt 类型存储 数字上是从1970-01-01以来的天数或秒数 POSIXct以整数存储时间 POSIXlt以年月日时分秒等信息存储时间 strptime as.Date as.POSIXlt as.POSIXct用来更改字符为时间 3.13 循环 3.13.1 lapply 对列表对象元素应用函数 可配合匿名函数使用 x &lt;- list(a = 1:5, b = rnorm(10)) lapply(x, mean) ## $a ## [1] 3 ## ## $b ## [1] 0.1914834 x &lt;- 1:4 lapply(x, runif, min = 0, max = 10) ## [[1]] ## [1] 8.261187 ## ## [[2]] ## [1] 8.133978 7.466983 ## ## [[3]] ## [1] 7.174344 9.534732 6.102234 ## ## [[4]] ## [1] 2.987294 8.140162 5.198192 6.746936 x &lt;- list(a = matrix(1:4, 2, 2), b = matrix(1:6, 3, 2)) lapply(x, function(elt) elt[,1]) ## $a ## [1] 1 2 ## ## $b ## [1] 1 2 3 3.13.2 sapply lapply的精简版 如果结果是单元素列表 转化为向量 如果结果是等长向量 转化为矩阵 否则输出依旧为列表 x &lt;- list(a = 1:4, b = rnorm(10), c = rnorm(20, 1), d = rnorm(100, 5)) sapply(x, mean) ## a b c d ## 2.5000000 0.5767039 1.0716042 5.0245747 3.13.3 vapply 类似lapply可用更复杂函数 返回矩阵 3.13.4 replicate 用于将函数循环使用 如返回随机矩阵 3.13.5 rapply 用how来调整输出方法 如选取某列表中类型数据进行迭代 3.13.6 apply 数组边际函数 常用于矩阵的行列处理 行为1，列为2 可用rowSums rowMeans colSums colMeans 来替代 大数据量更快 x &lt;- matrix(rnorm(50), 10, 5) apply(x, 1, quantile, probs = c(0.25, 0.75)) ## [,1] [,2] [,3] [,4] [,5] [,6] ## 25% -0.8986679 -1.1807803 -1.161744 -1.2167470 -0.8368479 -0.2167746 ## 75% -0.2221923 -0.8124451 1.009243 -0.3387738 1.5382441 0.1889342 ## [,7] [,8] [,9] [,10] ## 25% -0.7691945 -0.08020317 -0.8145935 -0.5898126 ## 75% 0.2362998 0.23274868 0.4391082 0.2688066 a &lt;- array(rnorm(2 * 2 * 10), c(2, 2, 10)) apply(a, c(1, 2), mean) ## [,1] [,2] ## [1,] -0.19875499 -0.58466161 ## [2,] -0.07304468 0.07321296 3.13.7 tapply 对数据子集（因子变量区分）向量应用函数 x &lt;- c(rnorm(10), runif(10), rnorm(10, 1)) f &lt;- gl(3, 10) tapply(x, f, mean) ## 1 2 3 ## 0.2253262 0.3480184 0.8073245 3.13.8 by 对数据按照因子变量应用函数 类似tapply 按照某个分类变量a分类求均值 by(x[,-a],a,mean) 3.13.9 split 将数据按因子分割为列表 常配合lapply使用 类似tapply 可用来生成分组 用drop来删除空分组 x &lt;- c(rnorm(10), runif(10), rnorm(10, 1)) f &lt;- gl(3, 10) lapply(split(x, f), mean) ## $`1` ## [1] -0.057905 ## ## $`2` ## [1] 0.7216394 ## ## $`3` ## [1] 0.6892158 x &lt;- rnorm(10) f1 &lt;- gl(2, 5) f2 &lt;- gl(5, 2) str(split(x, list(f1, f2), drop = TRUE)) ## List of 6 ## $ 1.1: num [1:2] 0.456 1.507 ## $ 1.2: num [1:2] -1.07 -0.61 ## $ 1.3: num -0.732 ## $ 2.3: num 0.722 ## $ 2.4: num [1:2] 1.17 -1.31 ## $ 2.5: num [1:2] 1.737 -0.841 3.13.10 mapply 多变量版apply 从多个参数范围取值 并用函数得到结果 noise &lt;- function(n, mean, sd) { rnorm(n, mean, sd) } mapply(noise, 1:5, 1:5, 2) ## [[1]] ## [1] 2.553377 ## ## [[2]] ## [1] 2.258300 -2.464258 ## ## [[3]] ## [1] 4.3520781 0.6556211 3.2402147 ## ## [[4]] ## [1] 5.070154 8.228491 2.731190 1.987956 ## ## [[5]] ## [1] 5.935563 3.656412 4.413114 2.268991 7.962731 #等同于如下循环 #list(noise(1, 1, 2), noise(2, 2, 2), # noise(3, 3, 2), noise(4, 4, 2), # noise(5, 5, 2)) 3.13.11 eapply 对环境变量应用函数 用于包 3.14 模拟 在某分布下产生随机数 d 分布概率密度 r 分布随机数 p 分布累计概率 q 分布分位数 dnorm(x, mean = 0, sd = 1, log = FALSE) pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) rnorm(n, mean = 0, sd = 1) set.seed保证重现性 sample对数据采样 3.15 调试 三种提示 message warning error 只有error致命 关注重现性 调试工具 traceback debug browser trace recover 三思而行 3.16 分析代码 先设计 后优化 system.time 计算代码运行时间 返回对象类型proc_time ‵user time` 执行代码用时 system time CPU时间 elapsed time 实际用时 在多核或并行条件下实际用时可以短于执行代码用时 明确知道耗时较长的函数时使用 Rprof R代码要支持分析函数 summaryRprof可使结果易读 不要与system.time混用 0.02s记录一次执行函数 by.total 记录单个函数用时 by.self 记录函数执行时被调用函数用时 "],
["section-4.html", "笔记 4 数据获取与整理 4.1 概述 4.2 下载 4.3 读取本地文件 4.4 读取excle文件 4.5 读取XML文件 4.6 读取json文件 4.7 读取MySQL数据库 4.8 读取HDF5数据 4.9 读取网页数据 4.10 读取API 4.11 读取其他资源 4.12 数据截取与排序 4.13 数据总结 4.14 数据整理 4.15 数据操作data.table包 4.16 文本处理 4.17 日期处理", " 笔记 4 数据获取与整理 4.1 概述 Raw data -&gt; Processing script -&gt; tidy data 前期需求 原始数据 干净数据 code book 详尽的处理步骤记录 原始数据要求 未经处理 未经修改 未经去除异常值 未经总结 干净数据 每个变量一列 同一变量不同样本不在一行 一种变量一个表 多张表要有一列可以相互链接 有表头 变量名要有意义 一个文件一张表 code book 变量信息 总结方式 实验设计 文本文件 包含研究设计与变量信息的章节 处理步骤记录 脚本文件 输入为原始数据 输出为处理过数据 脚本中无特定参数 4.2 下载 设定工作目录与数据存储目录 if (!file.exists(&quot;data&quot;)) { dir.create(&quot;data&quot;) } url下载与时间记录 fileUrl &lt;- &quot;yoururl&quot; download.file(fileUrl, destfile = &quot;./data/XXX.csv&quot;, method = &quot;curl&quot;) list.files(&quot;./data&quot;) dateDownloaded &lt;- date() 4.3 读取本地文件 read.table read.csv 默认sep=&quot;,&quot;, header=TRUE quote 设定引用 na.strings 设定缺失值字符 nrows 设定读取字段 skip 跳过开始行数 4.4 读取excle文件 xlsx包 library(xlsx) cameraData &lt;- read.xlsx(&quot;./data/cameras.xlsx&quot;,sheetIndex=1,header=TRUE) head(cameraData) # read.xlsx2更快不过选行读取时会不稳定 # 支持底层读取 如字体等 XLConnect包 library(XLConnect) wb &lt;- loadWorkbook(&quot;XLConnectExample1.xlsx&quot;, create = TRUE) createSheet(wb, name = &quot;chickSheet&quot;) writeWorksheet(wb, ChickWeight, sheet = &quot;chickSheet&quot;, startRow = 3, startCol = 4) saveWorkbook(wb) # 支持区域操作 生成报告 图片等 4.5 读取XML文件 网页常用格式 形式与内容分开 形式包括标签 元素 属性等 XML包 library(XML) fileUrl &lt;- &quot;http://www.w3schools.com/xml/simple.xml&quot; # 读取xml结构 doc &lt;- xmlTreeParse(fileUrl,useInternal=TRUE) # 提取节点 rootNode &lt;- xmlRoot(doc) # 提取根节点名 xmlName(rootNode) # 提取子节点名 names(rootNode) # 提取节点数值 xmlSApply(rootNode,xmlValue) XPath XML的一种查询语法 /node 顶级节点 //node 所有子节点 node(???) 带属性名的节点 node(??? =“bob”) 属性名为bob的节点 # 提取节点下属性名为name的数值 xpathSApply(rootNode,&quot;//name&quot;,xmlValue) 4.6 读取json文件 js对象符号 结构化 常作为API输出格式 jsonlite包 library(jsonlite) # 读取json文件 jsonData &lt;- fromJSON(&quot;https://api.github.com/users/jtleek/repos&quot;) # 列出文件名 names(jsonData) # 可嵌套截取 jsonData$owner$login # 可将R对象写成json文件 myjson &lt;- toJSON(iris, pretty=TRUE) 4.7 读取MySQL数据库 网络应用常见数据库软件 一行一记录 数据库表间有index向量 常见命令 指南 RMySQL包 library(RMySQL) # 读取数据库 ucscDb &lt;- dbConnect(MySQL(),user=&quot;genome&quot;, host=&quot;genome-mysql.cse.ucsc.edu&quot;) result &lt;- dbGetQuery(ucscDb,&quot;show databases;&quot;); # 断开链接 dbDisconnect(ucscDb); # 读取指定数据库 hg19 &lt;- dbConnect(MySQL(),user=&quot;genome&quot;, db=&quot;hg19&quot;, host=&quot;genome-mysql.cse.ucsc.edu&quot;) allTables &lt;- dbListTables(hg19) length(allTables) # mysql语句查询 dbGetQuery(hg19, &quot;select count(*) from affyU133Plus2&quot;) # 选择子集 query &lt;- dbSendQuery(hg19, &quot;select * from affyU133Plus2 where misMatches between 1 and 3&quot;) affyMis &lt;- fetch(query); quantile(affyMis$misMatches) 4.8 读取HDF5数据 分层分组读取大量数据的格式 rhdf5包 library(rhdf5) created = h5createFile(&quot;example.h5&quot;) created = h5createGroup(&quot;example.h5&quot;,&quot;foo&quot;) created = h5createGroup(&quot;example.h5&quot;,&quot;baa&quot;) created = h5createGroup(&quot;example.h5&quot;,&quot;foo/foobaa&quot;) h5ls(&quot;example.h5&quot;) A = matrix(1:10,nr=5,nc=2) h5write(A, &quot;example.h5&quot;,&quot;foo/A&quot;) B = array(seq(0.1,2.0,by=0.1),dim=c(5,2,2)) attr(B, &quot;scale&quot;) &lt;- &quot;liter&quot; h5write(B, &quot;example.h5&quot;,&quot;foo/foobaa/B&quot;) h5ls(&quot;example.h5&quot;) df = data.frame(1L:5L,seq(0,1,length.out=5), c(&quot;ab&quot;,&quot;cde&quot;,&quot;fghi&quot;,&quot;a&quot;,&quot;s&quot;), stringsAsFactors=FALSE) h5write(df, &quot;example.h5&quot;,&quot;df&quot;) h5ls(&quot;example.h5&quot;) readA = h5read(&quot;example.h5&quot;,&quot;foo/A&quot;) readB = h5read(&quot;example.h5&quot;,&quot;foo/foobaa/B&quot;) readdf= h5read(&quot;example.h5&quot;,&quot;df&quot;) 4.9 读取网页数据 网页抓取HTML数据 读完了一定关链接 httr包 con = url(&quot;http://scholar.google.com/citations?user=HI-I6C0AAAAJ&amp;hl=en&quot;) htmlCode = readLines(con) close(con) htmlCode library(XML) url &lt;- &quot;http://scholar.google.com/citations?user=HI-I6C0AAAAJ&amp;hl=en&quot; html &lt;- htmlTreeParse(url, useInternalNodes=T) xpathSApply(html, &quot;//title&quot;, xmlValue) library(httr) html2 = GET(url) content2 = content(html2,as=&quot;text&quot;) parsedHtml = htmlParse(content2,asText=TRUE) xpathSApply(parsedHtml, &quot;//title&quot;, xmlValue) GET(&quot;http://httpbin.org/basic-auth/user/passwd&quot;) GET(&quot;http://httpbin.org/basic-auth/user/passwd&quot;, authenticate(&quot;user&quot;,&quot;passwd&quot;)) google = handle(&quot;http://google.com&quot;) pg1 = GET(handle=google,path=&quot;/&quot;) pg2 = GET(handle=google,path=&quot;search&quot;) 4.10 读取API 通过接口授权后调用数据 httr包 myapp = oauth_app(&quot;twitter&quot;, key=&quot;yourConsumerKeyHere&quot;,secret=&quot;yourConsumerSecretHere&quot;) sig = sign_oauth1.0(myapp, token = &quot;yourTokenHere&quot;, token_secret = &quot;yourTokenSecretHere&quot;) homeTL = GET(&quot;https://api.twitter.com/1.1/statuses/home_timeline.json&quot;, sig) json1 = content(homeTL) json2 = jsonlite::fromJSON(toJSON(json1)) 4.11 读取其他资源 图片 jpeg readbitmap png EBImage (Bioconductor) GIS rdgal rgeos raster 声音 tuneR seewave 4.12 数据截取与排序 增加行直接$ seq产生序列 通过[按行 列或条件截取 which返回行号 排序向量用sort 排序数据框(多向量)用order plyl包排序 library(plyr) arrange(X,var1) arrange(X,desc(var1)) 4.13 数据总结 head tail查看数据 summary str总结数据 quantile 按分位数总结向量 table 按向量元素频数总结 sum(is.na(data)) any(is.na(data)) all(data$x &gt; 0) 异常值总结 colSums(is.na(data)) 行列求和 table(data$x %in% c(&quot;21212&quot;))特定数值计数总结 xtabs ftable 创建列联表 print(object.size(fakeData),units=&quot;Mb&quot;) 现实数据大小 cut 通过设置breaks产生分类变量 Hmisc包 library(Hmisc) data$zipGroups = cut2(data$zipCode,g=4) table(data$zipGroups) library(plyr) # mutate进行数据替换或生成 data2 = mutate(data,zipGroups=cut2(zipCode,g=4)) table(data2$zipGroups) 4.14 数据整理 每一列一个变量 每一行一个样本 每个文件存储一类样本 melt进行数据融合 reshape2包 dcast分组汇总数据框 acast分组汇总向量数组 arrange指定变量名排序 merge按照指定向量合并数据 plyr包的join函数也可实现合并 4.15 数据操作data.table包 基本兼容data.frame 速度更快 通过key可指定因子变量并快速提取分组的行 可在第二个参数是R表达式 DT[,list(mean(x),sum(z))] DT[,table(y)] 可用:生成新变量 进行简单计算 DT[,w:=z^2] DT[,m:= {tmp &lt;- (x+z); log2(tmp+5)}] 进行数据条件截取 DT[,a:=x&gt;0] DT[,b:= mean(x+w),by=a] 进行计数 DT &lt;- data.table(x=sample(letters[1:3], 1E5, TRUE)) DT[, .N, by=x] 4.16 文本处理 处理大小写tolower toupper 处理变量名strsplit firstElement &lt;- function(x){x[1]} sapply(splitNames,firstElement) 字符替换sub gsub 寻找变量grep(返回行号) grepl(返回逻辑值) stringr包 stringr paste0 不带空格 str_trim 去除空格 命名原则 变量名小写 描述性 无重复 变量名不要符号分割 Names of variables should be 正则表达式 文字处理格式 ^ 匹配开头 $ 匹配结尾 [] 匹配大小写 ^在开头表示非 . 匹配任意字符 | 匹配或 () 匹配与 ? 匹配可选择 * 匹配任意 + 匹配至少一个 {} 匹配其中最小最大 一个值表示精确匹配 m,表示至少m次匹配 \\1 匹配前面指代 4.17 日期处理 formate处理日期格式 %d 日 %a 周缩写 %A 周 %m 月 %b 月缩写 %B 月全名 %y 2位年 %Y 4位年 weekdays 显示星期 months 显示月份 julian 显示70年以来的日期 lubridate包 ymd mdy dmy ymd_hms Sys.timezone "],
["section-5.html", "笔记 5 探索性数据分析 5.1 探索绘图原则 5.2 探索性绘图 5.3 R绘图系统 5.4 分层聚类 5.5 k-means聚类 5.6 维度还原", " 笔记 5 探索性数据分析 5.1 探索绘图原则 表示可比的对比 表示因果 解释 机制 系统结构 表示多元变量（超过2） 证据整合 目的驱动非工具驱动 证据描述要标注限定恰当 内容为王 5.2 探索性绘图 个人理解用 不用过分关注细节 基于问题或假设出发 5.3 R绘图系统 5.3.1 基础包 艺术家绘画模式 graphics 包括基础包的绘图函数如plot, hist, boxplot grDevices 包括执行调用绘图设备函数如X11, PDF, PostScript, PNG 叠加函数 高度自由度 初始化新图 然后标注 以下命令熟记 pch: the plotting symbol (default is open circle) lty: the line type (default is solid line), can be dashed, dotted, etc. lwd: the line width, specified as an integer multiple col: the plotting color, specified as a number, string, or hex code; the colors() function gives you a vector of colors by name xlab: character string for the x-axis label ylab: character string for the y-axis label par():查找做图的画布参数 具体如下 las: the orientation of the axis labels on the plot bg: the background color mar: the margin size oma: the outer margin size (default is 0 for all sides) mfrow: number of plots per row, column (plots are filled row-wise) mfcol: number of plots per row, column (plots are filled column-wise) plot: make a scatterplot, or other type of plot depending on the class of the object being plotted lines: add lines to a plot, given a vector x values and a corresponding vector of y values (or a 2-column matrix); this function just connects the dots points: add points to a plot text: add text labels to a plot using specified x, y coordinates title: add annotations to x, y axis labels, title, subtitle, outer margin mtext: add arbitrary text to the margins (inner or outer) of the plot axis: adding axis ticks/labels 图形设备 图像一定要有设备 屏幕设备 Mac quartz() windows windows() Unix/linux x11() 先调用后用dev.off()关闭设备 矢量图设备 保真放大 元素过多体积庞大 pdf() svg() winmetafile() postscript() 位图设备 放大失真 基于像素 png() jpeg() tiff() bmp() 当前设备dev.cur() 设置设备dev.set(&lt;integer&gt;) 设备转移dev.copy dev.copy2pdf 5.3.2 lattice 一站式解决 lattice 包括框架图函数如xyplot, bwplot, levelplot grid 包括独立于基础绘图系统的网格绘图系统 一个函数解决问题 默认自定义空间少 返回trellis类型对象 可单独存储 界面调整使用panel选项 以下为常见函数 xyplot: this is the main function for creating scatterplots bwplot: box-and-whiskers plots (“boxplots”) histogram: histograms stripplot: like a boxplot but with actual points dotplot: plot dots on “violin strings” splom: scatterplot matrix; like pairs in base plotting system levelplot, contourplot: for plotting “image” data 基本格式 xyplot(y ~ x | f * g, data) 可同时展示分组信息及交互作用 5.3.3 ggplot2 基于图形语法理念 图形属性映射数据问题 自动处理界面 允许后期添加 结合base与lattice 默认友好 基础绘图qplot() ggplot() 通过叠加元素出图 细节调整xlab(), ylab(), labs(), ggtitle() 主题调整theme() 做图需求 数据框 data.frame 属性映射 asethetic mappling 几何对象 geoms 条件 facets 统计转换 stats 范围量表 scales 坐标轴系统 coordinate system 5.3.4 数学绘图 Tex语法 使用expression() ?plotmath 5.3.5 色彩管理 colorRamp 返回01间数值 表示颜色过度 colorRampPalette 返回8位颜色代码调色盘 colors 返回可用颜色 RColorBrewer包 含有预先配色信息 序列 无序 两级 rgb产生三原色颜色 alpha 控制透明度 绘图时用col调用调色盘颜色 pal &lt;- colorRamp(c(&quot;red&quot;, &quot;blue&quot;)) pal(0) ## [,1] [,2] [,3] ## [1,] 255 0 0 pal(1) ## [,1] [,2] [,3] ## [1,] 0 0 255 pal(0.5) ## [,1] [,2] [,3] ## [1,] 127.5 0 127.5 ##### pal &lt;- colorRampPalette(c(&quot;red&quot;, &quot;yellow&quot;)) pal(2) ## [1] &quot;#FF0000&quot; &quot;#FFFF00&quot; pal(10) ## [1] &quot;#FF0000&quot; &quot;#FF1C00&quot; &quot;#FF3800&quot; &quot;#FF5500&quot; &quot;#FF7100&quot; &quot;#FF8D00&quot; &quot;#FFAA00&quot; ## [8] &quot;#FFC600&quot; &quot;#FFE200&quot; &quot;#FFFF00&quot; ##### library(RColorBrewer) cols &lt;- brewer.pal(3, &quot;BuGn&quot;) 5.4 分层聚类 找到最近的 聚到一起 找下个最近的 给出距离范围与距离计算方法 欧氏距离 多维空间点距 开平方 manhattan距离 出租车距离 绝对值 给出变量间或样本间的关系 图形可能不稳定 多少样本多少类 结果是确定的 选定cut点并不明显 应该首先用来探索 5.5 k-means聚类 固定聚类数 给出聚类中心 寻找最近的点 循环 需要聚类数与聚类距离范围 需要大量聚类 通过眼睛 交叉检验 k的经验数值\\(\\sqrt{n/2}\\) 或者根据解释的变量变化多少来选取 结果不确定 根据聚类数与迭代次数而变化 5.6 维度还原 找到最不相关的数来解释整体方差（统计）在这些数中选取个数最少的来解释原始数据（压缩） 不一定是真实向量的叠加 SVD是PCA的一种解法 UDV三个向量 其中U表示行变化模式 D表示方差 V表示列变换模式 这样有助于解释主成分变化 标准化与否影响结果 计算量大 类似探索分析还有因子分析 独立成分分析 潜在语义分析 impute包可补充缺失值 "],
["section-6.html", "笔记 6 可复算性研究 6.1 Replication 6.2 Reproducible 6.3 研究流程 6.4 数据分析步骤 6.5 数据分析文件结构 6.6 文本化统计编程-Knitr 6.7 结果通讯 6.8 检查列表 6.9 基于证据的数据分析", " 笔记 6 可复算性研究 6.1 Replication 科学研究的的终极标准是研究证据可独立发现与验证 并非所有结果都可以重复 6.2 Reproducible 可重复的数据分析过程与代码 数据维度增高 现有数据可被整合入更大的数据集 计算机条件允许 6.3 研究流程 6.4 数据分析步骤 定义问题 背后要有科学假设或问题 从大到小 具体定义 定义理想数据 描述性的 &lt;- 总体数据 探索性的 &lt;- 有属性测量的样本数据 推断性的 &lt;- 合适的总体 随机采样 预测性的 &lt;- 来自同一总体 有训练集与测试集的样本 因果性的 &lt;- 随机性研究 机械性的 &lt;- 系统中所有组成部分的数据 决定可获取数据 网络免费数据 购买数据 注意使用条款 数据不存在 自己创造 &lt;- 实验 获取数据 原始数据 引用来源 网络数据注明数据来源URL与获取时间 整理数据 原始数据需要整理 如果事先处理过要搞清楚如何处理的 了解数据来源 需要重新格式化 采样 &lt;- 记录步骤 判断数据是否合适 不合适重新获取 探索性数据分析 描述性总结数据 检查缺失值 绘制探索性图 尝试探索性分析 例如聚类 统计预测/建模 基于探索性分析 根据问题确定方法 数据转换要解释 测定的不确定性要考虑 解释结果 描述 相关 推断 预测 质疑结果 问题 数据源 处理过程 分析 结论 整合写出结果 从问题角度出发 形成一个故事 不要包含分析过程除非用来说明问题 消除质疑 以故事而不是时间顺序描述 图片要漂亮 写出可重复的R代码 Rmarkdown文件 6.5 数据分析文件结构 Data Raw data 来自网络在Readme里注明url 描述 日期 Processed data 命名体现处理过程 Readme里注明处理过程 Figures Exploratory figures 不必考虑装饰 Final figures 只考虑装饰 R code Raw scripts 不必过分注释 版本控制 不一定用得上 Final scripts 注释清晰 包括处理细节 只包括文章需要费分析 R Markdown files (optional) Text Readme files 按步骤记录清晰 Text of analysis 包括前言 方法 结果 结论 讲故事 有引用 6.6 文本化统计编程-Knitr markdown是轻量化结构语言 R markdown 是轻量化统计结构语言 文本+代码块 逻辑清晰 文本语言可用latex markdown 代码块可用R 不用保存输出 可缓存结果 cacher包 6.7 结果通讯 研究论文的信息层级 题目/作者名单 摘要 主体/结果 支持材料/细节 代码/数据 邮件汇报的信息层级 题目最好一行一句 描述问题 如何实验 总结发现 简明扼要 如果有问题 写成yes/no形式 附件齐全严谨 6.8 检查列表 数据选取得当 问题简单专一 队友靠谱 兴趣驱动 不要手动处理数据 全部交给计算机 少用交互界面 用命令行界面并记录历史 使用版本控制 处理降速而冷静 记录软件操作环境 sessionInfo() 不保存结果保证数据可重复 使用随机数要说明种子 原始数据-处理数据-分析-报告 考虑从哪一步开始数据重复性变差 6.9 基于证据的数据分析 可重复性研究不保证结果是对的 发表后研究存在动因 应关注数据生成前的过程 设定基于证据研究的路线图 减少研究人员的自由度 提出区域研究范式 "],
["-1.html", "笔记 7 统计推断 7.1 导论 7.2 概率 7.3 期望 7.4 方差 7.5 独立性 7.6 条件概率 7.7 贝叶斯定理 7.8 常见分布 7.9 渐进 7.10 T 置信区间 7.11 似然函数 7.12 贝叶斯推断 7.13 两独立样本t检验 7.14 假设检验 7.15 P 值 7.16 功效 7.17 多重比较 7.18 重采样推断", " 笔记 7 统计推断 7.1 导论 定义 用需要考虑不确定度的含噪音的统计学数据推断事实 工具 随机化 随机采样 采样模型 假设检验 置信区间 概率模型 实验设计 bootstraping 排列交换随机 类型 频率派 使用概率的频率解释来控制错误率 贝叶斯派 给定概率与数据概率哪个靠谱 7.2 概率 术语 样本空间 Ω 事件 样本空间子集 E 单独事件 ω 空事件 ∅ \\(ω∈E\\) ω发生E发生 \\(ω∉E\\) ω发生E不发生 \\(E⊂F\\) E发生则F发生 \\(E∩F\\) EF一起发生 \\(E∪F\\) EF中至少一个发生 \\(E∩F=∅\\) EF互斥 \\(E^c\\) 或 \\(\\bar E\\) E不发生 概率 对事件 \\(E\\subset \\Omega\\), \\(0 \\leq P(E) \\leq 1\\) \\(P(\\Omega) = 1\\) 如果 \\(E_1\\) 与 \\(E_2\\) 互斥 有\\(P(E_1 \\cup E_2) = P(E_1) + P(E_2)\\). 概率无限可加性 \\(P(\\cup_{i=1}^n A_i) = \\sum_{i=1}^n P(A_i)\\) \\(P(\\emptyset) = 0\\) \\(P(E) = 1 - P(E^c)\\) \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) 如果 \\(A \\subset B\\) 则 \\(P(A) \\leq P(B)\\) \\(P\\left(A \\cup B\\right) = 1 - P(A^c \\cap B^c)\\) \\(P(A \\cap B^c) = P(A) - P(A \\cap B)\\) \\(P(\\cup_{i=1}^n E_i) \\leq \\sum_{i=1}^n P(E_i)\\) \\(P(\\cup_{i=1}^n E_i) \\geq \\max_i P(E_i)\\) 随机变量 实验的数值输出 离散随机变量取可数的概率 \\(P(X = k)\\) 连续随机变量取连续区间子集概率 \\(P(X \\in A)\\) 概率质量函数（PMF）&lt;- 离散随机变量 对于所有 \\(x\\) \\(p(x) \\geq 0\\) \\(\\sum_{x} p(x) = 1\\) 概率密度函数（PDF）&lt;- 连续随机变量 对于所有 \\(x\\) \\(f(x) \\geq 0\\) \\(f(x)\\) 下面积为1 累计概率函数（CDF） 定义 \\(F(x) = P(X \\leq x)\\) 生存函数 \\(S(x) = P(X &gt; x)\\) \\(S(x) = 1 - F(x)\\) 对于连续函数 CDF是PDF的积分 分位数 \\(\\alpha^{th}\\) \\(F(x_\\alpha) = \\alpha\\) \\(50^{th}\\) 分位数是中位数 7.3 期望 离散随机变量均值 \\(E[X] = \\sum_x xp(x)\\) \\(E[X]\\) 代表质量与位置的中心 \\(\\{x, p(x)\\}\\) 连续随机变量均值 \\(E[X] = \\mbox{the area under the function}~~~ t f(t)\\) 期望值是线性可加的 如果 \\(a\\) 与 \\(b\\) 不随机 \\(X\\) 与 \\(Y\\) 是随机变量 \\(E[aX + b] = a E[X] + b\\) \\(E[X + Y] = E[X] + E[Y]\\) 样本均值是总体均值\\(\\mu\\)的无偏估计的证明 \\[ \\begin{eqnarray*} E\\left[ \\frac{1}{n}\\sum_{i=1}^n X_i\\right] &amp; = &amp; \\frac{1}{n} E\\left[\\sum_{i=1}^n X_i\\right] \\\\ &amp; = &amp; \\frac{1}{n} \\sum_{i=1}^n E\\left[X_i\\right] \\\\ &amp; = &amp; \\frac{1}{n} \\sum_{i=1}^n \\mu = \\mu. \\end{eqnarray*} \\] 7.4 方差 描述随机变量的离散情况 如果 \\(X\\) 是均值 \\(\\mu\\) 的随机变量 其方差为\\(Var(X) = E[(X - \\mu)^2]\\) 离开均值距离期望的平方 计算公式 \\(Var(X) = E[X^2] - E[X]^2\\) 如果 \\(a\\) 是常数有 \\(Var(aX) = a^2 Var(X)\\) 方差的开方是标准差 单位与 \\(X\\) 一致 车比雪夫不等式（Chebyshev’s inequality）边界极为保守 \\[ P(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2} \\] 7.5 独立性 独立事件 两事件 \\(A\\) 与 \\(B\\) 在 \\(P(A \\cap B) = P(A)P(B)\\) 下独立 在 \\(P([X \\in A] \\cap [Y \\in B]) = P(X\\in A)P(Y\\in B)\\) 下两随机变量 \\(X\\) 与 \\(Y\\) 独立 对于一组随机独立变量\\(X_1, X_2, \\ldots, X_n\\)有 \\(f(x_1,\\ldots, x_n) = \\prod_{i=1}^n f_i(x_i)\\) iid随机变量（independent and identically distributed） 来自同一分布相互独立的随机变量 协方差（covariance） \\(Cov(X, Y) = E[(X - \\mu_x)(Y - \\mu_y)] = E[X Y] - E[X]E[Y]\\) \\(Cov(X, Y) = Cov(Y, X)\\) \\(Cov(X, Y)\\) 可以有正负 \\(|Cov(X, Y)| \\leq \\sqrt{Var(X) Var(y)}\\) 相关性（correlation） \\(X\\) 与 \\(Y\\) 的相关性 \\(Cor(X, Y) = Cov(X, Y) / \\sqrt{Var(X) Var(y)}\\) \\(-1 \\leq Cor(X, Y) \\leq 1\\) 只有对常数 \\(a\\) 与 \\(b\\)满足 \\(X = a + bY\\) 时\\(Cor(X, Y) = \\pm 1\\) \\(Cor(X, Y)\\) 无单位 \\(Cor(X, Y) = 0\\) 时 \\(X\\) 与 \\(Y\\) 不相关 \\(Cor(X,Y)\\) 越接近1 \\(X\\) 与 \\(Y\\) 越正相关 反之接近-1 负相关 \\(\\{X_i\\}_{i=1}^n\\) 是一组随机变量 当 \\(\\{X_i\\}\\) 不相关时 \\(Var\\left(\\sum_{i=1}^n a_i X_i + b\\right) = \\sum_{i=1}^n a_i^2 Var(X_i)\\) 如果一组随机变量\\(\\{X_i\\}\\)不相关 方差的和等于和的方差 非标准差 样本均值方差的推导 \\[ \\begin{eqnarray*} Var(\\bar X) &amp; = &amp; Var \\left( \\frac{1}{n}\\sum_{i=1}^n X_i \\right)\\\\ \\\\ &amp; = &amp; \\frac{1}{n^2} Var\\left(\\sum_{i=1}^n X_i \\right)\\\\ \\\\ &amp; = &amp; \\frac{1}{n^2} \\sum_{i=1}^n Var(X_i) \\\\ \\\\ &amp; = &amp; \\frac{1}{n^2} \\times n\\sigma^2 \\\\ \\\\ &amp; = &amp; \\frac{\\sigma^2}{n} \\end{eqnarray*} \\] 当 \\(X_i\\) 独立且方差为 \\(Var(\\bar X) = \\frac{\\sigma^2}{n}\\) \\(\\sigma/\\sqrt{n}\\) 为样本均值的标准误 样本均值的标准误就是样本均值分布的标准差 \\(\\sigma\\) 是一次观察分布的标准差 样本均值要比一次观察变化小 因此除以\\(\\sqrt{n}\\) 样本方差 \\(S^2 = \\frac{\\sum_{i=1}^n (X_i - \\bar X)^2}{n-1}\\) 总体方差 \\(\\sigma^2\\)的估计 计算 \\(\\sum_{i=1}^n (X_i - \\bar X)^2 = \\sum_{i=1}^n X_i^2 - n \\bar X^2\\) 均值偏差平方的均值 样本方差是总体方差的无偏估计 \\[ \\begin{eqnarray*} E\\left[\\sum_{i=1}^n (X_i - \\bar X)^2\\right] &amp; = &amp; \\sum_{i=1}^n E\\left[X_i^2\\right] - n E\\left[\\bar X^2\\right] \\\\ \\\\ &amp; = &amp; \\sum_{i=1}^n \\left\\{Var(X_i) + \\mu^2\\right\\} - n \\left\\{Var(\\bar X) + \\mu^2\\right\\} \\\\ \\\\ &amp; = &amp; \\sum_{i=1}^n \\left\\{\\sigma^2 + \\mu^2\\right\\} - n \\left\\{\\sigma^2 / n + \\mu^2\\right\\} \\\\ \\\\ &amp; = &amp; n \\sigma^2 + n \\mu ^ 2 - \\sigma^2 - n \\mu^2 \\\\ \\\\ &amp; = &amp; (n - 1) \\sigma^2 \\end{eqnarray*} \\] 澄清 假定 \\(X_i\\) 是 iid 均值 \\(\\mu\\) 方差 \\(\\sigma^2\\) \\(S^2\\) 估计 \\(\\sigma^2\\) \\(S^2\\) 的计算涉及除 \\(n-1\\) \\(S / \\sqrt{n}\\) 估计 \\(\\sigma / \\sqrt{n}\\) 是均值的标准误 7.6 条件概率 \\(B\\) 为一个事件 有 \\(P(B) &gt; 0\\) \\(B\\) 出现条件下 \\(A\\) 的条件概率为 \\(P(A ~|~ B) = \\frac{P(A \\cap B)}{P(B)}\\) 如果 \\(A\\) 与 \\(B\\) 独立 有 \\(P(A ~|~ B) = \\frac{P(A) P(B)}{P(B)} = P(A)\\) 7.7 贝叶斯定理 \\[ P(B ~|~ A) = \\frac{P(A ~|~ B) P(B)}{P(A ~|~ B) P(B) + P(A ~|~ B^c)P(B^c)}. \\] 2*2 列联表 - 诊断测试 7.8 常见分布 贝努力分布 二元输出变量 数值为0或1 概率\\(p\\) 与 \\(1-p\\) \\(X\\)的PMF是\\(P(X = x) = p^x (1 - p)^{1 - x}\\) 均值 \\(p\\) 方差 \\(p(1 - p)\\) 如果有iid的贝努力观察\\(x_1,\\ldots, x_n\\) 似然函数 \\(\\prod_{i=1}^n p^{x_i} (1 - p)^{1 - x_i} = p^{\\sum x_i} (1 - p)^{n - \\sum x_i}\\) 似然函数依赖\\(x_i\\)的和 \\(\\sum_i x_i / n\\) 包含了所有 \\(p\\) 的可能性 最大化似然函数可以得到 \\(p\\) 的估计 二项分布 PMF \\[ P(X = x) = \\left( \\begin{array}{c} n \\\\ x \\end{array} \\right) p^x(1 - p)^{n-x} \\] 对于 \\(x=0,\\ldots,n\\) 正态分布 PDF \\((2\\pi \\sigma^2)^{-1/2}e^{-(x - \\mu)^2/2\\sigma^2}\\) \\(X\\) 为均值 \\(E[X] = \\mu\\) 方差 \\(Var(X) = \\sigma^2\\) 的iid随机变量 写作\\(X\\sim \\mbox{N}(\\mu, \\sigma^2)\\) 均值 \\(\\mu = 0\\) 方差 \\(\\sigma = 1\\) 是标准正态分布 标准正态函数写作 \\(\\phi\\) 标准正态随机变量用 \\(Z\\) 表示 如果 \\(X \\sim \\mbox{N}(\\mu,\\sigma^2)\\) 并且 \\(Z = \\frac{X -\\mu}{\\sigma}\\) 是标准正态函数 如果 \\(Z\\) 是标准正态函数 \\(X = \\mu + \\sigma Z \\sim \\mbox{N}(\\mu, \\sigma^2)\\) 非标准正态密度函数 \\(\\phi\\{(x - \\mu) / \\sigma\\}/\\sigma\\) 正态似然函数对方差的估计是有偏的 正态的和是正态 样本均值正态 正态的平方是卡方 泊松分布 PMF \\(P(X = x; \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\\) 均值方差均为 \\(\\lambda\\) 可看做很短时间间隔中发生事件的概率 模拟速率 其中\\(\\lambda * h\\)小于1 则各时间段独立 \\(X \\sim Poisson(\\lambda t)\\) \\(\\lambda = E[X / t]\\)是速率 \\(t\\) 是总时间 \\(n\\) 大 \\(p\\) 小是对二项分布的模拟 \\(X \\sim \\mbox{Binomial}(n, p)\\), \\(\\lambda = n p\\) 7.9 渐进 样本接近无穷大时统计量的行为 频率派的基石 大数理论（LLN） 样本数量越多 均值接近期望 中心极限理论 (CLT) iid 变量均值的分布标准化后随样本数增加接近标准正态分布 \\[ \\frac{\\bar X_n - \\mu}{\\sigma / \\sqrt{n}} = \\frac{\\mbox{Estimate} - \\mbox{Mean of estimate}}{\\mbox{Std. Err. of estimate}} \\] 可根据变量分布来 知道均值 方差 计算出样本均值标准误 就可以根据CLT计算逼近的统计量 置信区间 根据CLT随机区间\\(\\bar X_n \\pm z_{1-\\alpha/2}\\sigma / \\sqrt{n}\\) 包括 \\(\\mu\\) 的概率逼近于 100\\((1-\\alpha)\\)% \\(z_{1-\\alpha/2}\\)为标准正态分布\\(1-\\alpha/2\\)的分位数 \\(100(1 - \\alpha)\\)% 为置信区间 \\(\\sigma\\) 可用样本估计 \\(s\\) 来近似 估计是基于分布假设的 如果分布有解析解 则置信区间可以更准确的得到估计 先生成不依赖参数的统计量 根据统计量的概率分布计算参数的边界 7.10 T 置信区间 卡方分布 假定 \\(S^2\\) 是来自\\(n\\)个 iid \\(N(\\mu,\\sigma^2)\\) 数据样本的方差 有\\(\\frac{(n - 1) S^2}{\\sigma^2} \\sim \\chi^2_{n-1}\\) 符合自由度\\(n-1\\)的卡方分布 不对称分布 均值是自由度 方差是两倍的自由度 方差的置信区间 \\[ \\begin{eqnarray*} 1 - \\alpha &amp; = &amp; P \\left( \\chi^2_{n-1, \\alpha/2} \\leq \\frac{(n - 1) S^2}{\\sigma^2} \\leq \\chi^2_{n-1,1 - \\alpha/2} \\right) \\\\ \\\\ &amp; = &amp; P\\left(\\frac{(n-1)S^2}{\\chi^2_{n-1,1-\\alpha/2}} \\leq \\sigma^2 \\leq \\frac{(n-1)S^2}{\\chi^2_{n-1,\\alpha/2}} \\right) \\\\ \\end{eqnarray*} \\] \\(\\left[\\frac{(n-1)S^2}{\\chi^2_{n-1,1-\\alpha/2}}, \\frac{(n-1)S^2}{\\chi^2_{n-1,\\alpha/2}}\\right]\\) 是 \\(\\sigma^2\\) 的 \\(100(1-\\alpha)\\%\\) 置信区间 依赖正态性假设 开方后得到 \\(\\sigma\\) 的置信区间 Gosset的 t 分布 比正态分布尾厚 考虑自由度 自由度大时接近正态分布 \\(\\frac{Z}{\\sqrt{\\frac{\\chi^2}{df}}}\\) 假定 \\((X_1,\\ldots,X_n)\\) 是 iid \\(N(\\mu,\\sigma^2)\\) 有 \\(\\frac{\\bar X - \\mu}{\\sigma / \\sqrt{n}}\\) 是标准正态分布 \\(\\sqrt{\\frac{(n - 1) S^2}{\\sigma^2 (n - 1)}} = S / \\sigma\\) 是卡方除以自由度的开方 有 \\[ \\frac{\\frac{\\bar X - \\mu}{\\sigma /\\sqrt{n}}}{S/\\sigma} = \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\] 服从自由度\\(n-1\\)的\\(t\\)分布 均值的置信区间 \\[ \\begin{eqnarray*} &amp; &amp; 1 - \\alpha \\\\ &amp; = &amp; P\\left(-t_{n-1,1-\\alpha/2} \\leq \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\leq t_{n-1,1-\\alpha/2}\\right) \\\\ \\\\ &amp; = &amp; P\\left(\\bar X - t_{n-1,1-\\alpha/2} S / \\sqrt{n} \\leq \\mu \\leq \\bar X + t_{n-1,1-\\alpha/2}S /\\sqrt{n}\\right) \\end{eqnarray*} \\] \\(t_{df,\\alpha}\\) 是t分布的 \\(\\alpha^{th}\\) 分位数 自由度 \\(df\\) t检验不适合有偏分布 置信区间中心也不在均值上 7.11 似然函数 一组数据的似然函数是数据固定下参数的联合概率密度函数 似然函数可用来估计参数 是参数的函数 似然函数比估计两个可能参数值的可能性 给定模型与数据 似然函数包含所有参数可能性 样本独立时 参数的似然函数是各独立样本似然函数的乘积 参数使似然函数概率取最大值时真实的可能性更大 更支持这组数据 这个估计是最大似然估计（MLE） 7.12 贝叶斯推断 \\(\\mbox{Posterior} \\propto \\mbox{Likelihood} \\times \\mbox{Prior}\\) 先验beta分布 01之间 依赖 \\(\\alpha\\) \\(\\beta\\) 的概率密度函数 \\[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} p ^ {\\alpha - 1} (1 - p) ^ {\\beta - 1} ~~~~\\mbox{for} ~~ 0 \\leq p \\leq 1 \\] 均值 \\(\\alpha / (\\alpha + \\beta)\\) 方差 \\(\\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\) \\(\\alpha = \\beta = 1\\) 为均匀分布 后验beta分布 参数\\(\\tilde \\alpha = x + \\alpha\\) \\(\\tilde \\beta = n - x + \\beta\\) 的beta分布 \\[ \\begin{align} \\mbox{Posterior} &amp;\\propto p^x(1 - p)^{n-x} \\times p^{\\alpha -1} (1 - p)^{\\beta - 1} \\\\ &amp; = p^{x + \\alpha - 1} (1 - p)^{n - x + \\beta - 1} \\end{align} \\] 后验均值 \\[ \\begin{align} E[p ~|~ X] &amp; = \\frac{\\tilde \\alpha}{\\tilde \\alpha + \\tilde \\beta}\\\\ \\\\ &amp; = \\frac{x + \\alpha}{x + \\alpha + n - x + \\beta}\\\\ \\\\ &amp; = \\frac{x + \\alpha}{n + \\alpha + \\beta} \\\\ \\\\ &amp; = \\frac{x}{n} \\times \\frac{n}{n + \\alpha + \\beta} + \\frac{\\alpha}{\\alpha + \\beta} \\times \\frac{\\alpha + \\beta}{n + \\alpha + \\beta} \\\\ \\\\ &amp; = \\mbox{MLE} \\times \\pi + \\mbox{Prior Mean} \\times (1 - \\pi) \\end{align} \\] 后验均值是先验均值与最大似然估计的混合 当 \\(n\\) 变大 \\(\\pi\\) 接近 \\(1\\) 先验作用小 当 \\(n\\) 很小 先验作用大 当数据量够大时 先验概率作用就很小了 当先验概率足够稳定 数据就作用不大了 信任区间 \\(95\\%\\) 信任区间 \\([a, b]\\) 会满足\\(P(p \\in [a, b] ~|~ x) = .95\\) 最高后验密度 (HPD) 区间 7.13 两独立样本t检验 \\(X_1,\\ldots,X_{n_x}\\) 为 iid \\(N(\\mu_x,\\sigma^2)\\) \\(Y_1,\\ldots,Y_{n_y}\\) 为 iid \\(N(\\mu_y, \\sigma^2)\\) \\(\\bar X\\), \\(\\bar Y\\), \\(S_x\\), \\(S_y\\) 为均值与标准差 根据均值与方差的线性组合 有 \\(\\bar Y - \\bar X\\) 也是正态 均值 \\(\\mu_y - \\mu_x\\) 方差 \\(\\sigma^2 (\\frac{1}{n_x} + \\frac{1}{n_y})\\) 混合方差为 \\(S_p^2 = \\{(n_x - 1) S_x^2 + (n_y - 1) S_y^2\\}/(n_x + n_y - 2)\\) 为\\(\\sigma^2\\)的良好估计 该估计为无偏估计 \\[ \\begin{eqnarray*} E[S_p^2] &amp; = &amp; \\frac{(n_x - 1) E[S_x^2] + (n_y - 1) E[S_y^2]}{n_x + n_y - 2}\\\\ &amp; = &amp; \\frac{(n_x - 1)\\sigma^2 + (n_y - 1)\\sigma^2}{n_x + n_y - 2} \\end{eqnarray*} \\] 该估计独立于 \\(\\bar Y - \\bar X\\) 因为方差独立于均值 两个独立的卡方变量之和是自由度之和的卡方值 \\[ \\begin{eqnarray*} (n_x + n_y - 2) S_p^2 / \\sigma^2 &amp; = &amp; (n_x - 1)S_x^2 /\\sigma^2 + (n_y - 1)S_y^2/\\sigma^2 \\\\ \\\\ &amp; = &amp; \\chi^2_{n_x - 1} + \\chi^2_{n_y-1} \\\\ \\\\ &amp; = &amp; \\chi^2_{n_x + n_y - 2} \\end{eqnarray*} \\] 构建统计量 \\[ \\frac{\\frac{\\bar Y - \\bar X - (\\mu_y - \\mu_x)}{\\sigma \\left(\\frac{1}{n_x} + \\frac{1}{n_y}\\right)^{1/2}}}{\\sqrt{\\frac{(n_x + n_y - 2) S_p^2}{(n_x + n_y - 2)\\sigma^2}}} = \\frac{\\bar Y - \\bar X - (\\mu_y - \\mu_x)}{S_p \\left(\\frac{1}{n_x} + \\frac{1}{n_y}\\right)^{1/2}} \\] 该统计量为符合自由度 \\(n_x + n_y - 2\\) 的 \\(t\\) 分布 置信区间 \\[ \\bar Y - \\bar X \\pm t_{n_x + n_y - 2, 1 - \\alpha/2}S_p\\left(\\frac{1}{n_x} + \\frac{1}{n_y}\\right)^{1/2} \\] 方差不等 \\[ \\bar Y - \\bar X \\sim N\\left(\\mu_y - \\mu_x, \\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y}\\right) \\] 统计量 \\[ \\frac{\\bar Y - \\bar X - (\\mu_y - \\mu_x)}{\\left(\\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y}\\right)^{1/2}} \\] 近似于自由度 \\[ \\frac{\\left(S_x^2 / n_x + S_y^2/n_y\\right)^2} {\\left(\\frac{S_x^2}{n_x}\\right)^2 / (n_x - 1) + \\left(\\frac{S_y^2}{n_y}\\right)^2 / (n_y - 1)} \\] 的\\(t\\)分布 7.14 假设检验 使用数据做决定 空假设 \\(H_0\\) 无变化 备择假设 \\(H_a\\) 或大 或小 或不等 真值表 Truth Decide Result \\(H_0\\) \\(H_0\\) Correctly accept null \\(H_0\\) \\(H_a\\) Type I error \\(H_a\\) \\(H_a\\) Correctly reject null \\(H_a\\) \\(H_0\\) Type II error Z检验 Z检验 \\(H_0:\\mu = \\mu_0\\) 与 \\(H_1: \\mu &lt; \\mu_0\\) \\(H_2: \\mu \\neq \\mu_0\\) \\(H_3: \\mu &gt; \\mu_0\\) 检验统计量 \\(TS = \\frac{\\bar{X} - \\mu_0}{S / \\sqrt{n}}\\) 拒绝空假设条件 \\(TS \\leq -Z_{1 - \\alpha}\\) \\(|TS| \\geq Z_{1 - \\alpha / 2}\\) \\(TS \\geq Z_{1 - \\alpha}\\) 样本数要足够 否则选 \\(t\\) 检验 通过 \\(\\alpha\\) 控制了 Type I error 但没控制 \\(\\beta\\) Type II error 所以结论为没有拒绝 \\(H_0\\) 而不是接受 \\(H_0\\) 拒绝 \\(H_0\\) 的值域为拒绝域 二项分布不易做正态假设可精确计算拒绝域 7.15 P 值 假定没有事发生 出现状况的可能性 先定义分布 然后计算相关统计量 对比常见阈值看数值是否够极端 阈值为达到显著性水平 与p值有区别 p值可设定任意显著性水平 小于就可以拒绝 两尾检验 单尾概率翻倍 独立于假设检验 但常常一起使用 7.16 功效 错误拒绝空假设的概率为功效（power） Power \\(= 1 - \\beta\\) 对 Type II error 的控制 正态分布假设下的推导 \\[ \\begin{align} 1 -\\beta &amp; = P\\left(\\frac{\\bar X - 30}{\\sigma /\\sqrt{n}} &gt; z_{1-\\alpha} ~|~ \\mu = \\mu_a \\right)\\\\ &amp; = P\\left(\\frac{\\bar X - \\mu_a + \\mu_a - 30}{\\sigma /\\sqrt{n}} &gt; z_{1-\\alpha} ~|~ \\mu = \\mu_a \\right)\\\\ \\\\ &amp; = P\\left(\\frac{\\bar X - \\mu_a}{\\sigma /\\sqrt{n}} &gt; z_{1-\\alpha} - \\frac{\\mu_a - 30}{\\sigma /\\sqrt{n}} ~|~ \\mu = \\mu_a \\right)\\\\ \\\\ &amp; = P\\left(Z &gt; z_{1-\\alpha} - \\frac{\\mu_a - 30}{\\sigma /\\sqrt{n}} ~|~ \\mu = \\mu_a \\right)\\\\ \\\\ \\end{align} \\] sigma &lt;- 10; mu_0 = 0; mu_a = 2; n &lt;- 100; alpha = .05 plot(c(-3, 6),c(0, dnorm(0)), type = &quot;n&quot;, frame = F, xlab = &quot;Z value&quot;, ylab = &quot;&quot;) xvals &lt;- seq(-3, 6, length = 1000) lines(xvals, dnorm(xvals), type = &quot;l&quot;, lwd = 3) lines(xvals, dnorm(xvals, mean = sqrt(n) * (mu_a - mu_0) / sigma), lwd =3) abline(v = qnorm(1 - alpha)) - 计算步骤 - 考虑 \\(H_0 : \\mu = \\mu_0\\) 与 \\(H_a : \\mu &gt; \\mu_0\\) 且在\\(H_a\\)下 \\(\\mu = \\mu_a\\) - 在 \\(H_0\\) 下统计量 \\(Z = \\frac{\\sqrt{n}(\\bar X - \\mu_0)}{\\sigma}\\) 符合 \\(N(0, 1)\\) - 在\\(H_a\\)下 \\(Z\\) 是 \\(N\\left( \\frac{\\sqrt{n}(\\mu_a - \\mu_0)}{\\sigma}, 1\\right)\\) - 如果 \\(Z &gt; Z_{1-\\alpha}\\) 拒绝空假设 也就是给定条件下功效不够 - 当检验 \\(H_a : \\mu &gt; \\mu_0\\), 如果功效为 \\(1 - \\beta\\) 那么 \\(1 - \\beta = P\\left(Z &gt; z_{1-\\alpha} - \\frac{\\mu_a - \\mu_0}{\\sigma /\\sqrt{n}} ~|~ \\mu = \\mu_a \\right) = P(Z &gt; z_{\\beta})\\) 也就是 \\(z_{1-\\alpha} - \\frac{\\sqrt{n}(\\mu_a - \\mu_0)}{\\sigma} = z_{\\beta}\\) - \\(\\mu_a\\), \\(\\sigma\\), \\(n\\), \\(\\beta\\), \\(\\mu_0\\), \\(\\alpha\\) 给定五个可解出剩余的 - 两尾检验考虑 \\(\\alpha / 2\\) - 功效在 \\(\\alpha\\) 提高 单尾检验功效高于两尾 \\(\\mu_1\\) 距离 \\(\\mu_0\\) 远功效大 样本数提高功效高 - 计算功效不需要特定样本 只需要指定 \\(\\frac{\\mu_a - \\mu_0}{\\sigma}\\) 也就是有效样本大小 无单位 - R 中使用 power.t.test 来计算 \\(t\\) 检验功效相关参数 指定多数求一个 7.17 多重比较 多次进行比较会导致错误率与校正出现问题 False positive rate 错误结果是显著的比率 \\(\\alpha\\) 样本数增大错误增加 Family wise error rate (FWER) 所有比较中至少一个假阳性比率 Bonferroni correction 假设你进行m次测试 控制 \\(\\alpha\\) 在某水平 计算所有测试的 \\(p\\) 值 将 \\(\\alpha\\) 设为 $ /m$ 所有测试都在这个置信度下进行 容易计算 过于保守 False discovery rate (FDR) 声称显著是错误的概率 \\(m\\) 次测试 水平 \\(\\alpha\\) 计算 \\(p\\) 值 排序 \\(P_{(i)} \\leq \\alpha \\times \\frac{i}{m}\\) 为显著 相对容易计算 不保守 允许一定的假阳性 调节p值 \\(P_i^{fwer} = \\max{m \\times P_i,1}\\) 类似FWER处理 \\(\\alpha\\) 的方式处理 \\(p\\) 按照正常 \\(\\alpha\\) 检测 一般情况对 \\(p\\) 值用 bonferroni/BH矫正就够了 对比间依赖强烈考虑 method=“BY” 多重比较从原理到应用 从实用角度分类 适合常见科研实验结果处理 7.18 重采样推断 jackknife 用来无偏估计偏差与标准误 每次估计删掉一个数据 \\(\\bar \\theta = \\frac{1}{n}\\sum_{i=1}^n \\hat \\theta_{i}\\) 偏差 \\((n - 1) \\left(\\bar \\theta - \\hat \\theta\\right)\\) 标准误 \\(\\left[\\frac{n-1}{n}\\sum_{i=1}^n (\\hat \\theta_i - \\bar\\theta )^2\\right]^{1/2}\\) 可用来估计分位数 是bootstrap的线性逼近 但性质不好 假观察量角度理解jackknife \\(\\mbox{Pseudo Obs} = n \\hat \\theta - (n - 1) \\hat \\theta_{i}\\) 生成原数据集 bootstrap 构建置信区间与求标准误 假定采样分布是总体分布 重采样估计统计量 有放回的重采样 \\(B\\) 次 \\(N\\) 个样本 得到估计统计量的一个分布 直接计算置信区间 非参方法 偏差小 进阶指南 置换检验 分组对比时取消原分组随机分组 重复进行 记录分组差异 对比原参数与置换后参数差异进行推断 "],
["section-8.html", "笔记 8 回归模型 8.1 导论 8.2 术语 8.3 回归线的最小二乘回归 8.4 统计线性回归模型 8.5 残差 8.6 回归推断 8.7 多元回归 8.8 模型诊断与选择 8.9 广义线性模型 8.10 二元响应 8.11 计数或速率响应 8.12 分段平滑", " 笔记 8 回归模型 8.1 导论 Francis Galton 1885年用父母身高预测子女身高的案例 考虑单变量的数据代表：最小二乘值 最小二乘值物理意义为质心 最小二乘统计学意义是平均值 可用不等式解 也可用求导方法解 \\[ \\begin{align} \\sum_{i=1}^n (Y_i - \\mu)^2 &amp; = \\ \\sum_{i=1}^n (Y_i - \\bar Y + \\bar Y - \\mu)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\bar Y)^2 + \\ 2 \\sum_{i=1}^n (Y_i - \\bar Y) (\\bar Y - \\mu) +\\ \\sum_{i=1}^n (\\bar Y - \\mu)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\bar Y)^2 + \\ 2 (\\bar Y - \\mu) \\sum_{i=1}^n (Y_i - \\bar Y) +\\ \\sum_{i=1}^n (\\bar Y - \\mu)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\bar Y)^2 + \\ 2 (\\bar Y - \\mu) (\\sum_{i=1}^n Y_i - n \\bar Y) +\\ \\sum_{i=1}^n (\\bar Y - \\mu)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\bar Y)^2 + \\sum_{i=1}^n (\\bar Y - \\mu)^2\\\\ &amp; \\geq \\sum_{i=1}^n (Y_i - \\bar Y)^2 \\ \\end{align} \\] 通过原点的回归 最小化\\(\\sum_{i=1}^n (Y_i - X_i \\beta)^2\\) 两变量关系用回归线解释 8.2 术语 \\(X_1, X_2, \\ldots, X_n\\) 表示 \\(n\\) 个数据点 \\(Y_1, \\ldots , Y_n\\) 表示另外 \\(n\\) 个数据点 用希腊字母表示不知道的东西 如 \\(\\mu\\) 大写字母表示概念值 小写字母表示真实值 如 \\(P(X_i &gt; x)\\) \\(\\bar X = \\frac{1}{n}\\sum_{i=1}^n X_i\\) 表示均值 数据的中心趋向 \\(\\tilde X_i = X_i - \\bar X\\) 表示对数据中心化 均值为0 均值为数据的最小二乘估计 \\(S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar X)^2 = \\frac{1}{n-1} \\left( \\sum_{i=1}^n X_i^2 - n \\bar X ^ 2 \\right)\\) 表示方差 \\(S\\) 为标准差 数据的离散程度 \\(X_i / s\\) 表示数据缩放 方差为1 \\(Z_i = \\frac{X_i - \\bar X}{s}\\) 表示数据的标准化 先中心化再标准化 \\(Cov(X, Y) = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar X) (Y_i - \\bar Y)= \\frac{1}{n-1}\\left( \\sum_{i=1}^n X_i Y_i - n \\bar X \\bar Y\\right)\\) 表示协方差 \\(Cor(X, Y) = \\frac{Cov(X, Y)}{S_x S_y}\\) 表示相关性 \\(Cor(X, Y) = Cor(Y, X)\\) \\(-1 \\leq Cor(X, Y) \\leq 1\\) \\(Cor(X, Y)\\) 度量线性关系强度 \\(Cor(X, Y) = 0\\) 表示无线性关系 8.3 回归线的最小二乘回归 用最小二乘法寻找回归线 最小化 \\(\\sum_{i=1}^n \\{Y_i - (\\beta_0 + \\beta_1 X_i)\\}^2\\) 如果定义 \\(\\mu_i = \\beta_0\\) \\(\\hat \\beta_0 = \\bar Y\\) 不考虑其他变量 \\(Y\\) 的均值就是最小二乘估计 如果定义 \\(\\mu_i = X_i \\beta_1\\) \\(\\hat \\beta_1 = \\frac{\\sum_{i=1^n} Y_i X_i}{\\sum_{i=1}^n X_i^2}\\) 如果考虑过原点线的回归 斜率如上 如果考虑 \\(\\mu_i = \\beta_0 + \\beta_1 X_i\\) \\[\\begin{align} \\ \\sum_{i=1}^n (Y_i - \\hat \\mu_i) (\\hat \\mu_i - \\mu_i) = &amp; \\sum_{i=1}^n (Y_i - \\hat\\beta_0 - \\hat\\beta_1 X_i) (\\hat \\beta_0 + \\hat \\beta_1 X_i - \\beta_0 - \\beta_1 X_i) \\\\ = &amp; (\\hat \\beta_0 - \\beta_0) \\sum_{i=1}^n (Y_i - \\hat\\beta_0 - \\hat \\beta_1 X_i) + (\\beta_1 - \\beta_1)\\sum_{i=1}^n (Y_i - \\hat\\beta_0 - \\hat \\beta_1 X_i)X_i\\\\ \\end{align} \\] 解为\\(\\hat \\beta_1 = Cor(Y, X) \\frac{Sd(Y)}{Sd(X)} ~~~ \\hat \\beta_0 = \\bar Y - \\hat \\beta_1 \\bar X\\) 如果标准化数据 \\(\\{ \\frac{X_i - \\bar X}{Sd(X)}, \\frac{Y_i - \\bar Y}{Sd(Y)}\\}\\) 解为\\(Cor(Y, X)\\) 回归是因变量向自己均值回归与向自变量相关回归的平衡 8.4 统计线性回归模型 最小二乘是一种估计方法，做推断需要模型 建立线性回归的概率模型\\(Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_{i}\\) \\(\\epsilon_{i}\\) 为 iid \\(N(0, \\sigma^2)\\) \\(E[Y_i ~|~ X_i = x_i] = \\mu_i = \\beta_0 + \\beta_1 x_i\\) \\(Var(Y_i ~|~ X_i = x_i) = \\sigma^2\\) 对\\(N(\\mu_i, \\sigma^2)\\)独立变量 \\(Y\\) 进行极大似然估计 \\({\\cal L}(\\beta, \\sigma) = \\prod_{i=1}^n \\left\\{(2 \\pi \\sigma^2)^{-1/2}\\exp\\left(-\\frac{1}{2\\sigma^2}(y_i - \\mu_i)^2 \\right) \\right\\}\\) 取对数有 \\(-2 \\log\\{ {\\cal L}(\\beta, \\sigma) \\} = \\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\mu_i)^2 + n\\log(\\sigma^2)\\) 最小二乘估计就是极大似然估计 \\(\\hat \\beta_1 = Cor(Y, X) \\frac{Sd(Y)}{Sd(X)} ~~~ \\hat \\beta_0 = \\bar Y - \\hat \\beta_1 \\bar X\\) 截距是自变量为0时 \\(Y\\) 的期望 斜率是自变量变化一个单位对 \\(Y\\) 的影响 8.5 残差 模型 \\(Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\\) 预测值 \\(\\hat Y_i = \\hat \\beta_0 + \\hat \\beta_1 X_i\\) \\(e_i = Y_i - \\hat Y_i\\) 观察数据与回归线的垂直距离 最小二乘估计最小化残差 \\(\\sum_{i=1}^n e_i^2\\) 残差 \\(e_i\\) 可看作 \\(\\epsilon_i\\) 的估计 可证 \\(E[e_i] = 0\\) 模型中考虑截距 \\(\\sum_{i=1}^n e_i = 0\\) 考虑自变量 \\(\\sum_{i=1}^n e_i X_i = 0\\) 残差可用来评价模型效果 残差波动不同于模型波动 残差波动 \\(\\sigma^2\\) 的极大似然估计为 \\(\\frac{1}{n}\\sum_{i=1}^n e_i^2\\) \\(\\hat \\sigma^2 = \\frac{1}{n-2}\\sum_{i=1}^n e_i^2\\) 为无偏估计 \\[ \\begin{align} \\sum_{i=1}^n (Y_i - \\bar Y)^2 &amp; = \\sum_{i=1}^n (Y_i - \\hat Y_i + \\hat Y_i - \\bar Y)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\hat Y_i)^2 + 2 \\sum_{i=1}^n (Y_i - \\hat Y_i)(\\hat Y_i - \\bar Y) + \\sum_{i=1}^n (\\hat Y_i - \\bar Y)^2 \\\\ \\end{align} \\] 其中 \\((Y_i - \\hat Y_i) = \\{Y_i - (\\bar Y - \\hat \\beta_1 \\bar X) - \\hat \\beta_1 X_i\\} = (Y_i - \\bar Y) - \\hat \\beta_1 (X_i - \\bar X)\\) \\((\\hat Y_i - \\bar Y) = (\\bar Y - \\hat \\beta_1 \\bar X - \\hat \\beta_1 X_i - \\bar Y )= \\hat \\beta_1 (X_i - \\bar X)\\) 有\\(\\sum_{i=1}^n (Y_i - \\hat Y_i)(\\hat Y_i - \\bar Y) = \\sum_{i=1}^n \\{(Y_i - \\bar Y) - \\hat \\beta_1 (X_i - \\bar X))\\}\\{\\hat \\beta_1 (X_i - \\bar X)\\}=\\hat \\beta_1 \\sum_{i=1}^n (Y_i - \\bar Y)(X_i - \\bar X) -\\hat\\beta_1^2\\sum_{i=1}^n (X_i - \\bar X)^2= \\hat \\beta_1^2 \\sum_{i=1}^n (X_i - \\bar X)^2-\\hat\\beta_1^2\\sum_{i=1}^n (X_i - \\bar X)^2 = 0\\) 综上 \\(\\sum_{i=1}^n (Y_i - \\bar Y)^2 = \\sum_{i=1}^n (Y_i - \\hat Y_i)^2 + \\sum_{i=1}^n (\\hat Y_i - \\bar Y)^2\\) 有 Total Variation = Residual Variation + Regression Variation 模型解释部分\\(R^2 = \\frac{\\sum_{i=1}^n (\\hat Y_i - \\bar Y)^2}{\\sum_{i=1}^n (Y_i - \\bar Y)^2} = 1 - \\frac{\\sum_{i=1}^n (Y_i - \\hat Y_i)^2}{\\sum_{i=1}^n (Y_i - \\bar Y)^2}\\) 已知 \\((\\hat Y_i - \\bar Y) = \\hat \\beta_1 (X_i - \\bar X)\\) \\(\\hat \\beta_1 = Cor(Y, X)\\frac{Sd(Y)}{Sd(X)}\\) 有 \\(R^2 = \\frac{\\sum_{i=1}^n (\\hat Y_i - \\bar Y)^2}{\\sum_{i=1}^n (Y_i - \\bar Y)^2}= \\hat \\beta_1^2 \\frac{\\sum_{i=1}^n(X_i - \\bar X)^2}{\\sum_{i=1}^n (Y_i - \\bar Y)^2}= Cor(Y, X)^2\\) \\(R^2\\) 实际上是相关性 \\(r\\) 的平方 &lt;- 线性模型的可解释性 \\(R^2\\) 会伴随样本数增加而增加 会因删除异常值而增加 data(anscombe);example(anscombe) 8.6 回归推断 \\(\\frac{\\hat \\theta - \\theta}{\\hat \\sigma_{\\hat \\theta}}\\) 总符合正态分布或\\(t\\)分布 假设检验 \\(H_0 : \\theta = \\theta_0\\) 与 \\(H_a : \\theta &gt;, &lt;, \\neq \\theta_0\\) 置信区间 \\(\\theta\\) 通过 \\(\\hat \\theta \\pm Q_{1-\\alpha/2} \\hat \\sigma_{\\hat \\theta}\\) 构建 \\[ \\begin{align} Var(\\hat \\beta_1) &amp; = Var\\left(\\frac{\\sum_{i=1}^n (Y_i - \\bar Y) (X_i - \\bar X)}{\\sum_{i=1}^n (X_i - \\bar X)^2}\\right) \\\\ &amp; = \\frac{Var\\left(\\sum_{i=1}^n Y_i (X_i - \\bar X) \\right) }{\\left(\\sum_{i=1}^n (X_i - \\bar X)^2 \\right)^2} \\\\ &amp; = \\frac{\\sum_{i=1}^n \\sigma^2(X_i - \\bar X)^2}{\\left(\\sum_{i=1}^n (X_i - \\bar X)^2 \\right)^2} \\\\ &amp; = \\frac{\\sigma^2}{\\sum_{i=1}^n (X_i - \\bar X)^2} \\\\ \\end{align} \\] \\(\\sigma_{\\hat \\beta_1}^2 = Var(\\hat \\beta_1) = \\sigma^2 / \\sum_{i=1}^n (X_i - \\bar X)^2\\) \\(\\sigma_{\\hat \\beta_0}^2 = Var(\\hat \\beta_0) = \\left(\\frac{1}{n} + \\frac{\\bar X^2}{\\sum_{i=1}^n (X_i - \\bar X)^2 }\\right)\\sigma^2\\) 这样 \\(\\frac{\\hat \\beta_j - \\beta_j}{\\hat \\sigma_{\\hat \\beta_j}}\\) 遵守自由度为\\(n-2\\)的\\(t\\)分布或正态分布 在\\(x_0\\) 回归线的标准误 \\(\\hat \\sigma\\sqrt{\\frac{1}{n} + \\frac{(x_0 - \\bar X)^2}{\\sum_{i=1}^n (X_i - \\bar X)^2}}\\) 在\\(x_0\\) 预测值的标准误 \\(\\hat \\sigma\\sqrt{1 + \\frac{1}{n} + \\frac{(x_0 - \\bar X)^2}{\\sum_{i=1}^n (X_i - \\bar X)^2}}\\) CI代表回归线在特定\\(x\\)处的变动 PI代表预测值在此处的变动 前者在回归线固定时不变 后者还要考虑预测值围绕回归线的变动 The prediction interval is the range in which future observation can be thought most likely to occur, whereas the confidence interval is where the mean of future observation is most likely to reside. From here 8.7 多元回归 线性模型 \\(Y_i = \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\ldots + \\beta_{p} X_{pi} + \\epsilon_{i} = \\sum_{k=1}^p X_{ik} \\beta_j + \\epsilon_{i}\\) 最小化 \\(\\sum_{i=1}^n \\left(Y_i - \\sum_{k=1}^p X_{ki} \\beta_j\\right)^2\\) 最小二乘估计也是误差正态化的极大似然估计 最小二乘估计等价于 \\(\\sum_{i=1}^n (Y_i - X_{1i}\\hat \\beta_1 - \\ldots - X_{ip}\\hat \\beta_p) X_k = 0\\) 本质上使其他参数固定解出一个 然后逐级代入 最后全部解出参数值 参考线性代数 参数代表固定其他参数后变动一个单位引发的变化 方差估计 \\(\\hat \\sigma^2 = \\frac{1}{n-p} \\sum_{i=1}^n e_i ^2\\) 参数标准误\\(\\hat \\sigma_{\\hat \\beta_k}\\) \\(\\frac{\\hat \\beta_k - \\beta_k}{\\hat \\sigma_{\\hat \\beta_k}}\\) 符合自由度 \\(n-p\\) 的 \\(T\\) 分布 多元模型中加入变量会导致原有变量的参数估计发生变化 甚至方向相反 一般是由于加入变量与原有变量存在共相关 导致两者参数估计都不准 n &lt;- 100; x2 &lt;- 1 : n; x1 &lt;- .01 * x2 + runif(n, -.1, .1); y = -x1 + x2 + rnorm(n, sd = .01) summary(lm(y ~ x1))$coef summary(lm(y ~ x1 + x2))$coef R 会自动检测并消除变量生成的变量 如上面 x2 中需要加入 runif(n,-.1,.1) 才能得到结果 多元模型中包括分类变量考虑加入虚拟变量 \\(Y_i = \\beta_0 + X_{i1} \\beta_1 + \\epsilon_{i}\\) 属于该分类时 \\(E[Y_i] = \\beta_0 + \\beta_1\\) 否则为\\(E[Y_i] = \\beta_0\\) 分类变量截距有意义 代表其中一个分类 等同于其他分类与该分类进行 t 检验 如果模型中去掉截距 等同于所有分类与零进行 t 检验 参数系数为均值差 可用 relevel(data,'name') 来指定比对对象 两变量均值差的标准误通过 \\(Var(\\hat \\beta_B - \\hat \\beta_C) = Var(\\hat \\beta_B) + Var(\\hat \\beta_C) - 2 Cov(\\hat \\beta_B, \\hat \\beta_C)\\) 来计算进行推断 交互作用 \\(E[Y_i | X_{1i}=x_1, X_{2i}=x_2] = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\beta_3 x_{1}x_{2}\\) 中交互作用参数实际表示 \\(E[Y_i | X_{1i}=x_1+1, X_{2i}=x_2+1]-E[Y_i | X_{1i}=x_1, X_{2i}=x_2+1]-E[Y_i | X_{1i}=x_1+1, X_{2i}=x_2]-E[Y_i | X_{1i}=x_1, X_{2i}=x_2] =\\beta_3\\) 各交互参数变化一单位响应变化 多元回归的参数解释需要考虑清楚变量类型与交互作用 多元回归中变量与响应 变量与变量间的相关性要全盘考虑 通过模拟观察决定 8.8 模型诊断与选择 通过残差诊断 最小二乘决定均值为零 方差通过 \\(\\hat \\sigma^2 = \\frac{\\sum_{i=1}^n e_i^2}{n-p}\\) 进行无偏估计 异常值判断 对回归关系包括系数与其标准误的影响 残差的分布检验等 ?influence.measures There are known knowns. These are things we know that we know. There are known unknowns. That is to say, there are things that we know we don’t know. But there are also unknown unknowns. There are things we don’t know we don’t know. Donald Rumsfeld 随机化有助于平衡未知变量 杠杆点 加入前后与回归线距离差的比值 参数方差膨胀 共相关或随机相关 vif来检验 协变量在欠拟合下有偏 协变量的选择需要专业知识与经验 8.9 广义线性模型 Nelder 与 Wedderburn 1972年提出 响应是指数家族模型 模型组成部分是线性的 线性预测变量与响应通过连接函数联系 线性模型 \\(Y_i \\sim N(\\mu_i, \\sigma^2)\\) \\(\\eta_i = \\sum_{k=1}^p X_{ik} \\beta_k\\) \\(g(\\mu) = \\eta\\) 似然模型为 \\(Y_i = \\sum_{k=1}^p X_{ik} \\beta_k + \\epsilon_{i}\\) \\(\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma^2)\\) logistic 模型 \\(Y_i \\sim Bernoulli(\\mu_i)\\) \\(\\eta_i = \\sum_{k=1}^p X_{ik} \\beta_k\\) \\(g(\\mu) = \\eta = \\log\\left( \\frac{\\mu}{1 - \\mu}\\right)\\) \\(g\\)为logit函数 似然函数为 \\(\\prod_{i=1}^n \\mu_i^{y_i} (1 - \\mu_i)^{1-y_i} = \\exp\\left(\\sum_{i=1}^n y_i \\eta_i \\right) \\prod_{i=1}^n (1 + \\eta_i)^{-1}\\) 泊松模型 \\(Y_i \\sim Poisson(\\mu_i)\\) \\(\\eta_i = \\sum_{k=1}^p X_{ik} \\beta_k\\) \\(g(\\mu) = \\eta = \\log(\\mu)\\) 似然函数为 \\(\\prod_{i=1}^n (y_i !)^{-1} \\mu_i^{y_i}e^{-\\mu_i}\\propto \\exp\\left(\\sum_{i=1}^n y_i \\eta_i - \\sum_{i=1}^n \\mu_i\\right)\\) 似然函数与数据的联系 \\(\\sum_{i=1}^n y_i \\eta_i = \\sum_{i=1}^n y_i\\sum_{k=1}^p X_{ik} \\beta_k = \\sum_{k=1}^p \\beta_k\\sum_{i=1}^n X_{ik} y_i\\) 只有\\(\\sum_{i=1}^n X_{ik} y_i\\) 极大似然估计的解 \\(0=\\sum_{i=1}^n \\frac{(Y_i - \\mu_i)}{Var(Y_i)}W_i\\) \\(W_i\\)是连接函数的反函数的微分 响应的方差中线性模型 \\(Var(Y_i) = \\sigma^2\\) 是常数 logistic 模型 \\(Var(Y_i) = \\mu_i (1 - \\mu_i)\\) 泊松模型 \\(Var(Y_i) = \\mu_i\\) 可通过对模型方差增加调谐参数 \\(\\phi\\) 使模型更灵活 quasi-likelihood 模型求解为 \\(\\hat \\beta_k\\) 及可能的 \\(\\hat \\phi\\) 线性预测变量关系 \\(\\hat \\eta = \\sum_{k=1}^p X_k \\hat \\beta_k\\) 平均响应 \\(\\hat \\mu = g^{-1}(\\hat \\eta)\\) 系数解释 \\(g(E[Y | X_k = x_k + 1, X_{\\sim k} = x_{\\sim k}]) - g(E[Y | X_k = x_k, X_{\\sim k}=x_{\\sim k}]) = \\beta_k\\) 8.10 二元响应 \\(\\log\\left(\\frac{\\rm{Pr}(RW_i | RS_i, b_0, b_1 )}{1-\\rm{Pr}(RW_i | RS_i, b_0, b_1)}\\right) = b_0 + b_1 RS_i\\) \\(b_0\\) 预测变量为零时胜率对数 \\(b_1\\) 预测变量变化一个单位胜率的改变对数 \\(\\exp(b_1)\\) 预测变量变化一个单位胜率的改变 8.11 计数或速率响应 \\(\\log\\left(E[NH_i | JD_i, b_0, b_1]\\right) = b_0 + b_1 JD_i\\) \\(e^{E[\\log(Y)]}\\) \\(Y\\) 的几何平均值 \\(e^{\\beta_0}\\) 第零天的几何平均值 \\(e^{\\beta_1}\\) 每天相对增加或减少的几何平均值 通过设置 offset 可用来估计增长率 注意方差膨胀与零膨胀问题 8.12 分段平滑 可用线性回归拟合曲线 原理是分段拟合连接 断点平滑可用二次项 分段项可看作基进行组合 "],
["section-9.html", "笔记 9 机器学习实战 9.1 研究设计 9.2 错误率 9.3 ROC 曲线 9.4 交叉检验 9.5 caret 包 9.6 数据分割 9.7 训练选项 9.8 预测变量作图 9.9 数据预处理 9.10 协变量生成 9.11 线性回归&amp;多元线性回归 9.12 树 9.13 Bagging 9.14 radom forest 9.15 boosting 9.16 其他预测算法 9.17 模型联合 9.18 无监督预测 9.19 预测", " 笔记 9 机器学习实战 问题 -&gt; 数据 -&gt; 特征 -&gt; 算法 -&gt; 参数 -&gt; 评价 The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. John Tukey 数据质量优先于模型 不要自动特征选择 算法的可扩展性与计算性能要考虑 数据过拟合问题 数据总是由信号与噪音组成 但会被算法无差别对待 数据要与问题相关 低相关度的组合可能产生高相关度 9.1 研究设计 定义错误率 将数据分割为训练集 预测集 验证集 在训练集上使用交叉检验选择特征与预测算法 在预测集或验证集上使用一次数据 预测效果起码要优于瞎猜 避免使用小样本 比例为 60% 训练集 20% 预测集 20% 验证集 或 60% 训练集 40% 预测集 或小样本交叉检验 注意数据结构 时序分析要对数据分段采样 9.2 错误率 真阳性 真的是对的 TP 假阳性 真的是错的 FP Type I 真阴性 假的是错的 TN 假阴性 假的是对的 FN Type II 灵敏度 TP/(TP+FP) 特异性 TN/(TN+FN) 均方差 MSE \\(\\frac{1}{n} \\sum_{i=1}^n (Prediction_i - Truth_i)^2\\) 均方误 RMSE \\(\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(Prediction_i - Truth_i)^2}\\) 中位差 Median absolute deviation 准确性 (TP+TN)/(TP+FP+TN+FP) 一致性 kappa值 9.3 ROC 曲线 分类问题寻找判别阈值 满足一定TP下最小FP的模型 FP v.s.TP 作图 AUC 曲线下面积表示选择标准 一般超过80% 对角线是随机猜的结果 9.4 交叉检验 训练集上的操作 训练集上再分为训练集与测试集 在测试集上评价 重复并平均化测试集错误 用来进行变量 模型 参数选择 随机 分组 留一 分组多方差大 分组少有偏差 有放回的为bootstrap 不建议用 9.5 caret 包 数据清洗 预处理 数据分割 createDataPartition 数据比例 重采样 产生时间片段 训练检验整合函数 train predict 模型对比 算法整合为选项 线性判别 回归 朴素贝叶斯 支持向量机 分类与回归树 随机森林 Boosting 等 9.6 数据分割 train &lt;- createDataPartition(y=spam$type,p=0.75, list=FALSE) 数据三一分 得到index folds &lt;- createFolds(y=spam$type,k=10,list=TRUE,returnTrain=TRUE) 数据分10份 返回每一份列表 folds &lt;- createResample(y=spam$type,times=10,list=TRUE) 数据bootstrap重采样 返回每一份列表 folds &lt;- createTimeSlices(y=tme,initialWindow=20,horizon=10) 时序数据重采样 产生20为窗口时序片段的训练集与预测集 9.7 训练选项 args(train.default) 通过 method 控制算法 metric 控制算法评价 trainControl 控制训练方法 trainControl中 method选择模型选择方法 如bootstrap 交叉检验 留一法 number 控制次数 repeats 控制重采样次数 seed 控制可重复性 总体设置一个 具体每一次用列表设置控制具体过程 特别是并行模型 9.8 预测变量作图 featurePlot ggplot2 9.9 数据预处理 train 中的 preProcess=c(&quot;center&quot;,&quot;scale&quot;) 标准化 spatialSign 该转化可提高计算效率 有偏 preProcess(training[,-58],method=c(&quot;BoxCox&quot;)) 正态化转化 method=&quot;knnImpute&quot; 用最小邻近法填补缺失值 nearZeroVar 去除零方差变量 findCorrelation 去除相关变量 findLinearCombos 去除线性组合变量 classDist 测定分类变量的距离 生成新变量 测试集也要预处理 9.10 协变量生成 原始数据提取特征 提取特征后生成新变量 因子变量要转为虚拟变量 样条基变量 splines 包中的 bs 数据压缩 preProcess 中 method 设置为 pca pcaComp 指定主成分个数 9.11 线性回归&amp;多元线性回归 \\(ED_i = b_0 + b_1 WT_i + e_i\\) 基本模型 参见前面回归部分 9.12 树 迭代分割变量 在最大化预测时分割 评估分支的同质性 多个树的预测更好 优点 容易解释应用 可用在神经网络上 缺点 不容易交叉验证 不确定性不宜估计 结果可能变化 -算法 先在一个组里用所有的变量计算 寻找最容易分离结果的变量 把数据按照该变量节点分为两组 在每一个组中寻找最好的分离变量 迭代直到过程结束 节点纯度用 Gini 系数或 交叉墒来衡量 rattle 包的 fancyRpartPlot 出图漂亮 可用来处理非线性模型与变量选择 9.13 Bagging 重采样 重新计算预测值 平均或投票给出结果 减少方差 偏差类似 适用于非线性过程 bagged trees 重采样 重建树 结果重评价 更稳健 效果不如RF Bagged loess 可用来处理细节 9.14 radom forest bootstrap采样 每一个节点bootstrap选取变量 多棵树投票 准确度高 速度慢 不好解释 容易过拟合 9.15 boosting 弱预测变量加权后构建强预测变量 从一组预测变量开始 添加有惩罚项的预测变量来训练模型 以降低训练集误差为目的 通用方法 9.16 其他预测算法 参考统计学习导论笔记 9.17 模型联合 通过平均与投票结合模型 联合分类器提高准确率 caretEnsemble 包 案例 广义加性模型 library(ISLR); data(Wage); library(ggplot2); library(caret); Wage &lt;- subset(Wage,select=-c(logwage)) # Create a building data set and validation set inBuild &lt;- createDataPartition(y=Wage$wage,p=0.7, list=FALSE) validation &lt;- Wage[-inBuild,]; buildData &lt;- Wage[inBuild,] inTrain &lt;- createDataPartition(y=buildData$wage,p=0.7, list=FALSE) training &lt;- buildData[inTrain,]; testing &lt;- buildData[-inTrain,] mod1 &lt;- train(wage ~.,method=&quot;glm&quot;,data=training) mod2 &lt;- train(wage ~.,method=&quot;rf&quot;,data=training,trControl = trainControl(method=&quot;cv&quot;),number=3) pred1 &lt;- predict(mod1,testing); pred2 &lt;- predict(mod2,testing) qplot(pred1,pred2,colour=wage,data=testing) predDF &lt;- data.frame(pred1,pred2,wage=testing$wage) combModFit &lt;- train(wage ~.,method=&quot;gam&quot;,data=predDF) combPred &lt;- predict(combModFit,predDF) sqrt(sum((pred1-testing$wage)^2)) sqrt(sum((pred2-testing$wage)^2)) sqrt(sum((combPred-testing$wage)^2)) 9.18 无监督预测 先聚类 后预测 clue 包 cl_predict 函数 推荐系统 9.19 预测 时序数据 包含趋势 季节变化 循环 效应分解 decompose window 窗口 ma 平滑 ets 指数平滑 forecast 预测 空间数据同样有这种问题 临近依赖 地域效应 quantmod 包 或 quandl 包处理金融数据 外推要谨慎 "],
["section-10.html", "笔记 10 开发数据产品 10.1 shiny 10.2 rCharts 10.3 GoogleVis 10.4 Slidify 10.5 Rpresentation 10.6 yhat 10.7 R 包开发 10.8 R 中方法与类型", " 笔记 10 开发数据产品 10.1 shiny 源自 R-studio 动态网络应用 入门版 OpenCPU 高级版 Manipulate install.packages(&quot;shiny&quot;);libray(shiny) ui.R 控制外观 sever.R 控制计算 runApp() 启动应用 sever.R 中 shinyServer 之前的代码只在启动应用时执行一次 适合读入数据 shinyServer(function(input, output){ 之内的非互动函数只被每个用户执行一次 Render* 为互动函数 数值改变就执行一次 runApp(display.mode='showcase') 可用来同时高亮显示执行代码 reactive 用来加速互动函数外的信息交换 actionButton 用来一次提交输入数据 if (input$goButton == 1){ Conditional statements } 用来定义条件语句 cat browser() 调试 fluidRow 产生表格 10.2 rCharts 主页 动态交互可视化工具 require(devtools);install_github('rCharts', 'ramnathv') 10.3 GoogleVis 主页 R 代码产生图表 生成html install.packages('googleVis');library(googleVis) 教程 10.4 Slidify 主页 html5 幻灯片 install.packages(&quot;devtools&quot;);library(devtools);install_github('slidify', 'ramnathv');install_github('slidifyLibraries', 'ramnathv');library(slidify) author(&quot;yufree&quot;) YAML 配置幻灯片结构 ## 幻灯片开始 --- 加空行表结束 .class #id 自定义css文件id slidify(&quot;index.Rmd&quot;) 生成 browseURL(&quot;index.html&quot;) 观看 publish_github(user, repo) github发布 10.5 Rpresentation 源自 R-studio 轻量级幻灯片 教程 10.6 yhat 主页 本地提交算法或模型 生成可调用API 支持R与python 10.7 R 包开发 DESCRIPTION 指明包内容 Package 包名字 Title 全名 Description 一句话描述 Version 版本号 Author 作者 Maintainer 维护者 License 许可协议 Depends 依赖 Suggests 建议 Date 发布日期 YYYY-MM-DD 格式 URL 项目主页 R 源码 Documentation 文档 Rd文件 NAMESPACE 关键词 输入输出的函数及类型 R CMD build/check newpackage 构建 检查包 roxygen2 源文件注释文档 10.8 R 中方法与类型 R 面向对象编程 对象用setClass指定类型 用setMethod指定处理类型的方法 对象一般指新的数据类型 S3函数对象不算严格 generic处理对象 开放 没有指定类型就用通用方法 S4函数对象定义严格 只处理指定类型对象 不可直接调用方法 针对性强 stats4 有很多针对性的极大似然估计的对象定义与方法 "],
["section-11.html", "笔记 11 统计学习导论 11.1 导论 11.2 统计学习 11.3 线性回归 11.4 分类 11.5 重采样技术 11.6 线性模型选择与正则化 11.7 非线性 11.8 决策树 11.9 支持向量机 11.10 无监督学习", " 笔记 11 统计学习导论 11.1 导论 11.1.1 统计学习概论 统计学习：理解数据的工具集 监督学习：有因变量，根据自变量预测估计因变量 非监督学习：无因变量，探索自变量间的关系与结构 11.1.2 统计学习简史 19世纪初，Legendre 与 Gauss 发表了最小二乘法的论文，该方法首先应用在天文学领域 1936年，Fisher 提出线性判别分析来解决定性分析问题 1940s，logistic回归提出 1970s，Nelder 与 Wedderburn 提出广义线性模型，将线性回归与logistic回归统一到一个体系 1980s，计算机技术进步，非线性问题开始得到解决 Breiman，Friedman，Olshen 与 Stone 提出回归树与聚类，提供交叉检验方法 1986年，Hastie 与 Tibshirani 提出广义加性模型，将广义线性模型与一些非线性模型同一到一个体系 伴随软件，机器学习与其他理论的发展，统计学习作为统计学子学科快速发展 11.2 统计学习 11.2.1 统计学习定义 \\(Y = f(X) + \\epsilon\\) 统计学习本质上是在寻找最合适的f来进行预测与推断 11.2.2 预测 \\(\\hat Y = \\hat f(X)\\)，\\(\\hat f(X)\\) 通常看作黑箱 \\(\\hat Y\\)预测\\(Y\\)需要考虑两部分误差：可约误差与不可约误差 可约误差指\\(\\hat f\\)推断\\(f\\)上的偏差 不可约误差指由\\(\\epsilon\\)引入的误差 误差的期望 \\(E(Y - \\hat Y)^2 = [f(x) - \\hat f(x)]^2 + Var(\\epsilon)\\) (证明用到\\(E(Y)\\)) 11.2.3 推断 关注X与Y的关系，\\(\\hat f(X)\\) 通常有明确的形式 自变量因变量是否相关 如何相关 关系的数学描述 11.2.4 估计f 使用训练集与验证集 参数方法与非参数方法 模型的欠拟合与过拟合 权衡模型的准确性（预测）与可解释性（推断） 模型的奥卡姆剃刀与黑箱 11.2.5 评价模型 11.2.5.1 拟合质量测量 训练集均方误 \\(MSE_{Tr} = Ave_{i \\in Tr}[y_{i} − \\hat f(x_i)]^2\\) 测试集均方误 \\(MSE_{Te} = Ave_{i \\in Te}[y_{i} − \\hat f(x_i)]^2\\) 测试集均方误源于训练集拟合模型的方差，误差项\\(\\epsilon\\)的方差及模型误差的平方三部分 11.2.5.2 聚类评价 错误率 \\(Err_{Te} = Ave_{i \\in Te}I[y_i \\neq \\hat C(x_i)]\\) 贝叶斯分类器：错误率最小的分类器，使x属于某个分类的概率最大 k临近值聚类：距离最小的k个为一类所产生的分类器 11.3 线性回归 11.3.1 简单线性回归 \\(Y \\approx \\beta_0 + \\beta_1 X\\) 用最小二乘法估计\\(\\beta_0\\)与\\(\\beta_1\\)得到估计值\\(\\hat \\beta_0\\)与\\(\\hat \\beta_1\\)，代入\\(X\\)，得到模型估计值\\(\\hat Y\\) 残差平方和：\\(RSS = e_1^2 + e_2^2 + ... + e_n^2\\)，使RSS最小，求导可得参数 回归线不等于最小二乘线，最小二乘线是通过采样对回归线的估计 估计会存在偏差，均值的偏差用标准误来描述\\(Var(\\hat \\mu) = SE(\\mu)^2 = \\frac{\\sigma^2}{n}\\) 回归参数的估计也涉及标准误的计算\\(Var(\\beta_{1}) = \\frac{\\sigma^2}{\\sum_{i=1}^n{(x_i - \\bar{x})^2}}\\) \\(\\sigma^2\\)可用残差标准误RSE(\\(RSE = RSS/(n − 2)\\))来估计\\(\\qquad\\hat\\sigma^2 = \\frac{n-p}{n}\\;s^2\\) 据此可得回归参数的95%置信区间\\(\\hat \\beta_1 ± 2 \\cdot SE(\\hat \\beta_1)\\) 参数的评价可通过假设检验进行，零假设为\\(\\beta_1\\)为0，也就是自变量对因变量无影响，构建t统计量\\(t = \\frac{\\hat \\beta_1 - 0}{\\hat {SE}(\\hat \\beta_1)}\\)，然后可根据p值判断参数的显著性 评价参数后需要评价模型，主要通过\\(RSE\\)与\\(R^2\\)来进行 \\(R^2\\)表示模型所解释总体方差的比例，与\\(RSE\\)不同，独立于Y，\\(R^2 = \\frac{TSS - RSS}{TSS}\\) \\(R^2\\)与两变量间的相关系数是一致的，但\\(R^2\\)统计量的应用面要广于相关系数 相关系数也可进行假设检验进而判断相关的显著性 11.3.2 多元线性回归 通过统计量F检验确定回归是否显著，零假设为所有自变量系数为0 \\(F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)}\\) 变量选择：向前选择（从0个到p个，显著则包含），向后选择（从p个到0个，不显著则剔除），混合选择（通过p的阈值调节） 因为RSS会减少，\\(R^2\\)会伴随自变量数目的增加而增加 \\(RSE\\)在多元线性线性回归中为\\(RSE = RSS/(n − p - 1)\\)，伴随自变量个数增加影响超过\\(RSS\\)减少的影响，\\(RSE\\)会增大 自变量间的影响会导致相比单一变量预测更容易出现不显著，这说明自变量间有可能可相互解释 预测的置信区间与预测区间，前者指模型的变动范围，后者指某个预测值的变动范围，考虑真值本身的变动，后者大于前者 因子变量通过对每个水平添加系数0，1来回归，也可根据需要赋值 11.3.3 线性模型延拓 线性模型基本假设：可加性与线性 去掉可加性：考虑交互作用 层级原理：交互作用项显著而主作用不显著时不可去掉主作用项 去掉线性：多项式回归 11.3.4 常见问题 关系非线性：残差图判断 误差项共相关：误差项的相关会导致标准误估计偏低，低估参数的区间使不显著差异变得显著，考虑时间序列数据，观察误差项轨迹判断 误差项方差非常数：喇叭状残差图，通过对因变量进行对数或开方来收敛方差，或者用加权最小二乘 异常值：通过标准化残差图判断 杠杆点：加入后会影响模型拟合，通过杠杆统计量判断： \\(h_i = \\frac{1}{n} + \\frac{(x_i - \\bar x)^2}{\\sum_{i&#39; = 1}^{n} (x_i&#39; - \\bar x)^2}\\) 多元回归中该统计量均值为\\((p+1)/n\\)，超过很多则可能为杠杆点 在标准残差-杠杆值图中，右上或右下方为危险值，左方数值对回归影响不大 共线性：共线性的变量相互可替代，取值范围扩大，标准误加大，对因变量影响相互抵消，降低参数假设检验的功效 多重共线性：引入方差膨胀因子，自变量引入全模型与单一模型方差的比值，超过5或10说明存在共相关，\\(VIF(\\hat \\beta_j) = \\frac{1}{1 - R^2_{X_j|X_{-j}}}\\) 解决共线性：丢弃变量或合并变量 共线性不同于交互作用 11.3.5 线性回归与k临近算法比较 k临近算法：\\(\\hat f(x_0) = \\frac{1}{K} \\sum_{x_i \\in N_0} y_i\\) 核心是选择k KNN算法在解决非线性问题上有优势，但一样的面对高维诅咒 线性回归可给出可解释的形式与简单的描述 11.4 分类 11.4.1 logistic回归 因变量以概率形式出现 \\(p(X) = \\frac {e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}\\) 变形后\\(\\frac {p(X)}{1 - p(X)}\\) 为胜率，比概率应用更实际些，去对数后为对数胜率（logit） 因变量\\(p(X)\\)与自变量间关系非线性 用极大似然估计确定参数，似然函数为\\(l(\\beta_0, \\beta_1) = \\prod_{i:y_i = 1} p(x_i)\\prod_{i&#39;:y_{i&#39;} = 0} (1 - p(x_{i&#39;}))\\)，该函数取最大值 线性回归中，最小二乘法为极大似然估计的特例 混杂因素的解释上要考虑单因素回归与多元回归 多响应logistic回归一般被判别分析取代 11.4.2 线性判别分析 使用原因：分类离散时logistic回归不稳定，n小X正态时更稳定，适用于多响应 贝页斯理论：\\(Pr(Y = k|X = x) = \\frac{\\pi_k f_k(x)}{\\sum_{l = 1}^K \\pi_lf_l(x)}\\) 其中\\(\\pi\\) 代表先验概率，估计\\(f_k(X)\\)需要对\\(x\\)的分布作出假设 自变量为1时，假定\\(f_k(x)\\)分布为正态的，有\\(f_k(x) = \\frac{1}{\\sqrt{2 \\pi} \\sigma_k} exp(- \\frac{1}{2 \\sigma_k^2} (x - \\mu_k)^2)\\)，代入可得\\(p_k(x)\\)，取对数有\\(\\sigma_k(x) = x \\cdot \\frac{\\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2\\sigma^2} + log(\\pi_k)\\)，使\\(\\sigma_k(x)\\)最大的分类方法为判定边界 贝页斯分类器需要知道所有分布参数，实际中会采用线性判别分析（LDA），通过以下训练集估计方法来插入贝页斯分类器：\\(\\hat \\pi_k = n_k/n\\)、\\(\\hat \\mu_k = \\frac{1}{n_k} \\sum_{i:y_i = k} x_i\\) 与 \\(\\hat \\sigma^2 = \\frac{1}{n - K} \\sum_{k = 1}^K \\sum_{i:y_i = k} (x_i - \\hat \\mu_k)^2\\) 线性体现在判别函数\\(\\hat \\sigma_k(x)\\)的形式是线性的 自变量多于1时，假设自变量均来自多元正态分布的分类 列连表，表示假阳性，假阴性，可计算灵敏度与特异性 LDA是对贝页斯分类的模拟，旨在降低总错误率，因此灵敏度与特异性区分并不明显，可根据实际需要调节 ROC曲线用来展示两种错误，横坐标假阳性，纵坐标真阳性 11.4.3 二次判别分析（QDA）及其它 不同于LDA，二次判别分析考虑各分类参数中方差不同而不是相同，引入了二次项 对分类描述更为精细，但容易过拟合，样本较少，LDA优先 对比logistic回归，两者数学形式相近，取值上logistic回归使用极大似然法，LDA使用共方差的高斯分布假设，结论多数条件一致，但随假设不同而不同 KNN更适用于非线性关系，标准化很有必要，QDA相对温和 11.5 重采样技术 11.5.1 交叉检验 核心思想：通过保留一部份训练集数据作为检验集来估计真实检验集的错误率与模型拟合效果 验证集方法：将训练集数据分为两部分，一部份拟合模型，一部份检验模型，这样得到的错误率为真实检验集的一个估计，选取错误率较低的模型建模 验证集方法缺点：错误率依赖于采样变动较大，训练集少，低估了错误率 留一法(LOOCV)：每次建模留一个数据点作为验证集，\\(MSE_i = (y_i - \\hat y_i)^2\\)重复n次，得到一个CV值作为对错误率的估计:\\(CV_{(n)} = \\frac{1}{n} \\sum_{i = 1}^{n} MSE_i\\) 留一法优点：使用数据量大，偏差小；结果唯一，不受随机化影响 留一法缺点：计算量大，公式插入杠杆统计量调节杠杆点对方程拟合的影响，得到\\(CV_{(n)} = \\frac{1}{n} \\sum_{i = 1}^{n} (\\frac{y_i - \\hat y_i}{1 - h_i})^2\\) k叠交叉检验：将训练集分为k叠，每次建模用(k-1)叠，用1叠检验 k叠交叉检验优点：计算量小，结果与留一法相差不多- 交叉检验的结果用来寻找\\(CV\\)值最小的点来选择模型，通常与真实检验集最小点结果相差不大乎，但交叉检验给出的\\(MSE\\)会偏低 偏差方差权衡：使用的训练集数据越多，估计偏差越小，方差越大（相关性越高的方差越大） 分类问题使用错误率计算\\(CV\\)：\\(CV{(n)} = \\frac{1}{n} \\sum_{i = 1}^{n} Err_{i}\\) 少n多p问题上使用交叉检验，不可先进行全模型变量选择再交叉检验，应该对整个过程交叉检验 11.5.2 bootstrap 在训练集里有放回的重采样等长的数据形成新的数据集并计算相关参数，重复n次得到对参数的估计，计算标准误 生成Bootstrap Percentile置信区间 适用于独立样本，样本间有相关如时间序列数据可采用block法分组屏蔽掉进行bootstrap 因为存在重复，使用bootstrap建立训练集与预测集会有非独立样本，造成检验集模型方差的低估，去掉重复使模型复杂，不如交叉检验对检验集误差估计的准 11.6 线性模型选择与正则化 最小二乘法（OLS）容易解释，预测性能好，但不万能 预测准确性上，当p&gt;n时，模型方差变大 模型解释上，p过多需要去除，进行模型选择 11.6.1 模型选择方法 11.6.1.1 子集选择 从p个自变量中选出与模型响应相关的进行建模 使用devianc，最大化为最优子集 最佳子集选择：p个自变量\\(p \\choose k\\) ，计算\\(RSS\\)与\\(R^2\\)，\\(RSS\\)要小，\\(R^2\\)要大，选择最佳的 步进法：p值过大，计算负担重，采用逐步改进法进行模型选择 向前步进选择：从0个自变量开始加，第k个自变量选择p-k个模型，如果\\(RSS\\)与\\(R^2\\)表现好就保留，递近选择变量，不保证选择最佳模型，p值较大优先考虑 向后步进选择：从p个自变量开始减，如果第k个自变量在模型\\(RSS\\)与\\(R^2\\)中没表现，就剔除进行变量选择，不保证选择最佳模型，适用于p值较小的情况(较大可能无法拟合) 步进选择构建\\(1 + p(p+1)/2\\)个模型，最佳子集法需要构建\\(2^p\\)个模型 混合模型:向前选择，之后向后验证，剔除不再提高效果的模型 11.6.1.2 测试集误差估计 \\(RSS\\)与\\(R^2\\)评价的是训练集拟合状况，不适用于估计测试集误差 估计测试集误差可以构建统计量调节训练集误差或直接通过验证集来估计 Mallow’s \\(C_p\\)：\\(C_p = \\frac{1}{n} (RSS + 2d\\hat \\sigma^2)\\) \\(d\\)代表使用的变量数，\\(\\hat \\sigma^2\\)是对模型方差的估计 AIC：\\(AIC = -2logL + 2 \\cdot d\\) 极大似然估计，线性模型下\\(C_p\\)与AIC实质等同 BIC：\\(BIC = \\frac{1}{n}(RSS + log(n)d\\hat \\sigma^2)\\) n是样本数，大于7时BIC会比\\(C_p\\)选择更轻量的模型 调节\\(R^2\\)：\\(Adjusted\\) \\(R^2 = 1 - \\frac{RSS/n-d-1}{TSS/(n - 1)}\\) 值越大，测试集误差越小 不同于\\(C_p\\)，AIC，BIC有严格的统计学意义，调节\\(R^2\\)虽然直观，但理论基础相对薄弱，单纯考虑了对无关变量的惩罚 验证与交叉验证：直接估计测试集误差而不用估计模型方差 单标准误原则：先计算不同规模测试集\\(MSE\\)的标准差，选择曲线中最小测试集误差一个标准误内最简单的模型 11.6.1.3 收缩 对系数估计进行收缩，接近0或等于0进行变量选择 11.6.1.3.1 岭回归 不同于最小二乘估计对\\(RSS\\)的最小化，岭回归最小化\\(RSS + \\lambda \\sum_{j = 1}^{p} \\beta_j^2\\)，其中\\(\\lambda\\)为调谐参数，后面一项为收缩惩罚，是个\\(l_2\\)范数，使参数估计逼近0，选择合适\\(\\lambda\\)很重要，可用交叉检验来实现 因为范数大小影响模型惩罚项，所以进行岭回归前要做标准化处理\\[\\bar x_{ij} = \\frac{x_{ij}}{\\sqrt{\\frac{1}{n} \\sum_{i = 1}^n (x_{ij} - \\bar x_j)^2}}\\] 岭回归的参数\\(\\lambda\\)与范数收缩状况可看作最小\\(MSE\\)的函数来表现偏差-误差均衡 岭回归适用于最小二乘回归产生方差较大的情况，同时，计算负担较小，只伴随\\(\\lambda\\)取值范围变化而变化 11.6.1.3.2 Lasso 形式与岭回归一致，最小化\\(RSS + \\lambda \\sum_{j = 1}^{p} |\\beta_j|\\)，使用\\(l_1\\)范数 岭回归参数同步收缩接近0，Lasso可以通过软边界直接收缩到0实现变量选择，产生稀疏模型，想像超球体与超多面体与超球面的接触 贝页斯视角下，岭回归与lasso关于线性模型系数的先验分布是不同的：前者为高斯分布，接近0时平坦，后验概率等同最优解；后者为拉普拉斯分布，接近0时尖锐，先验概率系数接近0，后验概率不一定为稀疏向量 岭回归与Lasso分别适用于真实模型自变量多或少的情况，并不广谱，考虑交叉检验来进行选择 交叉检验也可用来选择\\(\\lambda\\), 通过选择的自变量参与建模 11.6.2 降维 前提是自变量间不独立，将p个自变量向量投影到M维空间(M &lt; p)，使用投影M拟合线性回归模型 \\(\\sum_{m = 1}^{M}\\theta_m z_{im} = \\sum_{m = 1}^{M} \\theta_m \\sum_{j = 1}^{p} \\phi_{jm}x_{ij} = \\sum_{j = 1}^p \\sum_{m = 1}^{M} \\theta_m \\phi_{jm} x_{ij} = \\sum_{j = 1}^{p} \\beta_j x_{ij}\\) 主成分：各自变量在主成分方向上方差最大 主成分回归(PCA)：实际为无监督算法，得到主成分后作为新变量进行最小二乘回归，认为因变量与自变量变异最大的方向一致，需要仔细检验这个假设，主成分个数的选择影响模型效果 岭回归疑似为主成分回归的连续版，两者都需要标准化，效果也相近 偏最小二乘(PLA)：第一个投影方向为因变量与自变量回归方向，后续投影是对残差投影方向的回归，重复得到监督学习的效果 PLA通常并不比PCA更好，引入了监督算法提高了偏差 11.6.3 高维数据 n远远少于p或接近的数据 最小二乘估计在n小于p时残差为0，太过精细 \\(C_p\\)，AIC，BIC方法因为有参数\\(\\hat \\sigma^2\\)需要估计，而这个参数会在高维数据下变成0，调节\\(R^2\\)也会变成1 高维诅咒：正则化或收缩对高维方法产生影响，合适调谐参数十分重要，测试集误差必然增长 引入新变量会对预测产生不可知影响，选出的自变量并非不可替代，结果用独立验证集误差或交叉检验误差描述 11.7 非线性 11.7.1 多项式回归 模型基本形式为单一自变量在不同幂指数下的多项式，最小二乘拟合 模型在特定点的方差受系数方差与协方差影响，幂越高，模型越精细，方差越大 幂次一般不超过3或4 可进行logistic回归 11.7.2 阶梯函数 阶梯函数将自变量由连续变成有序分类变量 函数形式为引入指标函数\\(C_K(x)\\)进行自变量分段，然后进行最小二乘拟合 依赖找间隔点 可进行logistic回归 11.7.3 基函数 固定线性系数\\(\\beta\\),自变量的形式由\\(b(x)\\)决定，\\(b(x)\\)为基函数 多项式回归与阶梯函数均为基函数的特例 11.7.4 回归样条 设定分段点，分段点前后进行多项式回归 K个点分割(K+1)段，存在(K+1)个多项式回归，自由度过高 进行边界约束，对n次方程而言，约束分段点0阶，1阶，2阶导数连续，减少3个自由度，共有K个点，则有\\((n+1-3)k + n + 1\\)个自由度，相比无约束的\\((n+1)k\\)，自由度减少，更稳健 一般而言约束限制为(自由度-1)阶连续，这样自由度比分界点略多些，够用 分段样条最好在两端加入线性限制，收敛自由度，这样在边界稳健，为自然样条 分段点位置一般均匀分布，个数（本质上是自由度）通过交叉检验来确定 分段多项式回归限定了自由度，因此结果一般比多项式回归更稳定 11.7.5 平滑样条 如果以RSS衡量不加入限制，很容易产生过拟合，因此考虑加入平滑项 最小化 \\[ \\sum_{i = 1}^n (y_{i} - g(x_i))^2 + \\lambda \\int g&#39;&#39;(t)^2 dt \\] 其中，\\(g(x)\\)为平滑样条，由损失函数与惩罚项组成，二次导数表示在t处的平坦度，越平坦，惩罚越小，越崎岖，惩罚越大，因而平滑 对三次函数而言，平滑样条会将函数两端收敛的跟自然样条一样，实际上，平滑样条是自然样条的收缩版 参数\\(\\lambda\\)也影响平滑效果，越大越平滑，因为k固定，只涉及\\(\\lambda\\)的选择 参数\\(\\lambda\\)的选择基于有效自由度，可以用留一法进行估计，形式与杠杆点统计量差不多，可以很方便的进行数值求解 平滑样条的自由度比多项式要小，更稳健 11.7.6 本地回归 首先分段，然后分段内进行加权回归，离某点越近，权重越高，进行最小二乘拟合，得到每个点的函数，联合模型拟合 自变量较多，可考虑本地有选择的选取自变量进行本地回归 同样遭受高维诅咒带来的临近值少或稀疏问题 11.7.7 广义加性模型 \\[y_i = \\beta_0 + \\sum_{i = 1}^n f_j(x_{ij}) + \\epsilon\\] 每个自变量都有自己的函数形式，加合求解 每个自变量影响都可以展示 可分段，也可使用平滑，平滑方法中使用了反馈拟合策略对不易用最小二乘拟合求解的问题进行求解，效果差不多，分段不必要 可用于分类回归问题，解释性好 优点：非线性，更准确，易解释，可进行统计推断，可用自由度衡量平滑性 缺点：不易考虑交互影响 11.8 决策树 11.8.1 回归树 将因变量按自变量分区间，每个区间内预测值一致，直观易解释 \\(\\sum_{j = 1}^J\\sum_{i \\in R_J}(y_i - \\hat y_{R_j})^2\\) 计算困难，使用自上而下的贪心算法 递归二元分割：构建树过程每个节点都选最佳分割点，也就是分割后残差最小的变量与数值 算法在叶样本数为5时结束 树修剪，选择训练集误差最小的子树，引入调谐因子\\(\\alpha\\) 最小化\\(\\sum_{m = 1}^{|T|} \\sum_{i:x_i \\in R_m} (y_i - \\hat y_{R_m})^2 + \\alpha|T|\\) 类似lasso算法 确定，之后选出特定模型 11.8.2 分类树 因变量为分类变量，RSS用分类错误率代替 \\(E = 1 - max_k(\\hat p_{mk})\\)但分类错误率对树生长并不敏感，应采用其他指标 Gini系数：\\(G = \\sum_{k = 1}^K\\hat p_{mk}(1 - \\hat p_{mk})\\)，分类越准，值越小，衡量端纯度 cross-entropy：\\(D = - \\sum_{k = 1}^K\\hat p_{mk} log\\hat p_{mk}\\)，与Gini系数相似，描述一致 如果以修剪树为目标，指标应选择分类错误率 节点产生相同预测说明预测纯度不同，可靠性不同 与线性模型相比，适用数据种类不同，借助可视化判断 优点：容易解释，适用于决策，容易出图，处理分类问题简单 缺点：预测准确率低于其他常见回归与分类方法 11.8.3 Bagging 决策树方法相比线性回归模型方差很大 引入Bootstrap，通过平均构建低方差模型 \\(\\hat f_{avg}(x) = \\frac{1}{B} \\sum_{b = 1}^B \\hat f^{*b}(x)\\) 不修剪，通过平均降低方差 对于分类变量，通过投票，少数服从多数得到答案 误差估计通过包外样本（OOB）进行交叉检验并进行树的选择，降低计算成本 变量权重在Bagging中不易衡量，可通过衡量每棵树的RSS或者Gini系数在进行一次变量分割后RSS下降程度并进行排序取得 该方法可应用于其他统计模型 11.8.4 随机森林 bagging中使用所有的变量进行选择，但是会更易出现共相关变量，方差降低不多 随机森林的核心在于强制使用较少的自变量，为其他自变量提供预测空间进而提高模型表现 变量数一般选择为\\(\\sqrt p\\) 表现会比bagging好一些 11.8.5 Boosting 通用的统计学习方法 树生长基于先前的树，不使用bootstrap，使用修改过的原始数据 先生成有d个节点的树，之后通过加入收缩的新树来拟合残差，收缩因子为\\(\\lambda\\)，呈现层级模式，最后模型为\\(\\hat f(x) = \\sum_{b = 1}^B \\lambda \\hat f^b(x)\\) boosting学习缓慢，一般学习较慢的学习效果更好 三个参数：树个数B（交叉检验），收缩因子\\(\\lambda\\)（控制学习速率），树节点数（一般为1，为交互作用深度，控制涉及变量） 深度d为1时是加性模型 随机森林与Boosting产生的模型都不好解释 11.9 支持向量机 11.9.1 最大边界分类器 11.9.1.1 超平面 p维空间里(p-1)维子空间 \\(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p = 0\\) 定义一个p维超平面，X落在超平面上 p维空间中点X不在超平面上就在其两侧 11.9.1.2 超平面分类 n*p矩阵X分为两类Y-1或1 代入超平面大于0为1，小于0为-1，有\\(Y*\\beta*X &gt; 0\\) 表示分类正确 构建训练函数\\(f(x^*) = \\beta_0 + \\beta_1 X_1^* + \\beta_2 X_2^* + ... + \\beta_p X_p^*\\) 正数表示为1，负数为-1，距离0越远表示距离超平面越远，越近表示分类越不确定，判定边界为线性 11.9.1.3 最大边界分类器 最大边界超平面：距离边界最近的距离的所有超平面中距离边界点最远的那个超平面 分类良好但容易在p大时过拟合 形成最大边界分类器所需要的边界点为支持向量，用以支持最大边界超平面 \\(f(x^*)*y_i\\)在系数平方和为1时为点到平面的垂直距离，最小化后最大化这个距离是求最大边界超平面的关键 11.9.2 支持向量分类器 有些情况不存在超平面，需要求一个软边界来适配最多的分类，这就是支持向量分类器 因为是软边界所以允许在超平面或边界一边出现误判 计算上还是为最小化最大化距离，但分类上距离要乘以\\(1 - \\epsilon_i\\)项，也就是松弛变量 松弛变量大于0表示边界误判，大于1表示超平面误判，总和为C，表示边界的容忍度，越大分类越模糊 C可通过交叉检验获得，控制bias-variance权衡 只有边界内观察点影响超平面的选择，这些点为支持向量，是形成模型的关键 与LDA不同，使用部分数据，与logistic回归类似 11.9.3 支持向量机 非线性条件下可以考虑将超平面理解为非线性超平面，提高样本维度换取分类效果 加入多项式等非线性描述后计算量不可控 支持向量机通过核来控制非线性边界 通过样本内积来解决支持向量分类问题 线性支持向量分类器\\(f(x) = \\beta_0 + \\sum_{i = 1}^{n} \\alpha_i &lt; x,x_i &gt;\\) 只有支持向量在解中非0，现在只需要支持向量的内积就可以求解 内积可以推广为核函数，核函数可以采用非线性模式 \\(f(x) = \\beta_0 + \\sum_{i = 1}^{n} \\alpha_i K( x,x_i )\\) 径向基核函数较为常用 使用内积的核函数计算上简单且等价与高维空间超平面分类 11.9.3.1 多于二分类 一对一分类：对比\\(K \\choose 2\\)个分类器在检验集中的效果，通过计数来选择分类结果 一对多分类：对比K个与剩下的K-1个分类，分类结果最远的认为属于那个分类 11.9.4 与logistic回归关系 中枢损失，对关键点敏感 传统方法也可以借鉴核函数观点视同 支持向量无法提供参数概率信息，采用核函数的logistic回归可以，计算量大 分类距离较远，支持向量机会比logistic回归好一点 支持向量机是计算机背景，logistic回归是概率背景 11.10 无监督学习 11.10.1 主成分分析 用较少的变量代表较多的变量，方便可视化与理解数据 第一主成分\\(Z_1 = \\phi_{11} X_1 + \\phi_{21}X_2 + ... + \\phi_{p1} X_p\\) 方差最大， 正则化后有\\(\\sum_{j = 1}^p \\phi_{j1}^2 = 1\\)，则\\(\\phi\\)为变量在第一主成分上的载荷 求解上第一主成分最大化\\(\\frac{1}{n} \\sum_{i = 1}^{n} z_{i1}^2\\) 求解载荷值，\\(z_{ni}\\)是第一个样本在第一个主成分上的得分 载荷表示变量重要程度，得分表示样本重要程度 第二主成分与第一主成分正交求解 biplot 同时表示载荷与得分，载荷向量接近表示有相关性，方向不一表示相关性弱，变量在主成分得分差异表示其状态 第一个主成分表示在p维空间里距离n个观察最近的超平面，因此具备代表性 取M个主成分可代表所有数据\\(x_{ij} \\approx \\sum_{m = 1}^M z_{im} \\phi_{jm}\\) 变量单位要统一，已经统一就不要标准化了 主成分是唯一的，符号可能有变化，载荷与得分值也唯一 主成分的重要性通过方差解释比例(PVE)来衡量，用碎石图来可视化\\[\\frac{\\sum_{i = 1}^n (\\sum_{j =1}^p \\phi_{jm} x_{ij})^2}{\\sum_{j =1}^p x_{ij}^2}\\] 寻找碎石图的肘部来确定选取主成分的个数，方法不固定 可用来进行M小于p的主成分回归 11.10.2 聚类方法 寻找子分类或簇的方法，从异质性寻找同质性 11.10.2.1 k均值聚类 子类中方差小，子类间方差大 事先指定子类个数 最小化所有K个平均欧式距离\\(W(C_k) = \\frac{1}{|C_k|} \\sum_{i,i&#39; \\in C_k} \\sum_{j = 1}^{p} (x_{ij} - x_{i&#39;j})^2\\) 先对所有样本随机分类，然后每种分类取中心，选取里中心距离最近的点重新分类，重新计算中心，迭代得到聚类结果 11.10.2.2 分层聚类 不需要指定先前聚类数，形成冰柱图 冰柱图要垂直分层解释，水平解释容易出现误导- 修剪冰柱图可给出聚类数 计算所有样本间距离，越相近就融合为一类，重新计算距离，反复这一过程 计算两者间相似度是很关键的，不同场景应用不同算法 变量的标准化处理上也很重要，考虑实际场景 "],
["section-12.html", "笔记 12 基因组学数据分析 12.1 microarrays 12.2 NGS 12.3 数据分析应用背景 12.4 Bioconductor 12.5 示例：甲基化数据分析", " 笔记 12 基因组学数据分析 主页 12.1 microarrays 12.1.1 原理 生成互补DNA探针 标记样品中的DNA单链 可以对不同样品标记不同颜色 特异性互补反应 测定标记物光信号 12.1.2 应用 测定基因表达 已知序列 3’端（降解从5’端开始）选取11个片段作为探针 样品对11个片段都是高表达则基因高表达 寻找SNP SNP 单核苷酸多态性 用来探索基因型 合成SNP探针 测定对不同探针的响应判断AA AG GG类型 寻找转录因子结合位点 样品处理为含蛋白与不含蛋白两份 去除蛋白后扩增 探针是基因组感兴趣的片段 瓦片分析可知探针与含转录因子DNA结合位点 总DNA作为对照 12.2 NGS 12.2.1 原理 DNA打成50~70片段 一个样品片段上亿 加上adaptor 固定在板上后原位扩增成束 使用标记过的单核苷酸逐碱基对测光强 同时测序大量片段 得到测序结果与强度 12.2.2 应用 寻找SNP RNA-seq 测定RNA表达量 寻找结合位点 表达量 12.3 数据分析应用背景 12.3.1 DNA 甲基化 CpG 5’端到3‘端 CG C上甲基化 复制时该特性会保留 临近CpG位点的基因不会被表达 CpG 成簇存在 称为CpG islands bisulfite treatment 可以用来测定CpG是否被甲基化 通过将未甲基化的CpG中的C改为T 测序中测定改变率就可知CpG位点甲基化程度与位置 12.3.2 CHIP-SEQ 蛋白结合后固定，洗掉其余片段，然后洗掉蛋白，对序列片段测序得到结合位点 12.3.3 RNA 测序 RNA反转录为cDNA测序 只有外显子 同一基因多种RNA片段 均值与方差有相关性 需要进行log变换后分析 12.4 Bioconductor 官方说明 使用biocLite()安装，安装后仍需要library()才能使用 source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite() 12.4.1 数据结构 12.4.1.1 分析数据 F 行 S 列 F代表芯片特征数，S代表样本数 12.4.1.2 表型数据 S 行 V 列 V代表样本特征，为分类或连续变量 如果表型数据解释不清，可以建立一个解释样本特征的labelDescription数据框，通过phenoData &lt;- new(&quot;AnnotatedDataFrame&quot;,data=pData, varMetadata=metadata) 建立AnnotatedDataFrame类型数据 12.4.1.3 实验描述 MIAME 类型对象 描述实验参数 12.4.1.4 组装数据 将分析数据，表型数据，实验描述组装为一个ExpressionSet类型的对象 exampleSet &lt;- ExpressionSet(assayData=exprs,phenoData=phenoData,experimentData=experimentData,annotation=&quot;hgu95av2&quot;) annotation代表了一组相似实验设计的芯片数据的代号，通过相关代号可以索引到芯片特征信息并将其与其他数据如基因型，染色体位置等连接以便于分析 从ExpressionSet里可以按照表型数据提取子集，也就是对 S 截取 V 中特定子集 exampleSet[ , exampleSet$gender == &quot;Male&quot;] esApply 用来针对ExpressionSet应用函数 12.4.1.5 数据集应用 library(Biobase) library(GEOquery) geoq &lt;- getGEO(&quot;GSE9514&quot;) 从基因表达精选集（GEO）上得到数据表达集 names(geoq) 得到文件名 e &lt;- geoq[[1]] 得到数据集 dim(e) 查看表达集维度 给出样本数与特征值，也就是测定序列数 dim(exprs(e)) 与上面等同，给出基因分析数据 dim(pData(e)) 给出8个样本的信息，信息头用names(pData(e))给出 dim(fData(e)) 给出特征与信息头列表 exprs为特征数×样本数矩阵 pdata为样本数×信息头 fdata为特征数×信息 experimentData(e) 给出实验信息 annotation(e) 特征注释 exptData(se)$MIAME 给出实验相关关键信息 Y &lt;- log2(exprs(bottomly.eset) + 0.5) 对NGS数据加0.5取2为底的对数（防0）得-1，排除掉0后可得MAplot观察数值分布，一般为均值小差异大，均值大相对稳定 formula 用来定义公式 model.matrix 用定义的公式生成矩阵 rowttests(y[, smallset], group[smallset]) 定义分组，设定模型可进行t-test，用火山图来表示 12.4.1.5.1 Iranges library(IRanges) 序列范围 ir &lt;- IRanges(start = c(3, 5, 17), end = c(10, 8, 20)) 定义序列 IRanges(5, 10) 表示5到10这6个碱基对，可以shift range(ir) 表示存在ir中序列的起止范围 gaps(ir) 表示寻找ir中间隔片段 disjoin(ir) 表示将ir中序列碎片化后互不重叠的片段 12.4.1.5.2 GRanges and GRangesList library(GenomicRanges) 基因范围 gr &lt;- GRanges(&quot;chrZ&quot;, IRanges(start = c(5, 10), end = c(35, 45)), strand = &quot;+&quot;, seqlengths = c(chrZ = 100L)) 定义位于染色体chrZ上几个序列范围，认为这些范围共同定义一个基因 可以shift，可以定义长度后trim mcols(gr)$value &lt;- c(-1, 4) 定义该基因类型中的列并赋值 grl &lt;- GRangesList(gr, gr2) 多个Granges定义一个基因库 length(grl) 给出基因库里基因个数 mcols(grl)$value &lt;- c(5, 7) 定义该基因库类型中的列并赋值 12.4.1.5.3 findOverlaps gr1 gr2 为两个基因范围对象 fo &lt;- findOverlaps(gr1, gr2) 寻找两个基因重叠序列 queryHits(fo) 与 subjectHits(fo) 提取两个基因重叠序号 成对出现 gr1[gr1 %over% gr2] 提取对应序列范围 12.4.1.5.4 Rle Rle(c(1, 1, 1, 0, 0, -2, -2, -2, rep(-1, 20))) 表示4组处理，每组各有 3 2 3 20 个重复 Rle是一种压缩存储实验设计的方式，可以用as.numeric()提取原始数据 Views(r, start = c(4, 2), end = c(7, 6) 提取对应实验组 12.4.2 数据读取 microarray 或 NGS 数据由芯片厂商提供，常见读取原始信息的包有affyPLM、affy、 oligo、limma 在Bioconductor里，这些原始数据要转为ExpressionSet格式 12.4.2.1 Affymterix CEL files library(affy) tab &lt;- read.delim(&quot;sampleinfo.txt&quot;, check.names = FALSE, as.is = TRUE) 读取样本信息 ab &lt;- ReadAffy(phenoData = tab) 读取样本数据，探针层次 ejust &lt;- justRMA(filenames = tab[, 1], phenoData = tab) 直接读取为基因层数据 e &lt;- rma(ab) 对样本进行背景校正与正则化，从探针层转化为基因层数据 12.4.2.2 背景干扰 spikein方法 梯度加入已知浓度的基因片段 阵列上进行shift 类似拉丁方设计 可以看到同一基因不同片段大致符合先平后增模式 开始阶段是噪声主导 后面是浓度主导 使用类似基因模拟噪声主导 相减后得到去干扰浓度效应 但低值部分会导致方差过大 也可以使用统计建模方法模拟背景值与响应 得到还原度更高的信号 12.4.2.3 正则化 基因组数据大多数为0 加标样品变化 正则化是为了还原这一结果 分位数正则化 局部回归正则化 稳方差正则化 当重复实验时 直接用分位数正则会掩盖样品差异 可以考虑只对加标基因正则化 然后推广到全局 12.4.2.4 探索分析作图 12.4.2.4.1 MA-plot x轴为两组基因组的均值，y轴为两组基因组的均值差 用来表示两组平行间的差异 12.4.2.4.2 Volcano plot 横坐标为处理间基因表达差异，纵坐标为差异的-log10(p.value) 一般为火山喷发状，差异越大，p值越小 12.5 示例：甲基化数据分析 12.5.1 读取数据 devtools::install_github(&quot;coloncancermeth&quot;,&quot;genomicsclass&quot;) library(coloncancermeth) data(coloncancermeth) 该数据集为结肠癌病人与对照的DNA甲基化数据集。 12.5.2 数据说明 dim(meth) dim(pd) length(gr) meth为测序数据，pd为样本信息，gr测序片段信息。 colnames(pd) table(pd$Status) X = model.matrix(~pd$Status) 查看病患与正常人的分组并构建模型。 chr = as.factor(seqnames(gr)) pos = start(gr) library(bumphunter) cl = clusterMaker(chr,pos,maxGap=500) res = bumphunter(meth,X,chr=chr,pos=pos,cluster=cl,cutoff=0.1,B=0) 按染色体生成因子变量，找出基因起始位点，然后利用bumphunter包寻找甲基化数据中某个阈值（0.1）下甲基化基因聚类的后出现的位置，聚类号，聚类相关性等信息寻找问题基因，可从中提取相关信息 cols=ifelse(pd$Status==&quot;normal&quot;,1,2) Index=(res$table[6,7]-3):(res$table[6,8]+3) matplot(pos[Index],meth[Index,,drop=TRUE],col=cols,pch=1,xlab=&quot;genomic location&quot;,ylab=&quot;Methylation&quot;,ylim=c(0,1)) Index=(res$table[6,7]):(res$table[6,8]) test &lt;- meth[Index,,drop=T] colnames(test) &lt;- pd$bcr_patient_barcode test1 &lt;- test[,cols==1] test2 &lt;- test[,cols==2] test3 &lt;- apply(test2, 2, mean) apply(matrix, 1, rank) 从上面可以得到有差异的甲基化数据所在的基因位置并提取相关样本数据信息。可根据差异作图，得到两组数据甲基化水平差异所在的基因位置。可对差异进行平滑操作，得到位置。这样就可以知道甲基化发生的序列位置与水平差异的信息了。 下面的例子是用人类基因组数据探索潜在的CpG岛。 library(BSgenome.Hsapiens.UCSC.hg19) Hsapiens[[&quot;chr1&quot;]] # 计算某染色体上潜在位点个数 countPattern(&#39;CG&#39;,Hsapiens[[&quot;chr1&quot;]]) # 计算某染色体上特定序列比例 观察与期望出现的比例 CG &lt;- countPattern(&#39;CG&#39;,Hsapiens[[&quot;chr1&quot;]])/length(Hsapiens[[&quot;chr1&quot;]]) GC &lt;- countPattern(&#39;GC&#39;,Hsapiens[[&quot;chr1&quot;]])/length(Hsapiens[[&quot;chr1&quot;]]) table &lt;- alphabetFrequency(Hsapiens[[&quot;chr1&quot;]]) expect &lt;- table[&#39;C&#39;]%*%table[&#39;G&#39;]/(length(Hsapiens[[&quot;chr1&quot;]]))^2 CG/expect "],
["tex.html", "笔记 13 简明TEX笔记 13.1 tex 基础 13.2 关于xetex 13.3 tex 常见问题", " 笔记 13 简明TEX笔记 13.1 tex 基础 作者 Donald Knuth tex 排版引擎 圆周率 metafont 处理字体 自然对数的底数 控制序列 钩子为\\ 宏包 对控制序列打包 钩子为\\ Lamport latex 宏包 分部分处理文档 打包了大量命令 latex 2e 后基本停止 Hans 对 latex 不满 认为可定制性不够 遂进行二次开发 有了 context 引擎 处理控制序列 进行排版 pdftex 可解决文档直接输出为PDF的问题 避免产生dvi 早期不支持unicode 对多国语言只能通过调用宏包来实现字符与图形对应 cjk ctt ctex 等都是此类宏包 需要安装字体 xetex 可原生支持unicode的引擎并调用系统字体 支持plain tex xelatex 可支持latex宏包 luatex 合并metapost 可直接绘图 可直接调用字体 可脱离宏包调用程序 现与 context 结合紧密 tex格式 Knuth为原始300个控制序列写的宏包 有600命令 这900个合称plain tex 将引擎 宏包 格式 辅助程序等打包即为发行版 miktex texlive mactex context minimals 只有自己的引擎与宏包 字体 最早是栅格 后来是矢量 type I 是最早的矢量 truetype 是type I 的竞争对手 opentype 是基于truetype的进化版 最早格式为DVI 为字体准备了字形盒子 可通过上面编码调用字库显示 之后出现了PS与PDF 原来要编译多次 现在只需要用xetex或luatex引擎就可以了 他们内置了库来实现字形盒子与字体的联系 这个库有cache功能 字体分类 衬线体 起笔落笔有差异 横竖粗细各不同 易于识别 宋体 非衬线体 笔画粗细一致 无装饰 醒目 黑体 等宽体 每个字宽窄相同 汉字 编程 13.2 关于xetex xeCJK 使用xelatex引擎的中文宏包 纠正了xelatex一些缩进等的不美观 ctex 包含早期CTT CJK 及 xeCJK 可用\\setCJKmainfont{SimSun} 来调用系统字体 下面是底层调用中英文混排 13.2.1 实例讲解 \\documentclass[12pt,a4paper]{article} \\usepackage{xltxtra,fontspec,xunicode} \\usepackage[slantfont,boldfont]{xeCJK} % 允许斜体和粗体 \\setCJKmainfont{FZJingLeiS-R-GB} % 设置缺省中文字体 \\setCJKmonofont{SimSun} % 设置等宽字体 \\setmainfont{TeX Gyre Pagella} % 英文衬线字体 \\setmonofont{Monaco} % 英文等宽字体 \\setsansfont{Trebuchet MS} % 英文无衬线字体 13.3 tex 常见问题 空白 tab与多个空白认为是一个空白 空行表示段落结束 保留字符 # $ % ^ &amp; _ { } ~ \\ 可使用\\# \\$ \\% \\^{} \\&amp; \\_ \\{ \\} \\~{} 来表示 \\\\ 表示断行 $\\backslash$生成反斜杠 latex命令 \\tex{} 后面加空格防止命令延长 {}中为命令参数 % 表示注释掉一行 也可使用\\usepackage{verbatim} 中的comment环境 源文件结构 \\documentclass[]{...} 声明文档类型[]中为选项 包括字体 纸张 公式对齐 等文档格式 \\usepackage[]{...} 加入需要的宏包[]中为触发功能的关键词 以上为导言区 \\begin{document}开始正文 \\end{document}结束文档 页面样式\\pagestyle{style} 不同页眉页脚样式 \\include{ﬁlename} 用来包含文档 多用于大型文档 在新页包含 连续可用\\input{ﬁlename} \\includeonly{ﬁlename,ﬁlename,. . .} 导言区包含文档 在所有\\include文档中 只有\\includeonly中的会被处理 语法检查\\usepackage{syntonly} \\syntaxonly \\hyphenation{word list} 给出断字列表 完整的不允许断 有-的表示允许的唯一断字点 在文档中-表示唯一允许断字的地方 mbox fbox 不允许断字的地方 后者给出一个方框 mbox可用来分割连字 特殊字符 ‘输入两个表示双引号 -输入1个连字号 2个短破折 3个长破折 网址中波浪号用$\\sim$ 而不是\\~表示 摄氏度用$-30\\,^{\\circ}\\mathrm{C}$表示 \\ldots表示省略号 bable宏包可处理多种非中文语言 ~用来强制取消大写字母后空格多出的一点 \\@用来表示大写字母作为最后一个词后句号的处理 一般latex不会处理大写字母后的句号（加入多一点空格）认为是缩写 \\frontmatter 应接着命令 \\begin{document} 使用 它把页码更换为罗马数字 正文前的内容普遍使用带星的命令（例如，\\chapter*{Preface}） 以阻止 latex 对它们排序 \\mainmatter 应出现在书的第一章紧前面 它打开阿拉伯页码计数器并对页码从新计数 \\appendix 标志书中附录材料的开始 该命令后的各章序号改用字母标记 \\backmatter 应该插入与书中最后一部分内容的紧前面 如参考文献和索引 在标准文档类型中它对页面没有什么效果 交叉引用 \\label{marker}引用点 \\ref{marker}引用 \\pageref{marker} 引用点页码交叉引用 产生脚注 \\footnote{footnote text} 强调 \\underline{text} 下划线 \\emph{text} 斜体 强调中强调会切换字体 环境 itemize 环境用于简单的列表 enumerate 环境用于带序号的列表 description 环境用于带描述的列表 flushleft 和 flushright 环境分别产生靠左排列和靠右排列的段落 center 环境产生居中的文本 如果你不输入命令 \\\\ 指定断行点 latex 将自行决定 quote 环境对重要断语和例子的引用很重要 quotation 环境用于超过几段的较长引用，因为它对段落进行缩进 verse 环境用于诗歌，在诗歌中断行很重要。在一行的末尾用 \\\\ 断行，在每一段后留一空行 verbatim 环境直接输出其中内容 可用断字表示 可表示空格 较短的用\\verb*|like this :-) | \\begin{tabular}{table spec} 用来生成表格 \\begin{figure}[placement speciﬁer] or \\begin{table}[placement speciﬁer] 表示浮动体 \\caption{caption text} 给浮动体加标签 \\listoffigures 与 \\listoftables 生成图表目录 数学公式 段落中放于 \\( 和 \\) $ 和 $ 或者 \\begin{math} 和 \\end{math} 单独一行可放于 \\[ 和 \\] 或 \\begin{displaymath} 和 \\end{displaymath} 带编号可放于equation数学环境中 空格和分行都将被忽略 所有的空格或是由数学表达式逻辑的衍生 或是由特殊的命令如 \\ \\quad 或 \\qquad 来得到 不允许有空行 每个公式中只能有一个段落 每个字符都将被看作是一个变量名并以此来排版 如果你希望在公式中出现普通的文本（使用正体字并可以有空格），那么你必须使用命令 \\textrm{...} 来输入这些文本 \\newtheorem{name}[counter]{text}[section]定理环境 name 是短关键字，用于标识“定理”。text 定义“定理”的真实名称，会在最终文件中打印出来。 建立新命令 \\newcommand{name}[num]{deﬁnition} 第一个参数 name 是你想要建立的命令的名称 第二个参数 deﬁnition 是命令的定义 第三个参数 num 是可选的 用于指定命令所需的参数数目（命令最多可以有9个参数）如果不给出这个参数 那么新建的命令将不接受任何参数 num 可用来传参，\\renewcommand 可用来建立与原命令名称相同的命令 建立新环境 \\newenvironment{name}[num]{before}{after} 建立新宏包 \\ProvidesPackage{package name}命令环境打包起名字保存为sty 可直接调用 其实就是打包导言区 行距\\linespread{factor} 首行缩进与段落间距 \\setlength{\\parindent}{0pt} \\setlength{\\parskip}{1ex plus 0.5ex minus 0.2ex} 水平距离\\hspace{length} 橡皮擦 \\stretch{n} x\\hspace{\\stretch{3}}x 垂直距离\\vspace{length} \\sum\\limits_{k=1}^n k^2 使求和符号上下标真正出现在上下位 "],
["section-14.html", "笔记 14 生物信息学数据库 14.1 数据结构 14.2 Pubmed 搜索 14.3 动态规划 14.4 得分矩阵 14.5 E 值 14.6 PSI-BLAST 14.7 蛋白 14.8 蛋白结构预测 14.9 细菌基因组 14.10 病毒 14.11 单核苷酸多态性（SNP） 14.12 真核基因预测 14.13 DNA指纹 14.14 Ensembl", " 笔记 14 生物信息学数据库 14.1 数据结构 列代表特征 行代表条目 每个条目有一个唯一性特征 数据表可通过列链接成为关系数据库 14.2 Pubmed 搜索 PubMed search tags [AD] – Affiliation (company or school) [ALL] – All fields (eliminates defaults) [AU] or [AUTH] – Author [1AU] – First author [ECNO] – Enzyme Commission Numbers [EDAT] – Entry date (YYYY/MM/DD) [ISS] - Issue # of journal [JOUR] - Journal (Title, Abbreviation , ISSN) [LA] – Language [PDAT] – Publication date (YYYY/MM/DD) [PT] – Publication type [SUBS] – Substance name [TIAB] – Title/Abstract [TW] – Text words [UID] – Unique identifiers (primary keys) [VOL] or [VI] – Volume of journal MeSH terms [MH][MAJR][SH] 被 MeSH 索引的关系数据库 保守性检索 有层级关系 时间段搜索 冒号分割 YYYY/MM/DD:YYYY/MM/DD 序列长度搜索 [SLEN] 可以是蛋白 可以是核酸 蛋白分子量搜索 [MOLWT] 物种搜索 [ORGN] Nucleotide 序列蛋白数据库 MMDB 3D结构数据库 Genome 基因组数据库 OMIM 人类孟德尔遗传数据库 用来探索等位基因问题 分类数据库 用来界定分类 GEO 基因芯片的实验数据 SNP 基因指纹数据库 14.3 动态规划 用于序列比对 对角线得分 按总分评价比对结果 可全局 可局部 序列比对指标是特异性与相似性 特异性指精确匹配比率 相似性指精确匹配加化学相似性比率 结构相近则相似 FASTA 慢准 BLAST 快 三种情况 匹配 不匹配 间隔 间隔罚分 14.4 得分矩阵 考虑突变的比对 蛋白的自然突变率矩阵PM1 矩阵自相乘得到外推矩阵 PM10 PM250 取对数为打分矩阵 取不同矩阵源于研究目的对多样性的判断 14.5 E 值 表示序列的同源性 比对得分的稀有性 两个参数 数据库大小(N) 比对得分(S) E = N/S 数据库越大越可能随机碰到相同序列 得分越高越可能同源 E值很小说明同源性很高 E值很大什么说明不了 一般阈值1e-04 14.6 PSI-BLAST 先用BLAST在一定E值上建库 计算新库的氨基酸概率 再与全库比对得分 得到统计显著性 可以发现BLAST未发现的序列 建立蛋白家族 14.7 蛋白 Profiles 定量描述 Patterns 定性描述 Signature 蛋白保守序列 motif 少于20个氨基酸 指示二级结构 Domains 超过40个氨基酸 蛋白的球状区 共同点 保守 正则表达式表示保守区 E-X(2,4)-[FHM]-X(4)-{P}-L E后随意两个，三个，四个然后FHM其中一个，然后随意四个，然后一个不是P，最后为L 可以精确可以模糊 没有E值 14.8 蛋白结构预测 分子量 道尔顿（Da）描述质量 等电点 蛋白不带电的pH值 小于7 酸性 中性带负电 大于7 碱性 中性带正点 网站计算 蛋白定位 分泌 胞内 核内 MITOPRED 预测线粒体蛋白 14.9 细菌基因组 细菌是环形DNA 真核是线性染色体 细菌不加工mRNA 细菌一段mRNA上有多个顺反子 也就是多个编码DNA序列 操纵子在mRNA编码的上游或下游调控转录 GLIMMER与FGENESB用来预测一段序列的转录情况 14.10 病毒 三种 RNA DNA 逆转录病毒 突变快 RNA病毒三种 双链 正链 负链 逆转录基因组简单 Gag Pol Env 凝集素等决定病毒亚型 14.11 单核苷酸多态性（SNP） 至少1%种群中存在的DNA单核苷酸变化 后果 编码区改变影响表型 不改变蛋白序列的编码区可能影响mRNA加工 启动子或调控区可能影响表达 其他区没有影响 可作为染色体标记- 类型 不改变氨基酸 改变氨基酸 非编码区 数据库 dbSNP SNPEffect SNPs对蛋白的影响 SNPedia SNPs的临床效应 1000 基因组外显子计划 第二代测序的发展 14.12 真核基因预测 CDS是mRNA的子集 CDS可能比mRNA外显子少 基因预测只能发现编码区外显子 有些转录变化不改变蛋白序列：UTR区与同义密码子 14.13 DNA指纹 重复 突变会影响限制性片段长度 VNTR 用来排除嫌犯 PCR 用来扩增相关片段 CODIS 区域在美国用来鉴定身份 14.14 Ensembl 外显子基因组学数据库 可选择人类 鼠 斑马鱼等常见物种 "],
["section-15.html", "笔记 15 流行病学导论 15.1 声明 15.2 早期疾病的概念 15.3 近代流行病学关键人物 15.4 现代慢性病流行病学 15.5 流行病学基本概念 15.6 描述性流行病学 15.7 分析流行病学 15.8 疾病监控 15.9 疾病频率的测量 15.10 联系测量 15.11 随机误差 15.12 研究道德 15.13 临床实验 15.14 队列研究 15.15 病例对照研究 15.16 标准化 15.17 混杂 15.18 效应修饰（EMM） 15.19 多变量方法 15.20 筛选 15.21 因果推断 15.22 论文研读", " 笔记 15 流行病学导论 15.1 声明 本笔记来自于波士顿大学在线教程与北卡大学教堂山分校的公开课 二手知识，谨防消化不良 翻译有误之处见谅，烦请告知，谢谢！ 15.2 早期疾病的概念 渔猎时期主要问题是食物的供应与营养均衡问题 农耕时期开始群居，出现疾病的流行问题 神秘主义，迷信与神的惩罚 希波克拉底：理性思考疾病起源，提出体液学说 欧洲流行300多年的黑死病，开始认为病因是“瘴气”，其实是老鼠跳蚤上细菌 没有验证病因与疾病关系的方法与预防措施 工业革命时期城市规模迅速扩大，分工细化，出现职业暴露健康问题 15.3 近代流行病学关键人物 Girolamo Fracastoro (1546) 认为疾病来自种子 John Graunt - The Bills of Mortality (1662) 记录伦敦死亡率，出生率数据并进行分析 Anton van Leeuwenhouk (1670s) 显微镜之父，首先观察到细胞 John Pringle and “Jail Fever” (1740s) 研究军队与监狱卫生与疾病并讨论了与伤寒的关系 James Lind and Scurvy (1754) 进行了第一例临床控制实验，验证柑橘对坏血病的治疗作用 Francois Broussais &amp; Pierre Louis (1832) 提出放血疗法，没有验证但沿用几个世纪 Ignaz Semmelweis and Oliver Wendell Holmes (1840s) 前者发现了某种产科疾病是由刚解剖完尸体的学生引入的，后者推行了疾病可能来源于医护人员的理念而饱受争议 John Snow - The Father of Epidemiology (1850s) 流行病学之父，研究并验证了霍乱与城市供水的关系 Louis Pasteur (late 1800) 提出巴氏消毒法与疫苗理论 公共卫生的概念 (1850-1875) 起源于人口统计及18世纪的启蒙运动例如功利主义的兴起对公众健康的关注 15.4 现代慢性病流行病学 肺癌：工业革命后的肺癌发病率很高，普遍认为是工厂公路导致，但后续研究表明吸烟可能是主要因素，该研究促进了病例对照研究的发展 佛雷明翰心脏病研究：48年起追踪心脏病研究，已持续三代人 15.5 流行病学基本概念 15.5.1 基本假设 病有病因非随机 病因可察可研究 15.5.2 定义 研究人群中疾病分布与成因的学科 阶段 研究类型 观察&amp;形成假说 案例研究／断面研究／生态学研究 观察研究假设检验 病例控制研究与队列研究 临床研究假设检验 临床实验 15.6 描述性流行病学 关注不同时间、地点、人群的差异、相似性与相关性，形成假说 案例：传染病暴发 早期关注案例采访，寻找共同点 对地理位置作图寻找空间关系 对时间趋势作图寻找变化规律 流行曲线：横轴日期，纵轴新增病例 点源爆发：单峰，潜伏期相对一致 持续源爆发：单峰，潜伏期持续出现 逐步流行：多峰，存在人对人传染 15.6.1 疾病爆发的研究步骤 准备研究 验证诊断与爆发的存在 定义案例并寻找案例 进行描述性流行病学研究确定时间、地点与人群的差异 生成爆发原因与来源的假设 假设检验 制定控制与预防措施 交流研究发现 15.6.2 慢性病的描述性流行病学 人群特质：年龄，性别，种族，职业，饮食习惯，宗教习惯，业余活动等 地点：慢性病地域差距 时间：大趋势，季节性，片断性 其他：环境变化，诊断精度，医疗水平，人群年龄分布 15.6.3 描述流行病学分类 病例报道 单个案例 艾滋病血液传播的发现 无注射狂犬疫苗后痊愈 系列病例 多个案例 男同性恋间获得性免疫缺陷传染 断面研究 同一时间对特定人群的健康状况与风险因子进行调查 HIS NHANES 生态学研究 以群体为单位研究区域平均暴露状况 15.7 分析流行病学 不同于描述流行病学提出假设，分析流行病学进行假设检验 队列研究：定义基线与风险人群 前瞻性队列研究：参与者参加的时候不出现健康效应 回顾性队列研究：根据已经出现的健康效应反向追查风险因子 临床实验：风险因子由研究人员指定 病例对照研究：不用来研究发病率，侧重风险比，不追踪，根据已有状况回溯，对幸存者采样，适合稀有病症的研究 判断流程 是否个人（生态学研究） 是否有对照（系列案例） 是否追踪（断面研究） 是否不先选取出现健康状况的组（病例对照研究） 是否不出现健康状况（回顾队列研究） 是否指定对照组（前瞻队列研究） 临床实验 15.8 疾病监控 早期教堂记录出生率与死亡率 1662 John Graunt “Bills of Mortality” 1837 英国建立 General Registrar’s Office 记录市民出生、死亡与婚姻 John Snow 对霍乱数据的分析 1842 马萨诸塞州开始记录出生死亡状况 1901 全美开始记录疾病流行状况 1925 强制执行疾病监控 目前基本是CDC控制，除了强制汇报，也有主动收集 综合疾控，不等确诊收集症状，例如google flu 15.9 疾病频率的测量 15.9.1 人群 固定人群（相对固定，或由事件定义） 动态人群（由当前状态决定的人群） 15.9.2 患病率（prevalence） 表示在指定时间里具有某种健康效应的人群比例，非新增 \\[prevalence = \\frac{affected individuals}{total individuals in the population}\\] 举例：患病率0.25表示人群中有25%的人在指定的时间段里受某种健康效应影响 经常会导致因果推断不准，因为影响因素产生的效应被本来的效应覆盖了 15.9.3 风险（risk） 也称作发病率（incidence或cumulative incidence），表示在一段给定时间里新增某种健康效应的比例 \\[risk = \\frac{new cases}{total individuals at risk}\\] 举例：5年风险0.1表示在5年里某个个体有10%的几率出现某种健康效应 前瞻性研究（prospective studies）常用，但控制性研究（case-control studies）里总体风险无法确定，不能使用。 15.9.4 比率（rate） 也称作发病率比率（incidence rates）表示在一个人群中某种健康效应出现的速度。单位为每个人年，个人年表示风险个体参与研究到出现健康效应的总时间 \\[rate = \\frac{new cases}{total person-time at risk}\\] 举例：0.1案例每个人年表示对于每10个人追踪1年或2个人追踪5年将会有一个案例出现 人群无限状态下，有 \\[risk = rate \\cdot time\\] 考虑到人口的指数衰减，有 \\[risk = 1 - exp(- rate \\cdot times)\\] 当风险率非恒定时，或者对时间分段计算，或者进行生存分析 人群出现稳态时，有 \\[\\frac{prevalence}{1-prevalence} = rate \\cdot Avg.Duration\\] 当患病率很低时，有 \\[prevalence = rate \\cdot Avg.Duration\\] 疾病的持续期可计算为 \\[Avg.Duration = \\frac{prevalence}{rate}\\] 15.9.5 其他频率测量 分类比率：如年龄，性别，种族等 病态比率：不致命的状态 死亡率 致死率：患病中导致死亡的比率 攻击率：短期食物中毒 生育率：育龄妇女一年内生育新生儿的比率 新生儿死亡率：一岁以下新生儿死亡率 特殊患病率：体检率，新生儿感染率，非新增 15.10 联系测量 测定频率不涉及对比，探索关系需要对比 不同暴露状态下的频率差或者比表征 15.10.1 风险比与比率比（risk ratio rate ratio） \\[risk ratio = \\frac{risk_{exposed}}{risk_{unexposed}}\\] \\[rate ratio = \\frac{rate_{exposed}}{rate_{unexposed}}\\] 表示暴露与健康效应的关系强度，1表示无关，但比例关系不能给出绝对差异 表述风险比不要使用更多或更少，如果更多或更少需要减一除以风险比：相比不服用，服用阿司匹林有0.57倍的心肌梗死风险或43%的风险下降 15.10.2 对照组 暴露量最小的一组通常作为风险比计算中的对照组 15.10.3 风险差（risk difference） \\[risk = risk_{exposed} - risk_{unexposed} = \\frac{cases in exposed group}{total at risk in exposed group} - \\frac{cases in control group}{total at risk in control group}\\] 正数表明对某种健康效应有促进作用，负数表示有抑制作用，要指明时间区段 15.10.4 归因比例（Attributable Proportion Among the Exposed） \\[attributable proportion = \\frac{risk ratio - 1}{risk ratio}\\] 暴露组风险中归因于该原因的比例 15.10.5 人群归因比例（Population Attributable Fraction） \\[population Attributable Fraction = (proportion of cases exposed) \\cdot (attributable proportion in the exposed)\\] 人群中风险归于该原因的比例 15.10.6 胜率比（odds ratio） \\[odds ratios = \\frac{odds_{exposed}}{odds_{unexposed}}\\] 常用在控制性研究里替代风险比或比率比，这时风险比无法计算，但几率比可以在总体效应比较小与特殊采样技术使用的时候近似于风险比或比率比，解释起来与它们一致 15.11 随机误差 偏差，混杂与随机误差是流行病学采样中最常见问题 随机误差也是采样误差 置信区间用来表示随机误差而非混杂偏差等误差 95%置信区间与p值计算方法一致，可用来判断是否统计显著 15.12 研究道德 无论目的如何，以人作为研究对象是不道德的 纳粹在二战期间集中营里使用人作为研究对象，1946年审批时提出Nuremberg Code： Voluntary consent of the human subject is absolutely essential. The experiment must yield generalizable knowledge that could not be obtained in any other way and is not random and unnecessary in nature. Animal experimentation should precede human experimentation. All unnecessary physical and mental suffering and injury should be avoided. No experiment should be conducted if there is reason to believe that death or disabling injury will occur. The degree of risk to subjects should never exceed the humanitarian importance of the problem. Risks to the subjects should be minimized through proper preparations. Experiments should only be conducted by scientifically qualified investigators. Subjects should always be at liberty to withdraw from experiments. Investigators must be ready to end the experiment at any stage if there is cause to believe that continuing the experiment is likely to result in injury, disability or death to the subject. 1964年，WMA接受赫尔辛基宣言 塔斯基吉梅毒研究，没有征得患者同意，也没有进行有效治疗，1972年泄漏，1974年美国出台人类被试保护法案，所有涉及人的研究需要通过IRB审核 1978年，议会出台人类被试研究指南 法律不强制，但基金一般有相关要求 相信研究有益等同于对其怀疑才可进行 安慰剂可以使用，但要保证患者最终能得到最好的治疗 15.13 临床实验 分为预防性与治疗性干涉研究 新药研发的四阶段 8-80人小规模评价安全性，副作用及副作用出现的剂量 80-200人中等规模测试有效性，副作用及与剂量的关系 200-40,000人大规模测试其与当前治疗方式的副作用强度 推向市场后的监测，测试罕见但严重的副作用，例如H1N1疫苗 15.13.1 研究对象 人群分层考虑是否为目标人群及是否愿意参加 内部验证准确性，外部验证广泛性 样本数由功效决定，由于疾病发病率低，很小的差异也需要很大的样本来保证功效 15.13.2 对照组与控制组 排除混杂因素需要考虑除考察因素外其他因素在研究客体中分配均匀 分配方法包括自我前后对比与随机非随机分配 屏蔽 单盲：被试不知道是否是处理组 双盲：研究人员与被试都不知道处理组 三盲：进行处理的人也不知道是否是处理组 安慰剂（placebo），也就是无效药 装假（sham），假装进行某个操作流程（有道德风险） 安慰剂效应：接受治疗的人都认为会从中收益，即使知道是安慰剂也会产生该效应 服从度，处理组与控制组要区分明显，内部一致 设计尽量简单 被试生活规律 通知明确 实时追踪 屏蔽处理信息 对不服从的仔细询问，收集未使用药片，收集血液尿样进行评价 掉队会导致功效降低及存在偏误 15.13.3 临床分析中的问题 随即控制时要给出基线信息 混杂因素可能不在基线里而是直接影响结果 如果混杂因素在调整前后影响结果超过10%，那么就要进行调整- 希望被处理分析，保证处理与对照中接受治疗的意愿接近 二次分析，只对接受的人进行结果分析，失去随机性与一定样本数及混杂控制 某项研究同时有利弊，利大于弊，是否继续研究？ 预防花费如果很高，是否值得推荐？ 15.14 队列研究 15.14.1 前瞻性队列研究 研究开始时没病，记录基线，追踪个人 案例：BMI与心脏病关系 15.14.2 回顾性队列研究 适合职业暴露，回溯暴露状况 案例：游泳池污染事件 15.14.3 双向队列研究 同时进行前瞻性与回顾性队列研究 较少见 案例：橙剂喷洒飞行员追踪，急性与慢性暴露 15.14.4 固定队列与开放队列 固定队列表示人数固定或只能减少，例如日本原子弹受害者追踪，多数研究是固定队列 开放队列表示人数动态，可随时加入 15.14.5 研究对象 一般人群队列或特殊暴露队列（事件幸存者） 对比组越接近越好，信息收集越全越好 内部比对：同队列未暴露被试，肥胖调查中不肥胖的人 外部比对：内部不存在未暴露时，例如化学品职业暴露 一般人群比对：从国家抽取基础数据，但因为健康工人效应现在不常用，可使用标准死亡率（SMR）或标准流行指数（SIR）来测量联系，也就是用基础数据计算期望值与实际值的对比 健康工人效应：能工作的工人比一般人群要健康 15.14.6 队列追踪 队列研究一般开始时没有偏见 追踪率低于60%不可靠，丢失20%可能因掉队原因关联结果导致偏误 不愿参与会导致偏差 回溯研究会因保留疾病比例高于保留正常病例的原因导致选择偏误 15.14.7 优点 直接给出暴露与效应的时间序列关系 可直接计算疾病的风险率 可用来评价稀有暴露 可用来同时评价多种暴露 基本无选择偏误 15.14.8 前瞻性队列研究缺点 耗时长 费用高 不适用稀有疾病 不适用潜伏期长疾病 掉队会导致偏差 15.14.9 回顾性队列研究缺点 不适用稀有疾病 记录不匹配研究需要结果不好 过去记录丢失混杂因素信息 暴露组与对比组很难区分 掉队会导致偏差 15.14.10 偏误 选择人群无法代表群体 产生原因 在病例控制研究中控制组没有代表性 追踪丢失率在控制与处理组不同 是否愿意参加影响暴露与结果 健康工人效应(职业暴露) 诊断标准不同 回顾性研究中回顾会放大暴露或结果 观察偏误，如果是非特异性区分错误，那会指向空假设 记录偏误，引导性问题 暴露比结果难评价，结果比暴露稀有，因而暴露更容易产生导致结论错误的偏误 灵敏度与特异性对风险比与风险差的影响不同 15.15 病例对照研究 现有案例，后回顾暴露状态，两者在研究前是独立的 适用于稀有疾病，只能计算胜率比而不能计算风险比 经常内置于已有的队列研究，适用于稀有疾病假设 当研究对象为人群而不是队列研究中的未发病人群时，允许发病者作为控制组 案例：DES与子宫癌 病例来源：住院病人、死亡证明、死亡注册、断面研究 对照来源：代表群体的组、独立采样且采样策略一致避免代表性丧失 随机电话访问是之前一种选择对照的方法，由于存在偏误（无法区分居民与商业电话，固定电话使用率降低）而逐渐被替代 对照组的数量选择要考虑统计功效 采样方法：幸存者采样，基于队列采样（按队列开始时风险人群），风险组采样（出现案例时存在风险的人群）后两种可以不考虑稀有假设，因为他们对照可代表整体，胜率比可用来估计风险比 优点：对罕见病高效，节约成本，可动态研究 缺点：选择偏误，对罕见暴露低效，不能计算风险 15.16 标准化 粗比率（crude rates）忽略了人群组成差异，需要调整 死亡率上如果两组中有一组老年人占总体比率高，那么会使两组风险比较时有偏差 用整体人群作为基础分布，比率乘各分组人数之后求和得到标准比率，其实质是将各分组年龄分布归一来消除年龄偏误 Standardized Incidence Ratios 标准发病率用整体发病概率作为基准，计算各分组发病人的期望值并对比观察值 15.17 混杂 混杂因素是同时对暴露与结果产生影响的因素，例如唐氏综合症研究中出生的顺序其实对病症无影响，孕妇年龄为该研究的混杂因素 混杂因素判据：对暴露与结果都有影响；在暴露组间分配不均；不能是暴露与结果的中间步骤（饮酒通过升高HDL来降低心血管病发病率，HDL与两者相关但不是混杂因素） 混杂因素可能是另一个风险，也可以是预防因素，也可以是其他替代物 残差混杂表示在排除混杂因素后由于排除不全或分类错误或未知导致的混杂 现象或禁忌混杂，暴露与结果实际受结果的反馈影响，例如抗抑郁药与绝育的关系中抑郁本事会对绝育产生影响，这样在观察研究中不易区分 因果互换，例如母乳对婴幼儿有益，但有研究发现母乳可能造成营养不良，但后来人们发现其实是因为调查人群中婴儿出现体重偏轻或腹泻的家庭往往会停止使用母乳喂养，案例；另一个案例是止痛药与肾衰的研究中并非服用止痛药导致肾衰而是因为糖尿病多导致肾衰而糖尿病人经常服用止痛药 研究设计中防止混杂可通过限制研究人群，个体匹配与随机化实现 数据分析中混杂控制－分层，例如年龄分组后原有差异可能就消失 多分层方法可采用CMH方法计算风险比，其实就是对分组比率加权来忽视分组因素的影响，影响因素多要采用多元分析 15.18 效应修饰（EMM） 指由于另外的变量导致效应分类的状态，例如年龄可能造成某种药药效相反，可理解为线性模型中的交互作用项- 测定有混杂因素与无混杂因素下的两个风险比，如果差异很大且差异区间包括原始风险比，则存在修正测量效应；如果差异不大但影响原始风险比，则要同时考虑混杂因素；如果两者同时存在，则要考虑分层讨论混杂的情况 存在EMM时不能使用CMH方法，因为此时样本不适合混合，应该分层讨论，可用卡方检验EMM的存在与否 统计交互作用与生物学的交互作用需要区分 15.19 多变量方法 本质上是多元回归，通过参数判断变量影响 混杂变量用增加参数的方法排除，参数变化超过10%可认为明显混杂 EMM用交互作用项排除，观察是否显著 最终模型是否含有不显著相具体分析 15.20 筛选 “detectable pre-clinical phase”或DPCP表示在筛选与有症状后检测之间的时间 筛选的价值（高血压中测血压） 疾病很严重（子宫癌） 症状发生前的治疗效果要比发生后好 DPCP疾病流行概率很高 筛选的限制 胆结石中预先检测对治疗没意义，都是大了以后手术去除 肺癌中检测到了也无法有效治疗 疾病不流行 好的筛选应具有的标准 便宜 容易操作 最小化不适 可靠 有区分 测试验证 灵敏度（真阳性占阳性比例） 特异性（真阴性占阴性比例） 真阳性预测值（真阳性占阳性比例）这个值会随流行度变化而变化，即使灵敏度特异性都高，较低的流行度也会降低预测准确性，所以测试要针对易感人群并计算流行度 真阴性预测值（真阴性占阴性比例） gold standard “金标” ROC曲线 左上方靠近 多数情况可以接受假阳性而提高灵敏度 前列腺癌筛查的案例 测试本身的缺点 低流行率的假阳性 假阴性 前列腺相关报道 过度测试 癌症测试 评估筛选中需要注意的偏误 宫颈癌，乳腺癌也在常见筛选之中 15.21 因果推断 因果推断在流行病学中很重要，但目前没有标准来界定因果而仅仅有一些指南。 15.21.1 Hill 因果标准 由流行病学家Austin Bradford Hill提出的9条判断因果关系的标准，充分不必要条件，不能作为清单使用。 15.21.1.1 联系强度 由风险比，比率比，胜率比来测量，越强代表因果联系越大，反之不成立。 15.21.1.2 数据一致性（Consistency） 一致性用来排除解释某健康效应的其他可能，缺少不代表没有，可能有其他共有因素，越强因果联系越大。 15.21.1.3 特异性（Specificity） 因素结果1对1，该标准不是特别有效，有些因素会对应多种结果。 15.21.1.4 时序性 因果必要条件，先有因后有果。 15.21.1.5 剂量效应关系 剂量效应关系是充分不必要条件，例如阈值效应。 15.21.1.6 生物合理性 基础研究，没有流行病学研究前的实验室数据如毒理学研究。 15.21.1.7 相干性 相干性表示新数据不应该与现有证据矛盾。 15.21.1.8 实验证据 随机控制实验的结果，改变原因结果不同。 15.21.1.9 类比 最弱的标准，主观性较强。 15.21.2 部分原因理论 Kenneth Rothman 提出，认为健康效应的原因可看成一个饼图，缺少任一部分结果都不会发生，用来了解结果的发生过程。 15.21.3 逆向模型（Counterfactual models） 考虑无暴露状态下是否产生效应的思路，群组水平考察。 15.21.4 有向无环图（DAGs） 概念流程图，考虑混杂因素。 15.22 论文研读 科研论文类型包括原始研究（描述性与分析性）、方法、荟萃分析与评论 文章结构包括题目、作者、摘要、前言、方法、结果、讨论、结论、致谢、文献引用与图表 依次浏览摘要（概况），前言（问题的重要性），讨论（看结论与意义），方法（看实验设计），结果（看图表）并记录疑点 15.22.1 Introduction What was the primary question that the authors were trying to answer? Why were they asking this? Rationale? What was their goal? 15.22.2 Methods What type of study design was used? Was this a logical choice, given the goals of the study? What are the weaknesses of this study design? What problems and biases might have occurred? How were subjects identified and enrolled? How successful was enrollment? Could selection bias have occurred as a result of control selection bias, or differential non-participation in a case-control study? Did selection of controls meet the “would” criterion? If it was a cohort study, how complete was follow up How carefully was the exposure of interest defined? How was the exposure assessed? What was the quality of the exposure data? Was exposure data validated? How carefully was the outcome of interest defined? How was it assessed? Was it validated? Could selection bias have affected the results? What was the potential for information bias? Non-differential misclassification? Errors in recording or coding of data? General inability of subjects to remember? Differential misclassification? Recall bias? Interviewer bias? Recorder bias? Differential quality of data? What were the likely confounding variables? Did the authors control for confounding in the design of the study, in the analysis, or both? Did they fail to account for any potentially important confounders? Was control of confounding adequate? Could there have been residual confounding? Did they perform stratified analysis? Did they use regression analysis? Would these problems bias toward the null or away from the nul? 15.22.3 Results Do the results suggest an association? If so, how was it assessed, and how strong was the association? Did the authors estimate risk ratios or risk differences? How precise were the measures of association? Was the sample size adequate? Did the authors report confidence intervals? p-values? Did the authors adequately assess random error? 15.22.4 Discussion Was the interpretation appropriate? Are the results of this study consistent with other studies in this area? If there are differences with other study findings, what could they be due to? 15.22.5 Conclusion What are the public health implications of the study? 15.22.6 Clinical Trial Were patients randomly assigned to the comparison groups? Was the study blinded? Did the patients or doctors know which group the patient was in? Was the randomization effective in creating two groups which were similar with respect to age, gender, race, and other potentially confounding variables? Did patients adhere to the treatment? Did patients drop out? Were appropriate statistical tests used to compare the groups? Were the groups analyzed based on their randomized assignment, i.e. a so-called “intention to treat analysis” Was the sample size large enough to detect a meaningful difference if it had existed? 15.22.7 Cohort Study How did they select the subjects in the comparison groups? Were the groups comparable with respect to other factors? How did they ascertain risk factor status? Was the data accurate? Could there have been bias? How complete was the follow up data? Was the statistical analysis appropriate? Did they control for possible confounding variables? Was the sample size adequate to detect clinically important differences if they existed? 15.22.8 Case-Control Study What was the source population? How were cases and controls defined? Was there selection bias? Was the ‘would’ criterion met? How was information collected? Was it accurate? Was it collected in a comparable way in both groups? Could there have been recall bias? Interviewer bias? Was the statistical analysis appropriate? Did they control for possible confounding variables? Was the sample size adequate to detect clinically important differences if they existed? 15.22.9 Screening Test If so, did they have an independent blind comparison with a reference diagnostic technique, i.e., a “gold standard”? Was the diagnostic test evaluated in an appropriate group of patients, similar to those you would find in your practice? Did they address the ability of the test to discriminate between normal and abnormal? How was abnormality defined? Did they calculate sensitivity and specificity or likelihood ratios or report their data in such a way that you could calculate them? 15.22.10 Additional Considerations Are the Findings Important? External Validity (Generalizability) "],
["section-16.html", "笔记 16 化学品与健康 16.1 Chemicals in our environment: What is a chemical, and how are we exposed? 16.2 Toxicology: What do chemicals do in our bodies? 16.3 Biomonitoring: How do we measure chemicals in our bodies and why? 16.4 Health effects of chemicals: How do we figure out how chemicals affect our health? 16.5 Chemicals policy: What do we do about chemicals and health?", " 笔记 16 化学品与健康 16.1 Chemicals in our environment: What is a chemical, and how are we exposed? 16.1.1 Chemical defination A compound or substance that has been purified or prepared, especially artificially 16.1.2 How Populations Are Exposed to Chemicals 16.1.3 How Chemicals Get into Our Bodies 16.1.4 Database IRIS: Integrated Risk Information System (EPA) HazDat Database and ToxFAQ (ATSDR) TOXNET: National Library of Medicine MSDS: Materials Safety Data Sheets 16.1.5 The Chemical Industry Work Environment 16.1.6 Occupational Health: Understanding and Assessing Exposures and Outcomes Occupational Health Surveillance Exposure Assessment Occupational Epidemiology Study Designs Cohort: a designated group of individuals who are identified as eligible for the study, subject to further inclusion factors, in order to evaluate factors associated with adverse health outcomes no random selection of individuals into the cohort Cohort studies can be prospective or retrospective What Is the Healthy Worker Effect? Observation that workers exhibit lower mortality rates than the general population Selection of “healthier” persons into the workforce Retention of “healthier” persons in the workforce In appropriate comparison population that differs in terms of Vital status ascertainment Differential diagnoses Risk factors for mortality Access to treatment 16.1.7 Industrial Hygiene Practices 16.1.8 Regulatory Programs and Initiatives 16.2 Toxicology: What do chemicals do in our bodies? 16.2.1 Intro to Chemicals and Health Toxicology: the study of poisons Poisons: chemical or physical substances which produce adverse responses in biological organisms Toxicants: toxic substances that are either manmade or result from human activity Toxins: usually toxic substances produced by living organisms, such as reptiles, insects, plants, and microorganisms “The dose makes the poison” — Paracelsus 16.2.2 Processes Involved in Chemical Toxicity Exposure is outside the body After absorption, you have an internal dose Distribution mainly through blood Biotransformation Elimination Storage Fat (lipid-soluble) Bone (minerals) The end result of these toxicokinetic processes is a biologically effective dose (BED) of the toxicant The biologically effective dose is that portion of the internal dose that interacts with biological molecules (targets) Leads to changes in cells Molecular Biochemical changes Cell toxicity Organ dysfunction/disease The effect depends on the dose of the agent Toxicokinetics: (movement) processes that the body subjects the chemical to Absorption: taking in of a chemical from a site(s) of exposure (i.e., gastrointestinal system) resulting in an internal dose Distribution: distributing a chemical from its site of absorption throughout the body Excretion/elimination: removing the chemical from the body Biotransformation/metabolism: modification of chemicals by enzymes in the body Toxicodynamics: (changes) what the chemical does to the organism, Toxicodynamics refers to the effects of toxicants (or their metabolites) in biological systems Some interactions with target molecules result in an adverse biological effect, while others may not For some chemicals, the form that interacts with targets is the original chemical For other chemicals, the toxic form is a biotransformation product(s) of that chemical 16.3 Biomonitoring: How do we measure chemicals in our bodies and why? 16.3.1 Exposure Assessment Approaches Questionnaire/historical information Environmental monitoring Personal monitoring Biomonitoring Combine these approaches with calibrated and validated models 16.3.2 Biomonitoring A useful tool for exposure assessment Defined as the assessment of internal dose by measuring the parent chemical (or its metabolite or reaction product) in human specimens (for example: blood, urine) Measurement of concentrations, not exposures 16.3.3 Evaluation of Human Exposure Using Biomonitoring Large–scale population surveys NHANES: provides a foundation for CDC’s National Biomonitoring Program Epidemiological studies of specific populations Susceptible/vulnerable Highly exposed (for example: NICU infants, occupational settings) 16.3.4 Considerations in Biomonitoring What is the best chemical measure (analyte)? Parent chemical or metabolite or adduct What is the best time to obtain the specimen? Measurement time windows What is the best specimen (matrix)? Blood and urine Analytical considerations Related to the specimen (for example: stability, contamination, interferences, etc.) Related to the method (for example: validated method, sensitivity, specificity, QA/QC, etc.) 16.3.5 NHANES: How We Assess Exposure of the US Population to Priority Environmental Chemicals Began in 1971 Continuous survey since 1999 (survey cycle = two years) Stratified, multistate national probability sample About 10,000 participants in 30 locations every two years method Face-to-face and computer-assisted interviews:Demographics, Socioeconomic, Dietary,Health-related topics Physical examination Biological specimen collection More at: http://www.cdc.gov/nchs/nhanes/about_nhanes.htm Not all chemicals are measured in everyone, except:Blood Pb, Cd, and Hg: all persons one year and older, Serum cotinine: all persons three years and older Most urinary chemical measurements are made in a 1/3 subsample of the participants, Ages six years and older,Subsamples are determined so they are representative of the US population Biomonitoring results are presented in the National Report on Human Exposure to Environmental Chemicals DATA Chemical properties (for example: persistence in the body, metabolism, stability) and analytical considerations are factors in biomarker selection and specimen collection Detection of a chemical does not mean that it causes disease 16.3.6 Biomonitoring at the state and local laboratories CDC’s data can not be used at the state &amp; local level APHL. Public health laboratories 16.4 Health effects of chemicals: How do we figure out how chemicals affect our health? 16.4.1 Discuss different types of health effects Acute vs latent Transient vs chronic Beneficial vs adverse 16.4.2 Describe various health endpoints Acute toxicity Generally related to short-term exposure,severeeffects Example:carbonmonoxidepoisoning Can have short-term and long-term consequences Repeated dose toxicity -Depends on toxicokinetics(what happens to the toxin in the body, and how quickly) Effects could be acute(threshold),subacute,orchronic Example: some medications build up effects(e.g.,acetaminophen) Genotoxicity Some chemicals can damage DNA, causing mutations when the cells divide These mutations can lead to cancer if the cells are in not reproductive(eggorsperm) cells, or to some birth defects Carcinogenicity Ability to cause cancer or make cancer more likely Can be director in direct effects Most chemicals that have been identified as likely carcinogens have been from animal studies; fewer from direct human epidemiology Occupational workers most likely to be exposed; examples are coke oven workers, asbestos workers Reproductive toxicity Reproduction is complex, and process can be interrupted at many points Some effects from direct toxicity to egg or sperm cells, other effects on developing Difficult to identify in people; most identified in animal models fetus Endocrine disruption Relatively recent findings of chemicals mimicking naturally occurring hormones such as sex hormones Possible links to development, maturation, sexual maturation Early in our understanding Neurotoxicity: general,delayed Effect on developing or mature nervous system Effects on central nervous system including cognition(lead), peripheral nervous system Other: immunotoxicity, allergenicity, intolerance Toxicity endpoints National Environmental Health Tracking Network Causal association: Hill’s Causal Criteria 16.4.3 Risk Assessment in Environmental Decision Making Risk Assessment a policy tool designed to facilitate management of environmental health hazards Risk assessment is an integration of information from various scientific domains facilitate decision making, not science Who Uses Risk Assessment Federal and international agencies State environmental/health agencies Industry Non-governmental groups ### The Four Steps of Risk Assessment Hazard Identification Identify chemicals of concern and potential associated health effects Evaluate evidence that exposure to a given chemical elicits an adverse response Qualitative evaluation of relationship between exposure and adverse effects Effects seen in one human population are predictive for others Average human may be as sensitive as most sensitive animal responder Site concordance (tumors) or effects concordance (non-cancer responses) do not necessarily hold Dose-Response Assessment Quantitative characterization of the relationship between a chemical agent dose and the incidence of adverse health effects Where possible, quantitative toxicity metrics are presented Exposure Assessment Quantitative characterization of human exposure/contact with chemical hazards Integrates information on Chemical concentrations in environmental media, Human activity patterns and Population characteristics Predicts magnitude of human exposure in the form of external dose in milligrams per kilogram of body weight per day Estimation of intake of a chemical Key components Concentration of chemical in media of interest, Media intake rate, Time components(Frequency Duration Averaging time) and Body weight Risk Characterization Integration of information from hazard identification, dose-response evaluation, and exposure assessment steps A risk characterization often includes … Prediction of carcinogenic risks and potential for non-carcinogenic hazard Estimation of population burden (cancer) Uncertainty discussion Quantitative Risk Characterization Risk of 1 x 10e-6 is “one case per million persons exposed over a lifetime” Risk = exposed dose × effect unitless No. cases = risk × population size The outputs of a risk assessment typically include an estimate of cancer risk, non- cancer hazard, population cancer burden, and an uncertainty discussion 16.5 Chemicals policy: What do we do about chemicals and health? 16.5.1 Toxic Substances Control Act Covers most chemicals used in industry and in commercial/consumer products Excludes: Uses in drugs, cosmetics, food, and food packaging regulated by FDA Uses in pesticides covered by EPA under FIFRA Basic provisions have never been amended Chemical Policy Legislation Regulation Court decisions (“case law”) 16.5.2 Drivers for Chemical Policy Reform Chemicals Are Ubiquitous 10 trillion pounds produced per year in the US Used to make 96% of all materials and products Large but unknown number of chemicals in US commerce Science Drivers: Connecting the Dots Certain chronic diseases are on the rise Certain chemicals are linked to those same chronic diseases Many of those same chemicals are in us Diseases Linked to Chemical Exposures Cancer Learning and developmental disabilities Parkinson’s and Alzheimer’s disease Reproductive health and fertility problems Asthma Diabetes Obesity Immune disorders Cardiovascular disease Understanding of extent and pathways of chemical exposures Long-range transport Migration of chemicals from products into environment Disproportionate exposures: environmental justice issues Advent of biomonitoring Early-life exposures Risk assessment evolution and controversy “RedBook”(1983),and a major update “SilverBook”(2009) Key challenges: Human variability, Uncertainty, Cumulative effects and exposures(Multiple chemicals, Chemicals and other stressors) Emerging high-throughput testing: Tox21 16.5.3 Why Legislative Reform? New chemicals No data, no problem Guessing game Catch-22 Anti-precaution Why Now? State legislation and policy changes Top priority of last two EPA administrators Market demand, especially from downstream users Retail regulation European Union’s REACH Regulation and Canadian Environmental Protection Act REACH “No data,no market” Shifting the burden of proof: Industry required to show safety Information flow in supply chains: Two-way flow between suppliers &lt;–&gt; customers Authorization required to use substances of very high concern Action EDF EDF Health blog "],
["section-17.html", "笔记 17 心理学导论笔记 17.1 关于心理活动的来源-神经心理学 17.2 佛洛依德-精神分析 17.3 斯金纳-行为主义 17.4 认知-发展心理学-皮亚杰 17.5 语言学 17.6 感知 注意 记忆 17.7 情感-爱情 17.8 进化 17.9 理性 17.10 情感 17.11 共性-个性 17.12 性 17.13 道德 17.14 自己和他人-社会心理学 17.15 迷 17.16 临床心理学 17.17 幸福-积极心理学 17.18 心理学导论框架", " 笔记 17 心理学导论笔记 Psychology is the science of behavior and the mind. Science refers to all attempts to answer questions through the systematic collection and logical analysis of objectively observable data. 源于1879年Wilhelm Wundi在德国建立了第一个心理学实验室 编写了第一份教材 培养了第一个研究生 三个基础 Behavior and mental experiences have physical causes, so they are amenable to scientific analysis. dualism 二元论 指人存在两个本质：一个是肉体 一个是灵魂 笛卡尔的二元论认为并不是所有的人类才能来自于灵魂,他提出了一个反射模型并认为有纤维导管来牵引或分流液体来沟通外界刺激与大脑,这与神经及电信号传导模型有相似性.此外,这样的二元论有助于解释动物的无灵魂行为,因为人可以思考.同时他认为人的灵魂是通过松果体来接受信息与肉体联系,这一理解可以避开宗教等问题,但依然存在哲学上与心理学上的局限性. Thomas Hobbes的唯物主义发展了笛卡尔的观点认为灵魂不过是大脑的功能并受限于自然规律,这对英国经验论的发展有帮助. 19世纪,机械论与神经的发现促进了心理学的发展.在反射的研究上,François Magendie在法国认为神经传导需要两条独立途径:一条用来传入信息,一条用来传出信息 . reflexology 由俄国心理学家I. M. Sechenov奠基,他的思想对Ivan Pavlov的影响很大 19世纪另一项重要发现是大脑功能的区域化,德国Johannes Müller提出不同感觉经验来自不同大脑不同部分,法国Pierre Flourens用动物实验证明了大脑损伤与运动的关系,另外也有一些人的案例证明 The way a person behaves, thinks, and feels is modified, over time, by the person’s experiences in his or her environment. The body’s machinery, which produces behavior and mental experiences, is a product of evolution by natural selection. 心理学分为5个领域 neuroscience 通过观察大脑反应来研究心理 development 研究人们如何成长 发育以及学习 cognitive 用计算机方法研究意识 观察人们如何做事 如理解语言 识别物体 玩游戏等 social 研究人们群体行为与交流行为 clinical 研究心理健康和心理疾病 17.1 关于心理活动的来源-神经心理学 克里克 《惊人的假说》 心理活动时神经元活动 17.1.1 二元论者认为物质和精神是分离的–大多数人 笛卡尔-动物是机器 人不同有无形心灵 论据1 人们行为观察 机器可对环境反应 人有选择性 有语言 论据2 我思故我在 恶魔的把戏 无法怀疑自己思考这件事 怀疑论角度 思考不要物质身体 与语言协调 物质变化 人不变 多重人格 人死 心灵另有归宿 宗教文化方面 17.1.2 机械论者认为大脑产生精神活动 不能脱离实体–当前主流认识 不科学 无法合理解释物质与精神的联系 学习过程 大脑参与心理过程 17.1.3 大脑灰质 神经元-基本单位 树突 轴突 髓鞘 相互连接 senser motive linkage 可修复 强度变化 数量 频率 突触 神经递质 兴奋剂 抑制剂 人脑不是机器-并行过程-ann 人脑可修复 人脑反应快 17.1.4 不用大脑的活动-本能 大脑皮层是主要部分 存在功能区对应-不到四分之一 功能区拓扑关系与身体相似 功能区大小决定功能复杂性 其他功能研究方法-心理活动 CAT PET fMRI 活跃区 受损大脑-案例研究 左右大脑区分 胼胝体 裂脑人 心理 信息加工过程 意识难题 如何产生主观认识 机械论vs人文精神 17.2 佛洛依德-精神分析 理论包括一切 非局限理论 纪念碑 阴茎嫉妒论 无意识动机论 真正的原因你并不知道 非单一理性 无意识 本我id-追求快乐与满足 盲目 自我ego-追求现实中的快乐与满足 产生意识 超我superego-社会家庭规则内化 道德良知 盲目 性人格发展 无法跨越阶段 口唇期 过早断奶 暴饮暴食 口腔满足感 一岁 肛门期 如厕训练 不愿排泄 洁癖 吝啬 一到三岁 性器官期 对性器感兴趣 俄狄浦斯情结 恋母厌父 恋父 阴茎嫉妒 三到五岁 怕阉割潜伏 潜伏期 五岁到青春期 压抑性 转向自己兴趣 性器 青春期到成年 不压抑 防御机制-结合现实 保护自己 升华 转移精力到抽象 替代 转移发泄到他人 投射 将自己的想法认为别人是具有的 同性 合理化 给出理性解释 退化 孩子 退化早期阶段 癔症-保护的极端症状 压抑所致 催眠与自由联想 想到问题关键就解决问题 涉及梦 梦-另一种实现或发泄过程 显性梦 隐性梦 宗教-父亲与上帝 对佛洛依德的现代评价 科学评价-理论有误or成功预测 but语焉不详 可证伪 无法证伪 可变通的地方太多 经常涉及自身 无法证伪 文化差异过大-佛洛依德自身的社会时代限制 可治疗不代表正确 历史与文学多 心理少 无意识现象客观存在-语言理解-本能 进化上的意义 欺骗与自我欺骗 17.3 斯金纳-行为主义 心理活动来自后天学习 无天性之说 反心理主义 不考虑内心 只考虑观察 生物种群无差异性 通过研究动物研究人 原则 习惯成自然 反复刺激 形成经验 刺激反应相互联系作用 巴普洛夫狗实验 条件反射 消退 自发回复 扩散 治疗恐惧症 找到无关刺激如恐惧转为条件刺激如见到蛇的原因 用另一种无关刺激如放松替代 不总是有效 恋物癖 条件刺激 亦不准确 操控性条件作用 自主条件反射 选择最有利行为 效果律 类似自然选择 正负强化区别在于强化后的行为概率 行为塑造 代币法 部分强化 次数 时间 延长效果 先天行为 不可观察的内部行为 动物无需奖励就可以学习 加西亚效应-遗传影响 人类进化史 有效但毫无意义的理论 奖励惩罚术语过于模糊 遗产 理解学习机制 特别是动物 驯兽或婴儿 应用手段 17.4 认知-发展心理学-皮亚杰 儿童研究-认识产生的一般理论 斑马条纹来源-万物如此皆因其本-发展心理学 17.4.1 发生认识论 胚胎重演论 儿童重演认识 被认为错误 框架理论 同化（新信息纳入已有框架）和顺应（改变框架纳入新信息）-环境接纳 研究方法 让儿童解决问题并提问 阶段论 Sensorimotor Stage birth-2 只感知无推理 客体永存性概念 婴儿猜猜看 不理解客体 preoperational stage 2-7 表征事物-自我主义 无法从他人角度观察 守恒 儿童无法判定守恒过程与守恒概念（重要） concrete operational stage 7-12 可解决守恒问题 抽象能力有限 formal operation stage 12-adult 健全的理性 科学性 对儿童的研究可证伪 科学研究 是否解释了发展过程 观察答案是否可行 理论局限性 儿童理解力的低估 17.4.2 婴儿认知 婴儿比想象的聪明 脑电波研究 注视次数研究 习惯化与惊奇-行为主义 客体永存性问题 算数问题 婴儿出生就了解世界 但只有一部分 17.4.3 理解婴儿认知发展-物质世界 神经元的生长与连接 髓鞘的发展 青少年也不全 无法抑制 缺少控制行为的能力 后天习得问题 经验问题 17.4.4 社交能力发展 模仿能力 有些天生的社交能力 婴儿不懂欺骗 或无法控制 欺骗很困难 不同认知过程的关系 独立VS联系 儿童孤独症 大部分孤独症无法过上正常生活 无天份 模块理论 17.5 语言学 语言指交流用的语言系统 语言都可以表达抽象概念 达尔文-语言是天生的 每个文化都有语言 可能是创新非天生 实用保留 一代人就可以创造语言 奴隶混合语言 是天性 不需要文化积淀 每个人都掌握一门语言 语言神经功能区的存在 17.5.1 语言共性 都有创新性 笛卡尔 机器无语言 语言规则可理解不同语句 语音 语态 语法的存在 语音 基本语调 语言系统间不一致 词与词停顿是illusion 源自自己的语言系统 儿童要学习语言停顿 segment 自上而下加工 周杰伦的歌看歌词就觉得对的上 语态 语素 语法 将词组成句子的规则 递归 语言模糊性 17.5.2 语言知识的来源 语言不是学习的而是发育的 语言是学习来的 语言需要大脑正常 语言学习中人们更关注内容而不是语法 但语法错误会自然消失 语言节奏 法国可研究婴儿 17.5.3 语言学习时间表 0-4mouths 从出生前就开始选择自己母语节奏 对所有语调敏感 7mouths 可以学习语言 12个月 可以学习单词 对词语顺序敏感 18个月 可以学习简单句子 7岁到青春期 语言学习能力开始下降 17.5.4 动物语言学习 生物有自己的交流系统 交流方式 无系统 叫声 猩猩 连续的行为 蜜蜂 某一主题随机的行为 鸟鸣 是否可训练学习语言-有争议 仅仅聪明不够学习语言 进化上的近亲但分开已远 野生动物交流有助于了解原则 17.5.5 语言的其他研究课题-文化 意志 本质 创新 幼儿时期学多门语言没坏处 17.6 感知 注意 记忆 17.6.1 感知过程很复杂 2D重建3D很困难 信息不全 关于世界运作的无意识假设或常识判断 颜色 关于光照的假设 人眼的色彩修正-色温问题 物体 分辨出不同物体先验观点-格式塔原则 深度 视差 对象重叠 大小判断距离 错觉研究法-先验知识或本能 17.6.2 注意和记忆 记忆错误 失忆症 忘记过去 不能形成新记忆 分类 感觉记忆 短时记忆STM 存储能力弱 约5-7个组块-记忆单位 记忆单位取决于理解力 长时记忆LTM 存储能力强 存贮容量大 重复可将短时记忆加强为长时记忆 但不够 结构化记忆 理解 转化为意义 可转化为长时记忆 诗歌 图像等古文件记录 A newspaper is better than a magazine. A seashore is a better place than the street. At first it is better to run than to walk. You may have to try several times. It takes some skill but is easy to learn. Even young children can enjoy it. Once successful, complications are minimal. Birds seldom get too close. Rain, however, soaks in very fast. Too many people doing the same thing can also cause problems. One needs lots of room. If there are no complications it can be very peaceful. A rock will serve as an anchor. If things break loose from it, however, you will not get a second chance. 如果告诉你这是关于放风筝的 就好记了 - 情景提供线索 加强记忆 - 联系越多 记得越深 - 搜索策略 提供线索 - 外显记忆 可表述 - 内显记忆 吃饭 骑车子 - 语义记忆 - 场景记忆 - 编码 存储 取出-回忆 再认 感知中获得记忆 注意力获得显性记忆 有偏向性-看文字说颜色 存在干扰 stroop effect 变化视盲 我们的注意力只有很小的范围 多数事物不会改变-思维惯性 习惯成自然 既视感 前额叶受损 情况加剧 大脑出现错误 把时间戳盖错了 遗忘 大脑记忆消失 记得多阻止新记忆 线索变化 童年遗忘 语言未学习或线索缺失 大脑损伤 丧失瞬时记忆 失去新记忆 有内隐记忆 记忆通过引导改写 说服了自己 加深了错误记忆 被催眠的人取悦催眠者 为自己找解释 压抑记忆 真实vs编造 灌输 质疑催眠者 闪光灯记忆 重大事件的记忆 可能被扭曲了 记忆有很多种 记忆可通过组织结构化理解来加深 记忆并不总是真的 17.7 情感-爱情 定义-实验中 吸引力 感兴趣 亲密 分享秘密信息 激情 决心或承诺 维系关系 - line 3 一见钟情 - line 4 包办婚姻的第一阶段 离婚率并不高 社会文化原因 - line 6 柏拉图式 朋友 - line 7 闪婚 愚蠢的爱 吸引力 7个变量 3大要素-实验可操作度高 证实度高 空间近 相似高 物以类聚 熟悉度高 四小要素 能力 偶尔犯错却有能力的人吸引力高-出丑效应 -经典实验-出丑效应 - 身体吸引力 帅不帅 - 潜意识中外表很重要 对第二次约会 - 假发实验 外观或魅力对评价的影响很大 - 得失影响 - 随时间吸引力增强或减弱 反馈 - 错误归因 love错误 倾向于最近的客体归因 - 摇摆桥实验-有历险体验会将感觉兴奋错误归因 但没有随机分配被试 - 类似实验发生在有氧运动后或被告知要有危险行为或听到心跳（可以是虚假）时的错误归因 17.8 进化 另一个假说-意识的起源是什么 钟表匠-上帝-智创论 自相矛盾-上帝的来源 进化与退化的存在-物种间的联系 有些设计不好-眼睛盲点 17.8.1 达尔文-自然选择 随机变异 繁殖与生存不同 变化是可传递的 17.8.2 大脑的进化 传播基因 终极原因与现实原因是可以不同的 但非对立 不同层次 自然选择都是适应性的 不一定 可能是意外或副产品 不解释一切 质疑 二元论 大脑进化 但思想不进化 来自神创 人类文化的影响 孕妇晨吐反应可用进化论解释 爱情三大要素 兄妹最近 乱伦 对后代不好 终极原因与现实原因 离得近导致不感兴趣 如果被同一人抚育影响更重 17.9 理性 直观推断而不是逻辑推导更常见 17.9.1 框架效应 答复取决于问题框架 得失不同 得强于失 17.9.2 禀赋效应 拥有了对自己就升值 损失就会升值 偏见 忽略基础概率-贝叶斯条件概率 17.9.3 新闻效应 关注的被高估 确认偏误 -只看想看的东西 平凡无偏性 17.10 情感 看起来自然-脑中的真相-分析常见现象 仅有理性不可能 分清主次 17.10.1 面部表情 微笑 非学习 社会信号 面对他人 种类duchenne smile 礼节性微笑-假笑 杜兴微笑-真笑 duchenne smile Coy smiles, Appeasement smiles 对自己的微笑 腼腆 婴儿就掌握两种微笑 婚姻的坟墓是蔑视 微笑是好事 纪念册微笑与真实心境相关 情景感染 17.10.2 非社交表情 17.10.2.1 恐惧 广泛的生物行为 恐惧诱因 祖先比较害怕 进化意义 蜘蛛蛇vs枪支 婴儿也会害怕没见过的东西 17.10.3 社交表情 亲戚 进化压力与利他行为 生存vs繁衍 自私的基因诱导了利他行为 寄生虫角度而不是寄主角度 梅毒提高性欲 狂犬病传播病毒 自私的基因 无私的个体 亲戚关系 基因视角 雄狮杀小狮 诱导流产 小动物的求救信号 小动物的可爱来自进化 基因中认为可爱的信号 婴儿脸可爱可被偏爱 女性生理周期 无社会接触会导致疯狂 社会接触会改善孤僻 无引导相互之间安慰也会改善 非亲戚 打交道 分享食物-蝙蝠 欺骗与搭便车 只接受不分享 发现骗子 惩罚骗子 停止惠利 囚徒困境 从友好开始 投桃报李 最佳处理方式 情感变化 喜欢合作 痛恨黑手 理性的人容易被利用 公平原则 非理性占优势 讨人喜欢 不被招惹 非理性暴力 谋杀起源于非理性 进化使然 17.10.4 文化差异 荣誉文化 以暴力为荣 美国南部 男性 事关荣誉 17.11 共性-个性 人与人不同-性格 智力 性格测试 可信度 重复性 有效性 测得是否准不准 -罗夏测试 墨点测试 无效 五大类性格因素 神经质或稳定 内向或外向 经验丰富或缺乏 随和或不随和 尽责任或不尽责任 30岁后稳定 反映现实 不同人观察结果一致 智力测试 G 总体智力水平 S 测试得分 平均成绩100 贝尔曲线 生活水平与IQ 自我证明 问题作弊 差异来源 遗传 共享环境 非共享环境 双胞胎研究 同卵双胞胎相似性很高 弗林效应 IQ在不断提高 平均水平在提高 行为遗传学 父母的影响小于朋友？ 组内差异与组间差异溯源 17.12 性 喜欢但时间不多4min3sec很重要 两性来源-迷-进化损失50% 某物产生原因与推翻的原因不一致 基因与环境在改变人的本质上差不多 基因不代表宿命 环境不代表容易改变 17.12.1 区别 细胞小的雄性 带营养的雌性 雄性强壮 亲本投资-心理差异 雌性投资大 数量重要 挑剔-性选择 雄性投资小 数量不重要 社群行为可导致同等投资 灵长类 17.12.2 人类 男性体形大 有竞争 进攻性强 性选择 匿名性行为 卖淫很普遍 色情文学很普遍 猴子也有 柯立芝效应 男性喜欢匿名性行为 行为学差异 女同一夫一妻 男同滥交 吸引力 聪明善良 女性关注权利地位 后代 好父亲 男性 年轻很重要 后代很重要 漂亮 -代表年轻 健康 平均无瑕疵 平均脸是漂亮的 婴儿也能识别-天生的 女性在排卵期判别有差异 人们对男女期望不同-社会影响 文化隔离 4-11岁 男女对立 男性缺少同情心 社会认知障碍更容易发生 学术差异 逻辑推理能力差异 同性恋 道德问题 青春期就能有区别 天生或后天 有遗传影响 不完全是（双胞胎研究） 不符合生物适应性 不同物种间也存在 17.13 道德 17.13.1 道德感-进化 亲缘选择 合作 同理心-感同身受 本能 婴儿就有 黑猩猩也有 与道德感相关 in group out group 道德实施的范围 团结的唯一方法就是找出共同的敌人-外星人 随机分组也会出现组内道德感 17.13.2 道德判断 特征 评价 义务与惩罚 跨文化差别存在 三种道德观 个人道德 平等 自由-西方文化 乱伦的解释-就是不对 但无原因 吃掉宠物狗 -道德直觉的存在 团体道德 男女分工 神道德 宗教禁令 ### 好人做坏事 Milgram实验 服从与大屠杀 自愿-环境 权威 隔断距离 自知情况 自己判断 恶的动力 去个性化-减少责任 匿名-心理解放 遇险呼救基本无效 直接指定个人更容易让人帮助 心理距离远-面对不是个体 诋毁他人 善的动力-自私的基因 联系-经济全球化 相互依赖 互相了解 共同目标-军队 从他人角度出发 隐喻联系-动物说成人 一家人理论 17.14 自己和他人-社会心理学 17.14.1 六度分割理论 Milgram 一半的人2个就送到 有些人是结点 17.14.2 自我 焦点效应-自己的问题有那么严重吗 高估自己的问题对他人的影响 透明度效应 高估他人识谎能力 高估他人对自己的了解 自我估计通常高于平均值 原因 只得到正面反馈 自我评价不全面 偏重某一方面 想法不对称-正向增强 认为自己做的合理-认知失调 确认偏误 寻找支持自己的证据 理由不足效应 产生矛盾 寻找理由 自己做的总是对的 欺负新人-被折磨后反而更不认为错了 义务工更加投入工作 免费治疗通常无效 儿童因为奖励而不乐意做事 17.14.3 归因 对个体行为的解释 -别人的行为看作个人特质而不是环境 - 基本归因效应-错误归因 - 演员与角色混合-广告 天生与文化影响 东西方文化差异-东方看重环境 自我放大 简化他人 个人与环境归因不对称 对人对己不一样 喜欢一个人归因 临近性 接触性 接触越多越喜欢 -相似性 与临近性难区分 婚姻成功率 外貌 马太效应 多的越多 少的越少 17.14.4 印象 第一印象很重要 确认偏误 可塑造后续印象 印象形成很快很迅速 5秒人格形成 性取向判别-1秒 皮格马里翁效应 如果我认为你有某种特质 那你的行为就更像是有那种特质且你也会受此影响 卖花的与小姐不是因为自身行为而是被对待的方式而异 期望与评价-群组 对待自己组与他人组是不一样的-参道德部分 刻板印象 分类 推测对生存信息处理很重要 对人也会分类 刻板印象更可能是对的 错误 确认偏误-对找工作或社会偏见的理解有帮助 很多信息有误-娱乐媒介 道德问题 心理画像-车险 明确负面印象会让人受影响 层次-公众-个人-潜意识 -内隐态度实验-快速闪现 阈值下闪现 刻板影响会影响个人判断 每个人都会有刻板印象 很难去除 但可努力改变 17.15 迷 17.15.1 睡眠-部分解决 脑电图研究 1过渡期 2-4short-wave 慢慢进入深度睡眠 delta波增强 返回23 REM睡眠 -4到5个循环睡醒 两种 慢波睡眠 REM睡眠 类似清醒 做梦 原因 可能恢复过程 可能保存能量 睡眠障碍 梦游-一种安眠药副作用 做梦 梦是碎片 很快消失 可记下来 梦总是消极的 最常见的梦-被追捕 原因-可能的观点 加深记忆 重现-副产品 17.15.2 笑-完全是迷 婴儿的笑 进化上说不通 笑声可以区别 笑和笑话要区别 社会性的 感染性的-猴子猩猩也有 源于某种不较真的进攻性 凝聚力量 无法预料 17.16 临床心理学 17.16.1 什么是精神疾病 观察指标而非客观指标-主观影响 社会标准 个人特质 性别-刻板印象标准 情景 正常状态多疑 现在的共识-3D 痛苦Distress causes person or others signiﬁcant distress 机能失调Dysfunction prevents person from functioning in daily life 异常Deviance behaviors or feelings highly unusual 诊断发展 早期基于佛洛依德 现在更完善 心理问题很常见 大学第一个高峰 情绪失调 单向情绪失调 发病率高 女的25% 男的13% 只有沮丧 双向情绪失调 发病率低 男女一致 沮丧和狂躁都有 DSM标准-出现问题符合标准中一部分且持续一段时间 老年人发病率低-时代 老练 寿命影响 治疗 遗传影响 特别是双向情绪失调 神经递质影响 受体影响强于递质影响 等位基因在压力情况下发病 基因与压力共同作用 大脑皮层不活跃 杏仁核过于敏感 海马萎缩记忆下降 前扣带回失调 药物 SSIR 百忧解副作用小 效果不如老药 锂治疗躁郁 但副作用大 有争议 治疗脱离现实药物 认知行为治疗 负面认知强 思维扭曲 恶性循环 情绪调整 效果类似药物 预防疗法 防复发 药物易复发 实践反馈 人际关系疗法 帮助回忆 梳理关系 精神分裂症 同现实分裂 不同于多重人格 1%发病率 男女发病率差不多 男性发病年龄小18-25 女性26-45 指标（4个阳性表现1个阴性缺失） 幻觉 -幻听（最常见）幻视 妄想 相信不存在的信念-牵连观念 所有信息与你相关 胡言乱语 行为混乱 缺失正常思维 不说话 不关心 亚型（5种） -偏执型-认为被监听 自己了不起 -紧张性-不说话 -疯子 遗传与环境诱因 心灵创伤 病毒流行与精神分裂症相关 服用多巴胺可得到症状 焦虑症 5% 焦虑感强 恐惧感强 备战理论 强迫症 2-3% 反复检查 -可药物治疗 解离型障碍-人格分裂-记忆分裂 失忆-忘记糟糕回忆 杀人犯会有 酒精作用 漫游-开发新身份 完全失忆 新生活 回忆起旧的 新的就忘记了 多重独立人格 发病早 女性 虐待 患者易被催眠 自我催眠 真假存疑 人格障碍 自恋 回避 边缘 偏执 反社会 精神变态 精神疾病可共生 治疗 当魔鬼打死 精神病院 治疗效果很难评价 总体有效 治疗方式对应不同精神疾病 有些行为疗法是无效的 信心 安慰剂效应无治疗价值但可能有效 17.17 幸福-积极心理学 有些很糟糕 有些不错 Marty Seligman《真实的幸福 》 Dan Gilbert 《撞上快乐》 基本问题-你幸福吗？ 大多数人认为自己是幸福的 瑞士最幸福 保加利亚最低 都高于均值 情景影响 幸福为了什么 基本需求变化 但幸福感变化不大 不受影响 关于幸福的事实 环境因素影响不大 有严格的传承性 遗传影响 自然影响 重大悲剧的幸福感缺失是暂时性的 很快恢复 人们高估了幸福影响的持续时间 幸福感预测一般很差 日常无关性 有些事不会每天都有影响 适应 人们会适应一些事 噪音不会适应 形象改变却会持续 可能人们更重视 不断尝试新东西或看淡一点 幸福是相对的 与周边环境相关 幸福的峰终效应 好印象来源于好结果 17.18 心理学导论框架 以上总结源于耶鲁大学公开课《心理学导论》，心理学首先要解决意识来源问题，物质的大脑还是笛卡尔的灵魂？前者就涉及大量的脑科学与神经问题，例如功能分区，心灵地图什么的，后者基本无法研究。然后有了脑就要考虑如何形成意识，首当其冲的就是各种感官，这里面最直接的就是视觉，这里面有不少进化角度的研究工作。感官提供的是感觉，感觉如何成为知觉，知觉如何记忆，这有先后顺序，人的成长也有先后，这就是发展问题。搞清楚发展问题还没完，前面都是对自然过程的记录，认知与学习过程，甚至更早一些的行为主义都是从外在角度研究意识，这就是认知心理学。然后单一行为研究差不多了就该是情绪、人格、睡眠、表情……等高级认知过程，有了这些做基础，下一步就可谈异常了，也就是精神疾病与治疗，这里面有很多量表与治疗手段，其实很多手段个人不自觉的就使用了，有疗效不代表理论可靠（例如精神分析）。以上都是个人角度，放到群体、文化、社会中如何呢？这是一个交叉很广的领域，市面上的经济管理书籍大都取材于社会心理学。如果说有什么内在动力支持的话，我能总结出的有三个，一个是生存进化的理论，基本可以解释很多认知过程，但有点万金油的感觉；另一个就是先天后天之争，很多有影响力的工作都在围绕这个问题展开；还有一个就是意识产生之谜，直觉与理性是很有意思的矛盾统一体。 "],
["section-18.html", "笔记 18 抑郁 18.1 What is Depression? 18.2 Prevalence and Incidence of Major Depressive Episode 18.3 The Natural History of Major Depressive Disorder 18.4 Major Depressive Disorder and Medical Conditions 18.5 Estimating the Burden of Major Depressive Disorder and Medical Conditions 18.6 Does depression look the same across the world? 18.7 Is depression a relevant issue in low- and middle-income countries? 18.8 What predicts depression in low- and middle-income countries? 18.9 Basic Concepts of Epidemiology as Applied to Depression 18.10 Epidemiology of Depression: Risk Factors 18.11 BARRIERS AND SOLUTIONS 18.12 HISTORICAL DEVELOPMENTS &amp; RECENT TRENDS 18.13 QUALITY OF DIAGNOSIS &amp; TREATMENT &amp; INITIATIVES FOR IMPROVEMENT", " 笔记 18 抑郁 18.1 What is Depression? 18.1.1 Diagnostic Criteria of Major Depressive Episode 18.1.1.1 At least one of the following three abnormal moods significantly interfered with the person’s life: Abnormal depressed mood most of the day, nearly every day, for at least two weeks (dysphoria) Abnormal loss of all interest and pleasure most of the day, nearly every day, for at least two weeks (anhedonia) If 18 or younger, abnormal irritable mood most of the day, nearly every day, for at least two weeks 18.1.1.2 At least five of the following symptoms have been present during the same two week depressed period Depressed mood (criterion A, above) Loss of all interest and pleasure (criterion B, above) Appetite or weight disturbance Sleep disturbance Agitation or slowing Fatigue or loss of energy Abnormal inappropriate guilt Poor concentration Thoughts of death or suicide 18.1.2 source Inheritance Stress/Loss 18.2 Prevalence and Incidence of Major Depressive Episode 18.2.1 Prevalence: the proportion in the population with the illness, e.g., a percentage (burden) Define and count the population denominator Count cases for the numerator from that defined population 18.2.2 Incidence: the rate at which new cases form in the population, e.g.rate per time (force of morbidity) Define the population Define the cohort (risk set) who have never had the disorder Define the time period for follow-up Count the number of person years for the denominator Count the number of new cases for the numerator 18.2.3 variety gender: female early age: after 50 lifetime: raise then decrease culture: east low, west high 18.3 The Natural History of Major Depressive Disorder Prodrome is the period after the disease has begun, before it is diagnosed Dysphoria and suicide have a long prodrome Onset is the beginning of the first episode Episodes last several months Remission is the end of the symptoms in an episode Recovery occurs when a year has passed without another episode Recurrence is the start of a later episode after recovery About 50% of all lifetime cases have only one episode About 15% of all lifetime cases are unremitting About 35% of all lifetime cases have a relapsing and remitting course Gender Is Associated With Prevalence of Major Depressive Disorder, But Not With Bipolar Disorder Gender Affects Incidence But Not Recurrence and Duration 18.4 Major Depressive Disorder and Medical Conditions Predictors of Non-Insulin Dependent Diabetes Onset Find connection between Depression and certain illness 18.5 Estimating the Burden of Major Depressive Disorder and Medical Conditions Estimating the Burden of Disease–Disability Weights Disability weight of 0.0 = healthy person Disability weight of 1.0 = death Disability weight of 0.5 = disability weight indicating the prevention program would have to extend life for two years Depression for estimation of disability weight: about 0.35 and top3 around the world 18.6 Does depression look the same across the world? Majority of research on mental health has been done in so called ‘high-income countries’ Our methods/knowledge of mental health originate from research with a minority ‘Western’ (industrialized) population -Category fallacy (Kleinman, 1987): Applying a category that makes sense for a particular cultural group in another group, for whom this category may not make sense Etic: Disease perspective International classification Start with ‘Western’ evidence based treatments Emic: Illness perspective Local terminology and ethnopsychology Build on locally available treatments for mental health 18.7 Is depression a relevant issue in low- and middle-income countries? Despite continued tension between emic and etic approaches, research shows high burden of depression also in low- and middle- income countries. 18.8 What predicts depression in low- and middle-income countries? Poverty Out of 115 studies of poverty and common mental disorder: 79% positive association; 15% no association; 6% negative association More consistent relation with: education, food security, housing,social class, socioeconomic status, financial stress Violence In conflict-affected populations, studies show weighted prevalence of depression: 17.3% (26 studies using random samples and diagnostic interviews) Predictors: potentially traumatic events (OR 1.64); torture (OR 1.48); residency status in asylum seekers (OR 1.30); time since conflict (OR 0.80) 18.9 Basic Concepts of Epidemiology as Applied to Depression Definitions of Epidemiology The study of diseases in populations The study of rates (Langmuir) Prevalence (burden and demand) Incidence (force of morbidity) The study of disease occurrence by time, place, and person (Lilienfeld and Stolley) Seven Uses of Epidemiology (Morris) The study the history of health of populations, facilitating projections in to the future To diagnose the health of the community, which facilitates prioritizing health problems To study the working of health services, with a view towards their improvement To estimate individual risks, and how to avoid them, which can be communicated to individuals To identify syndromes To complete the clinical picture of chronic disease, especially as regards natural history To search for causes of health and disease Time, Space, and Disease: The Ecological Approach Cohort Studies Strengths No recall bias Estimates incidence Estimates Relative Risk Weaknesses Expensive Many controls Long time Attrition bias Case Control Studies Strengths Requires no hypothesis Cases can come from clinics Small number of controls Weaknesses Biased recall (strength) Temporality Controls may not match cases (consistency) 18.10 Epidemiology of Depression: Risk Factors Inheritance Evidence on Inheritance of Depressive Disorder Selected Family Studies - yes Evidence on Inheritance of Depressive Disorder Selected Twin Studies - yes Evidence on Genome-?wide meta?‐analysis -No!(Manhattan plot) Stress and Diathesis Diathesis Stress Model Social Supports Stress increases risk for depressive disorder Social supports are protective from depressive disorder Stress and social supports interact in affecting risk Inherited traits interact with stress in raising risk Low social support is riskier for females Work, Family, and Life Stage(forest plot) Work Environment affects risk for depression Life stage affects risk for Depression among Women in London Parenting Stress affects Maternal Mental Health Recency of Birth: Are we entering an “age of melancholy?” Cohorts born later have higher risk People with depression die sooner Older cohorts are less introspective More treatment availability leads to better recall Older subjects forget more distant episodes We are not entering an “age of melancholy” Appearance of large trends for higher prevalence in later cohorts is probably at least partly an artifact of recall Evidence on trends in rise in incidence is limited, but suggests there has not been a rise in incidence in the past half century There is evidence for a rise in prevalence for women in cohorts born about 1935-1954 Women born 1935-1954 entered work and married life in 1955-1974 These cohorts of females may have greater chronicity of depression than earlier or later cohorts Trends in social supports and divorce may be connected to trends in chronicity of depression for women 18.11 BARRIERS AND SOLUTIONS Large proportions of individuals with major depression do not seek mental health treatment. There variations in treatment seeking according to social and demographic factors such as age, sex and racial/ethnic group. Barriers include lack of perceived need, negative attitudes towards treatments, stigma and structural barriers. Legislative initiatives and antistigma campaigns attempt to reduce these barriers. 18.12 HISTORICAL DEVELOPMENTS &amp; RECENT TRENDS Possible reasons for recent trends in treatment of major depression Increased popularity of antidepressant medications among providers and the general population. Fewer side effects of newer antidepressants (practice innovation). Increased treatment of major depression in general medical settings. Aggressive marketing practices by pharmaceutical companies. Greater recognition of “major depression” as an illness. 18.13 QUALITY OF DIAGNOSIS &amp; TREATMENT &amp; INITIATIVES FOR IMPROVEMENT Diagnosis of depression, at least in the US has increased over the past 2-3 decades. Much of the care for depression in community settings is done by primary care and other general medical providers. Many patients with depression, however, are not detected and many individuals who are given the diagnosis do not meet the criteria (false negative and false positive problem). The quality of depression care in the community falls short of standards. Prevention of depression is possible through selective and indicated preventive interventions. "],
["section-19.html", "笔记 19 贝叶斯统计 19.1 贝塔分布 19.2 为什么击球的概率分布符合贝塔分布？ 19.3 先验与后验 19.4 经验贝叶斯 19.5 从整体到个人 19.6 可信区间与置信区间 19.7 后验错误率 19.8 错误发现率（FDR） 19.9 q值 19.10 贝叶斯视角的假设检验 19.11 比例检验 19.12 错误率控制 19.13 影响因子 19.14 混合概率模型 19.15 模拟验证", " 笔记 19 贝叶斯统计 19.1 贝塔分布 贝塔分布的本质是概率分布的分布 棒球击球率的预测问题，你不可能预测一个刚打出本垒下一个也击中，会有一个先验概率 这个概率可以用一个参数 \\(\\alpha\\) 与 \\(\\beta\\) 的贝塔分布来描述，例如一共打了300个球，81个击中，219个击空，那么 \\(\\alpha\\) 为81，\\(\\beta\\) 为219 均值为\\(\\frac{\\alpha}{\\alpha + \\beta} = \\frac{81}{81+219} = 0.27\\) 概率密度分布图，从图上我们可以看出一个大约在0.2-0.35的概率区间，表示击球的先验概率空间可能的取值 library(ggplot2) x &lt;- seq(0,1,length=100) db &lt;- dbeta(x, 81, 219) ggplot() + geom_line(aes(x,db)) + ylab(&quot;Density of beta&quot;) 19.2 为什么击球的概率分布符合贝塔分布？ 设想球员A打了一个球打中了，那么在没有先验知识的情况下我会认为他击中概率为1 这个球员又打中了一个球，那么还是1 但第三个没打中，我们会认为他击中概率是0吗？ 一般而言，这类连续击球问题可以用二项分布来描述，例如10个球打中8个的概率，我们假设这个击球概率为q，那么这个概率应该是个q的函数： \\[f(q) \\propto q^a(1-q)^b\\] q对于一个实际问题是确定的常数，所以出现这个场景的概率实际上是a与b的函数 为了保障这个概率函数累积为1，需要除一个跟a与b有关的数 这个数可以用贝塔函数\\(B(a,b)\\)来表示，数学证明略 如果接着打了一个中了，那么如何更新这个概率？ 根据贝叶斯公式，最后推导出的结果如下： \\[Beta(\\alpha+1,\\beta+0)\\] 那么我们对这个击球率的估计就略高了一点，这是贝塔分布的神奇之处，形式非常简单，理解也很直观 19.3 先验与后验 如果我们后续观察的击球少，那么不太容易影响到对概率的先验估计 x &lt;- seq(0,1,length=100) db &lt;- dbeta(x, 81+1, 219) ggplot() + geom_line(aes(x,db)) + ylab(&quot;Density of beta&quot;) 如果后续观察了大量的击球都中了，那么概率会偏向后面数据量的那一部分 x &lt;- seq(0,1,length=100) db &lt;- dbeta(x, 81+1000, 219) ggplot() + geom_line(aes(x,db)) + ylab(&quot;Density of beta&quot;) 这是贝叶斯分析的核心思想，通过证据更新经验 最后得到的均值（后验0.83）一定是介于经验值（先验0.27）与证据值（全击中就是1）之间 贝塔分布天然适合描述一个对概率的估计场景 另一种不那么严谨的理解方法是如果一个概率是稳定的，那么多次实验的结果差别不会太大，则有： \\[\\frac{a}{b} = \\frac{c}{d} = \\frac{a+b}{c+d}\\] 如果每次实验的概率持平，那么不存在不确定度；但如果前面实验的次数少而后面实验的次数多，那么概率会偏重于后面，这就是贝塔分布想说明的事 19.4 经验贝叶斯 对于两个球员，一个打了10个球中了4个，另一个打了1000个球中了300个，一般击中概率0.2，你会选哪一个？ 我们对于小样本量的统计推断会有天然的不信任，如何通过统计量来描述？ 下面用MLB的数据说明，首先提取出球员的击球数据： library(knitr) library(dplyr) library(tidyr) library(Lahman) # 拿到击球数据 career &lt;- Batting %&gt;% filter(AB &gt; 0) %&gt;% anti_join(Pitching, by = &quot;playerID&quot;) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB)) %&gt;% mutate(average = H / AB) # 把ID换成球员名字 career &lt;- Master %&gt;% tbl_df() %&gt;% select(playerID, nameFirst, nameLast) %&gt;% unite(name, nameFirst, nameLast, sep = &quot; &quot;) %&gt;% inner_join(career, by = &quot;playerID&quot;) %&gt;% select(-playerID) # 展示数据 career ## # A tibble: 9,429 × 4 ## name H AB average ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Hank Aaron 3771 12364 0.3050 ## 2 Tommie Aaron 216 944 0.2288 ## 3 Andy Abad 2 21 0.0952 ## 4 John Abadie 11 49 0.2245 ## 5 Ed Abbaticchio 772 3044 0.2536 ## 6 Fred Abbott 107 513 0.2086 ## 7 Jeff Abbott 157 596 0.2634 ## 8 Kurt Abbott 523 2044 0.2559 ## 9 Ody Abbott 13 70 0.1857 ## 10 Frank Abercrombie 0 4 0.0000 ## # ... with 9,419 more rows # 击球前5 career %&gt;% arrange(desc(average)) %&gt;% head(5) %&gt;% kable() name H AB average Jeff Banister 1 1 1 Doc Bass 1 1 1 Steve Biras 2 2 1 C. B. Burns 1 1 1 Jackie Gallagher 1 1 1 # 击球后5 career %&gt;% arrange(average) %&gt;% head(5) %&gt;% kable() name H AB average Frank Abercrombie 0 4 0 Lane Adams 0 3 0 Horace Allen 0 7 0 Pete Allen 0 4 0 Walter Alston 0 1 0 如果仅考虑击球率会把很多板凳球员与运气球员包括进来，一个先验概率分布很有必要 那么考虑下如何得到，经验贝叶斯方法认为如果估计一个个体的参数，那么这个个体所在的整体的概率分布可作为先验概率分布 这个先验概率分布可以直接从数据中得到，然后我们要用极大似然或矩估计的方法拿到贝塔分布的两个参数： career_filtered &lt;- career %&gt;% filter(AB &gt;= 500) m &lt;- MASS::fitdistr(career_filtered$average, dbeta, start = list(shape1 = 1, shape2 = 10)) alpha0 &lt;- m$estimate[1] beta0 &lt;- m$estimate[2] # 看下拟合效果 ggplot(career_filtered) + geom_histogram(aes(average, y = ..density..), binwidth = .005) + stat_function(fun = function(x) dbeta(x, alpha0, beta0), color = &quot;red&quot;, size = 1) + xlab(&quot;Batting average&quot;) 19.5 从整体到个人 当我们估计个人的击球率时，整体可以作为先验函数，个人的数据可以通过贝塔分布更新到个体 那么如果一个人数据少，我们倾向于认为他是平均水平；数据多则认为符合个人表现 这事实上是一个分层结构，经验贝叶斯推断里隐含了这么一个从整体到个人的过程 career_eb &lt;- career %&gt;% mutate(eb_estimate = (H + alpha0) / (AB + alpha0 + beta0)) # 击球率高 career_eb %&gt;% arrange(desc(eb_estimate)) %&gt;% head(5) %&gt;% kable() name H AB average eb_estimate Rogers Hornsby 2930 8173 0.358 0.355 Shoeless Joe Jackson 1772 4981 0.356 0.350 Ed Delahanty 2596 7505 0.346 0.343 Billy Hamilton 2158 6268 0.344 0.340 Harry Heilmann 2660 7787 0.342 0.338 # 击球率低 career_eb %&gt;% arrange(eb_estimate) %&gt;% head(5) %&gt;% kable() name H AB average eb_estimate Bill Bergen 516 3028 0.170 0.178 Ray Oyler 221 1265 0.175 0.191 John Vukovich 90 559 0.161 0.196 John Humphries 52 364 0.143 0.196 George Baker 74 474 0.156 0.196 # 整体估计 ggplot(career_eb, aes(average, eb_estimate, color = AB)) + geom_hline(yintercept = alpha0 / (alpha0 + beta0), color = &quot;red&quot;, lty = 2) + geom_point() + geom_abline(color = &quot;red&quot;) + scale_colour_gradient(trans = &quot;log&quot;, breaks = 10 ^ (1:5)) + xlab(&quot;Batting average&quot;) + ylab(&quot;Empirical Bayes batting average&quot;) 数据点多会收缩到\\(x=y\\)，也就是个人的击球率；数据点少则回归到整体击球率 这就是经验贝叶斯方法的全貌：先估计整体的参数，然后把整体参数作为先验概率估计个人参数 19.6 可信区间与置信区间 经验贝叶斯可以给出点估计，但现实中我们可能更关心区间估计 一般这类区间估计可以用二项式比例估计来进行，不过没有先验经验的限制置信区间大到没意义 经验贝叶斯会给出一个后验分布，这个分布可以用来求可信区间 # 给出后验分布 career &lt;- Batting %&gt;% filter(AB &gt; 0) %&gt;% anti_join(Pitching, by = &quot;playerID&quot;) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB)) %&gt;% mutate(average = H / AB) career &lt;- Master %&gt;% tbl_df() %&gt;% dplyr::select(playerID, nameFirst, nameLast) %&gt;% unite(name, nameFirst, nameLast, sep = &quot; &quot;) %&gt;% inner_join(career, by = &quot;playerID&quot;) career0 &lt;- Batting %&gt;% filter(AB &gt; 0) %&gt;% anti_join(Pitching, by = &quot;playerID&quot;) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB), year = mean(yearID)) %&gt;% mutate(average = H / AB) career2 &lt;- Master %&gt;% tbl_df() %&gt;% dplyr::select(playerID, nameFirst, nameLast, bats) %&gt;% unite(name, nameFirst, nameLast, sep = &quot; &quot;) %&gt;% inner_join(career0, by = &quot;playerID&quot;) career_eb &lt;- career %&gt;% mutate(eb_estimate = (H + alpha0) / (AB + alpha0 + beta0)) career_eb &lt;- career_eb %&gt;% mutate(alpha1 = H + alpha0, beta1 = AB - H + beta0) # 提取洋基队的数据 yankee_1998 &lt;- c(&quot;brosisc01&quot;, &quot;jeterde01&quot;, &quot;knoblch01&quot;, &quot;martiti02&quot;, &quot;posadjo01&quot;, &quot;strawda01&quot;, &quot;willibe02&quot;) yankee_1998_career &lt;- career_eb %&gt;% filter(playerID %in% yankee_1998) # 展示球员的后验分布 library(broom) yankee_beta &lt;- yankee_1998_career %&gt;% inflate(x = seq(.18, .33, .0002)) %&gt;% ungroup() %&gt;% mutate(density = dbeta(x, alpha1, beta1)) ggplot(yankee_beta, aes(x, density, color = name)) + geom_line() + stat_function(fun = function(x) dbeta(x, alpha0, beta0), lty = 2, color = &quot;black&quot;) # 提取可信区间 yankee_1998_career &lt;- yankee_1998_career %&gt;% mutate(low = qbeta(.025, alpha1, beta1), high = qbeta(.975, alpha1, beta1)) yankee_1998_career %&gt;% dplyr::select(-alpha1, -beta1, -eb_estimate) %&gt;% knitr::kable() playerID name H AB average low high brosisc01 Scott Brosius 1001 3889 0.257 0.244 0.271 jeterde01 Derek Jeter 3465 11195 0.310 0.300 0.317 knoblch01 Chuck Knoblauch 1839 6366 0.289 0.277 0.298 martiti02 Tino Martinez 1925 7111 0.271 0.260 0.280 posadjo01 Jorge Posada 1664 6092 0.273 0.262 0.283 strawda01 Darryl Strawberry 1401 5418 0.259 0.247 0.270 willibe02 Bernie Williams 2336 7869 0.297 0.286 0.305 # 绘制可信区间 yankee_1998_career %&gt;% mutate(name = reorder(name, average)) %&gt;% ggplot(aes(average, name)) + geom_point() + geom_errorbarh(aes(xmin = low, xmax = high)) + geom_vline(xintercept = alpha0 / (alpha0 + beta0), color = &quot;red&quot;, lty = 2) + xlab(&quot;Estimated batting average (w/ 95% interval)&quot;) + ylab(&quot;Player&quot;) # 对比置信区间与可信区间 career_eb &lt;- career_eb %&gt;% mutate(low = qbeta(.025, alpha1, beta1), high = qbeta(.975, alpha1, beta1)) set.seed(2016) some &lt;- career_eb %&gt;% sample_n(20) %&gt;% mutate(name = paste0(name, &quot; (&quot;, H, &quot;/&quot;, AB, &quot;)&quot;)) frequentist &lt;- some %&gt;% group_by(playerID, name, AB) %&gt;% do(tidy(binom.test(.$H, .$AB))) %&gt;% dplyr::select(playerID, name, estimate, low = conf.low, high = conf.high) %&gt;% mutate(method = &quot;Confidence&quot;) bayesian &lt;- some %&gt;% dplyr::select(playerID, name, AB, estimate = eb_estimate, low = low, high = high) %&gt;% mutate(method = &quot;Credible&quot;) combined &lt;- bind_rows(frequentist, bayesian) combined %&gt;% mutate(name2 = reorder(name, -AB)) %&gt;% ggplot(aes(estimate, name2, color = method, group = method)) + geom_point() + geom_errorbarh(aes(xmin = low, xmax = high)) + geom_vline(xintercept = alpha0 / (alpha0 + beta0), color = &quot;red&quot;, lty = 2) + xlab(&quot;Estimated batting average&quot;) + ylab(&quot;Player&quot;) + labs(color = &quot;&quot;) 可信区间与置信区间很大的区别在于前者考虑了先验概率进而实现了区间的收缩，后者则可看作无先验贝塔分布给出的区间估计，频率学派目前没有很好的收缩区间估计的方法 19.7 后验错误率 现实问题经常不局限于估计，而是侧重决策，例如如果一个球员的击球率高于某个值，他就可以进入名人堂（击球率大于0.3），这个决策常常伴随区间估计而不是简单的点估计 # 以 Hank Aaron 为例 career_eb %&gt;% filter(name == &quot;Hank Aaron&quot;) %&gt;% do(data_frame(x = seq(.27, .33, .0002), density = dbeta(x, .$alpha1, .$beta1))) %&gt;% ggplot(aes(x, density)) + geom_line() + geom_ribbon(aes(ymin = 0, ymax = density * (x &lt; .3)), alpha = .1, fill = &quot;red&quot;) + geom_vline(color = &quot;red&quot;, lty = 2, xintercept = .3) # 提取该球员数据 career_eb %&gt;% filter(name == &quot;Hank Aaron&quot;) ## # A tibble: 1 × 10 ## playerID name H AB average eb_estimate alpha1 beta1 low ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 aaronha01 Hank Aaron 3771 12364 0.305 0.304 3850 8819 0.296 ## # ... with 1 more variables: high &lt;dbl&gt; # 计算其不进入名人堂的概率 pbeta(.3, 3850, 8818) ## [1] 0.169 后验错误率（Posterior Error Probability）可类比经典假设检验中的显著性水平\\(\\alpha\\) 后验包括率（Posterior Inclusion Probability）可类比经典假设检验中的置信水平\\(1-\\alpha\\) # 所有球员的后验错误率分布，大部分不超过0.3 career_eb &lt;- career_eb %&gt;% mutate(PEP = pbeta(.3, alpha1, beta1)) ggplot(career_eb, aes(PEP)) + geom_histogram(binwidth = .02) + xlab(&quot;Posterior Error Probability (PEP)&quot;) + xlim(0, 1) # 后验错误率与击球率的关系 career_eb %&gt;% ggplot(aes(eb_estimate, PEP, color = AB)) + geom_point(size = 1) + xlab(&quot;(Shrunken) batting average estimate&quot;) + ylab(&quot;Posterior Error Probability (PEP)&quot;) + geom_vline(color = &quot;red&quot;, lty = 2, xintercept = .3) + scale_colour_gradient(trans = &quot;log&quot;, breaks = 10 ^ (1:5)) 后验错误率高于0.3的多数是击球率与击球数都高的人，因为贝叶斯方法惩罚了击球数低的人 19.8 错误发现率（FDR） FDR可用来控制一个整体决策，保证整体犯错的概率低于某个数值，错误发现率越高，越可能把假阳性包括进来 假如我们把进入名人堂的决策作为一个整体，则可允许一定的整体错误率，因为每个人的后验错误率可以计算且期望值线性可加和，我们可以得到一个整体的错误率 # 取前100个球员 top_players &lt;- career_eb %&gt;% arrange(PEP) %&gt;% head(100) # 总错率率 sum(top_players$PEP) ## [1] 5 # 平均错误率 mean(top_players$PEP) ## [1] 0.05 # 错误率随所取球员的变化 sorted_PEP &lt;- career_eb %&gt;% arrange(PEP) mean(head(sorted_PEP$PEP, 50)) ## [1] 0.00183 mean(head(sorted_PEP$PEP, 200)) ## [1] 0.246 错误率在排序后前面低后面高，但这个错误率不特指某个球员，而是包含到某个球员的整体犯错的概率 19.9 q值 q值定义为排序后累积到某个样本的整体平均错误率，类似多重比较中对整体错误率控制的p值 # 生成每个球员的q值 career_eb &lt;- career_eb %&gt;% arrange(PEP) %&gt;% mutate(qvalue = cummean(PEP)) # 观察不同q值对名人堂球员数的影响 career_eb %&gt;% ggplot(aes(qvalue, rank(PEP))) + geom_line() + xlab(&quot;q-value cutoff&quot;) + ylab(&quot;Number of players included&quot;) # 观察小q值部分 career_eb %&gt;% filter(qvalue &lt; .25) %&gt;% ggplot(aes(qvalue, rank(PEP))) + geom_line() + xlab(&quot;q-value cutoff&quot;) + ylab(&quot;Number of players included&quot;) 200个人进入名人堂可能有约1/4的球员不合适，如果是50个人进入名人堂那么基本不会犯错 q值是一个整体而非个体的平均错误率，具有累积性，不代表q值大的那一个就是错的 q值在频率学派的多重比较里也有定义，虽然没有空假设（有先验概率），但实质等同 19.10 贝叶斯视角的假设检验 前面描述的是击球率如何求，如何进行区间估计与多个体的错误率控制，面向的个体或整体，那么如何解决比较问题 设想多个球员，我们考虑如何去比较他们击球率 # 选三个球员 career_eb %&gt;% filter(name %in% c(&quot;Hank Aaron&quot;, &quot;Mike Piazza&quot;, &quot;Hideki Matsui&quot;)) %&gt;% inflate(x = seq(.26, .33, .00025)) %&gt;% mutate(density = dbeta(x, alpha1, beta1)) %&gt;% ggplot(aes(x, density, color = name)) + geom_line() + labs(x = &quot;Batting average&quot;, color = &quot;&quot;) 如果两个球员击球率的概率密度曲线比较接近，那么即便均值有不同我们也无法进行区分；如果重叠比较少，那么我们有理由认为他们之间的差异显著 贝叶斯视角下如何定量描述这个差异是否显著？ 19.10.1 模拟 单纯取样比大小然后计算比例 # 提取两人数据 aaron &lt;- career_eb %&gt;% filter(name == &quot;Hank Aaron&quot;) piazza &lt;- career_eb %&gt;% filter(name == &quot;Mike Piazza&quot;) # 模拟取样10万次 piazza_simulation &lt;- rbeta(1e6, piazza$alpha1, piazza$beta1) aaron_simulation &lt;- rbeta(1e6, aaron$alpha1, aaron$beta1) # 计算一个人超过另一个人的概率 sim &lt;- mean(piazza_simulation &gt; aaron_simulation) sim ## [1] 0.606 19.10.2 数值积分 两个概率的联合概率分布，然后积分一个队员大于另一个的概率 d &lt;- .00002 limits &lt;- seq(.29, .33, d) sum(outer(limits, limits, function(x, y) { (x &gt; y) * dbeta(x, piazza$alpha1, piazza$beta1) * dbeta(y, aaron$alpha1, aaron$beta1) * d ^ 2 })) ## [1] 0.604 19.10.3 解析解 两个贝塔分布一个比另一个高是有含有贝塔函数的解析解的： \\[p_A \\sim \\mbox{Beta}(\\alpha_A, \\beta_A)\\] \\[p_B \\sim \\mbox{Beta}(\\alpha_B, \\beta_B)\\] \\[{\\rm Pr}(p_B &gt; p_A) = \\sum_{i=0}^{\\alpha_B-1}\\frac{B(\\alpha_A+i,\\beta_A+\\beta_B)}{(\\beta_B+i) B(1+i, \\beta_B) B(\\alpha_A, \\beta_A) }\\] h &lt;- function(alpha_a, beta_a, alpha_b, beta_b) { j &lt;- seq.int(0, round(alpha_b) - 1) log_vals &lt;- (lbeta(alpha_a + j, beta_a + beta_b) - log(beta_b + j) - lbeta(1 + j, beta_b) - lbeta(alpha_a, beta_a)) 1 - sum(exp(log_vals)) } h(piazza$alpha1, piazza$beta1, aaron$alpha1, aaron$beta1) ## [1] 0.605 19.10.4 正态近似求解 贝塔分布在\\(\\alpha\\)与\\(\\beta\\)比较大时接近正态分布，可以直接用正态分布的解析解求，速度快很多 h_approx &lt;- function(alpha_a, beta_a, alpha_b, beta_b) { u1 &lt;- alpha_a / (alpha_a + beta_a) u2 &lt;- alpha_b / (alpha_b + beta_b) var1 &lt;- alpha_a * beta_a / ((alpha_a + beta_a) ^ 2 * (alpha_a + beta_a + 1)) var2 &lt;- alpha_b * beta_b / ((alpha_b + beta_b) ^ 2 * (alpha_b + beta_b + 1)) pnorm(0, u2 - u1, sqrt(var1 + var2)) } h_approx(piazza$alpha1, piazza$beta1, aaron$alpha1, aaron$beta1) ## [1] 0.606 19.11 比例检验 这是个列联表问题，频率学派对比两个比例 two_players &lt;- bind_rows(aaron, piazza) two_players %&gt;% transmute(Player = name, Hits = H, Misses = AB - H) %&gt;% knitr::kable() Player Hits Misses Hank Aaron 3771 8593 Mike Piazza 2127 4784 prop.test(two_players$H, two_players$AB) ## ## 2-sample test for equality of proportions with continuity ## correction ## ## data: two_players$H out of two_players$AB ## X-squared = 0.1, df = 1, p-value = 0.7 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.0165 0.0109 ## sample estimates: ## prop 1 prop 2 ## 0.305 0.308 贝叶斯学派对比两个比例 credible_interval_approx &lt;- function(a, b, c, d) { u1 &lt;- a / (a + b) u2 &lt;- c / (c + d) var1 &lt;- a * b / ((a + b) ^ 2 * (a + b + 1)) var2 &lt;- c * d / ((c + d) ^ 2 * (c + d + 1)) mu_diff &lt;- u2 - u1 sd_diff &lt;- sqrt(var1 + var2) data_frame(posterior = pnorm(0, mu_diff, sd_diff), estimate = mu_diff, conf.low = qnorm(.025, mu_diff, sd_diff), conf.high = qnorm(.975, mu_diff, sd_diff)) } credible_interval_approx(piazza$alpha1, piazza$beta1, aaron$alpha1, aaron$beta1) ## # A tibble: 1 × 4 ## posterior estimate conf.low conf.high ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.606 -0.00182 -0.0151 0.0115 多个球员对比一个 set.seed(2016) intervals &lt;- career_eb %&gt;% filter(AB &gt; 10) %&gt;% sample_n(20) %&gt;% group_by(name, H, AB) %&gt;% do(credible_interval_approx(piazza$alpha1, piazza$beta1, .$alpha1, .$beta1)) %&gt;% ungroup() %&gt;% mutate(name = reorder(paste0(name, &quot; (&quot;, H, &quot; / &quot;, AB, &quot;)&quot;), -estimate)) f &lt;- function(H, AB) broom::tidy(prop.test(c(H, piazza$H), c(AB, piazza$AB))) prop_tests &lt;- purrr::map2_df(intervals$H, intervals$AB, f) %&gt;% mutate(estimate = estimate1 - estimate2, name = intervals$name) all_intervals &lt;- bind_rows( mutate(intervals, type = &quot;Credible&quot;), mutate(prop_tests, type = &quot;Confidence&quot;) ) ggplot(all_intervals, aes(x = estimate, y = name, color = type)) + geom_point() + geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) + xlab(&quot;Piazza average - player average&quot;) + ylab(&quot;Player&quot;) 置信区间与可信区间的主要差异来自于经验贝叶斯的区间收敛 19.12 错误率控制 如果我打算交易一个球员，那么如何筛选候选人？ 先选那些击球率更好的球员 # 对比打算交易的球员与其他球员 career_eb_vs_piazza &lt;- bind_cols( career_eb, credible_interval_approx(piazza$alpha1, piazza$beta1, career_eb$alpha1, career_eb$beta1)) %&gt;% dplyr::select(name, posterior, conf.low, conf.high) career_eb_vs_piazza ## # A tibble: 9,429 × 4 ## name posterior conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Rogers Hornsby 2.84e-11 0.0345 0.0639 ## 2 Ed Delahanty 7.10e-07 0.0218 0.0518 ## 3 Shoeless Joe Jackson 8.77e-08 0.0278 0.0611 ## 4 Willie Keeler 4.62e-06 0.0183 0.0472 ## 5 Nap Lajoie 1.62e-05 0.0158 0.0441 ## 6 Tony Gwynn 1.83e-05 0.0157 0.0442 ## 7 Harry Heilmann 7.19e-06 0.0180 0.0476 ## 8 Lou Gehrig 1.43e-05 0.0167 0.0461 ## 9 Billy Hamilton 7.03e-06 0.0190 0.0503 ## 10 Eddie Collins 2.00e-04 0.0113 0.0393 ## # ... with 9,419 more rows # 计算q值 career_eb_vs_piazza &lt;- career_eb_vs_piazza %&gt;% arrange(posterior) %&gt;% mutate(qvalue = cummean(posterior)) # 筛选那些q值小于0.05的 better &lt;- career_eb_vs_piazza %&gt;% filter(qvalue &lt; .05) better ## # A tibble: 49 × 5 ## name posterior conf.low conf.high qvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Rogers Hornsby 2.84e-11 0.0345 0.0639 2.84e-11 ## 2 Shoeless Joe Jackson 8.77e-08 0.0278 0.0611 4.39e-08 ## 3 Ed Delahanty 7.10e-07 0.0218 0.0518 2.66e-07 ## 4 Willie Keeler 4.62e-06 0.0183 0.0472 1.35e-06 ## 5 Billy Hamilton 7.03e-06 0.0190 0.0503 2.49e-06 ## 6 Harry Heilmann 7.19e-06 0.0180 0.0476 3.27e-06 ## 7 Lou Gehrig 1.43e-05 0.0167 0.0461 4.85e-06 ## 8 Nap Lajoie 1.62e-05 0.0158 0.0441 6.27e-06 ## 9 Tony Gwynn 1.83e-05 0.0157 0.0442 7.61e-06 ## 10 Bill Terry 3.03e-05 0.0162 0.0472 9.88e-06 ## # ... with 39 more rows 这样我们筛到一个可交易的群体，总和错误率不超过5% 19.13 影响因子 击球率高除了能力影响外还有可能是因为得到的机会多或者光环效应，例如一开始凭运气打得好，后面给机会多，通过经验累积提高了击球率 career %&gt;% filter(AB &gt;= 20) %&gt;% ggplot(aes(AB, average)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_x_log10() 击球数低方差会大，这比较正常，很多人挂在起跑线上了 直接使用经验贝叶斯方法会导致整体向均值收敛，这高估了新手的数据 prior_mu &lt;- alpha0 / (alpha0 + beta0) career_eb %&gt;% filter(AB &gt;= 20) %&gt;% gather(type, value, average, eb_estimate) %&gt;% mutate(type = plyr::revalue(type, c(average = &quot;Raw&quot;, eb_estimate = &quot;With EB Shrinkage&quot;))) %&gt;% ggplot(aes(AB, value)) + geom_point() + scale_x_log10() + geom_hline(color = &quot;red&quot;, lty = 2, size = 1.5, yintercept = prior_mu) + facet_wrap(~type) + ylab(&quot;average&quot;) + geom_smooth(method = &quot;lm&quot;) 为了如实反应这种情况，我们应该认为击球率符合贝塔分布，但同时贝塔分布的两个参数受击球数的影响，击球数越多，越可能击中 这个模型可以用贝塔－二项式回归来描述 \\[\\mu_i = \\mu_0 + \\mu_{\\mbox{AB}} \\cdot \\log(\\mbox{AB})\\] \\[\\alpha_{0,i} = \\mu_i / \\sigma_0\\] \\[\\beta_{0,i} = (1 - \\mu_i) / \\sigma_0\\] \\[p_i \\sim \\mbox{Beta}(\\alpha_{0,i}, \\beta_{0,i})\\] \\[H_i \\sim \\mbox{Binom}(\\mbox{AB}_i, p_i)\\] 19.13.1 拟合模型 寻找拟合后的模型参数，构建新的先验概率 library(gamlss) # 拟合模型 fit &lt;- gamlss(cbind(H, AB - H) ~ log(AB), data = career_eb, family = BB(mu.link = &quot;identity&quot;)) ## GAMLSS-RS iteration 1: Global Deviance = 91967 ## GAMLSS-RS iteration 2: Global Deviance = 72747 ## GAMLSS-RS iteration 3: Global Deviance = 68633 ## GAMLSS-RS iteration 4: Global Deviance = 68627 ## GAMLSS-RS iteration 5: Global Deviance = 68627 # 展示拟合参数 td &lt;- tidy(fit) td ## parameter term estimate std.error statistic p.value ## 1 mu (Intercept) 0.1444 0.00161 89.8 0 ## 2 mu log(AB) 0.0151 0.00022 68.6 0 ## 3 sigma (Intercept) -6.3378 0.02483 -255.3 0 # 构建新的先验概率 mu_0 &lt;- td$estimate[1] mu_AB &lt;- td$estimate[2] sigma &lt;- exp(td$estimate[3]) # 看看AB对先验概率的影响 crossing(x = seq(0.08, .35, .001), AB = c(1, 10, 100, 1000, 10000)) %&gt;% mutate(density = dbeta(x, (mu_0 + mu_AB * log(AB)) / sigma, (1 - (mu_0 + mu_AB * log(AB))) / sigma)) %&gt;% mutate(AB = factor(AB)) %&gt;% ggplot(aes(x, density, color = AB, group = AB)) + geom_line() + xlab(&quot;Batting average&quot;) + ylab(&quot;Prior density&quot;) 19.13.2 求后验概率 # 计算所有拟合值 mu &lt;- fitted(fit, parameter = &quot;mu&quot;) sigma &lt;- fitted(fit, parameter = &quot;sigma&quot;) # 计算所有后验概率 career_eb_wAB &lt;- career_eb %&gt;% dplyr::select(name, H, AB, original_eb = eb_estimate) %&gt;% mutate(mu = mu, alpha0 = mu / sigma, beta0 = (1 - mu) / sigma, alpha1 = alpha0 + H, beta1 = beta0 + AB - H, new_eb = alpha1 / (alpha1 + beta1)) # 展示拟合后的击球率 ggplot(career_eb_wAB, aes(original_eb, new_eb, color = AB)) + geom_point() + geom_abline(color = &quot;red&quot;) + xlab(&quot;Original EB Estimate&quot;) + ylab(&quot;EB Estimate w/ AB term&quot;) + scale_color_continuous(trans = &quot;log&quot;, breaks = 10 ^ (0:4)) # 对比 library(tidyr) lev &lt;- c(raw = &quot;Raw H / AB&quot;, original_eb = &quot;EB Estimate&quot;, new_eb = &quot;EB w/ Regression&quot;) career_eb_wAB %&gt;% filter(AB &gt;= 10) %&gt;% mutate(raw = H / AB) %&gt;% gather(type, value, raw, original_eb, new_eb) %&gt;% mutate(mu = ifelse(type == &quot;original_eb&quot;, prior_mu, ifelse(type == &quot;new_eb&quot;, mu, NA))) %&gt;% mutate(type = factor(plyr::revalue(type, lev), lev)) %&gt;% ggplot(aes(AB, value)) + geom_point() + geom_line(aes(y = mu), color = &quot;red&quot;) + scale_x_log10() + facet_wrap(~type) + xlab(&quot;At-Bats (AB)&quot;) + ylab(&quot;Estimate&quot;) 矫正后我们的数据更复合现实了，其实这是贝叶斯分层模型的一个简单版本，通过考虑更多因素，我们可以构建更复杂的模型来挖掘出我们所需要的信息 19.13.3 考虑更多因素 现在我们听说左利手跟右利手的表现可能不一样，所以我们要对模型进行完善，考虑把左右手参数加入模型 # 展示数据 career2 %&gt;% count(bats) ## # A tibble: 4 × 2 ## bats n ## &lt;fctr&gt; &lt;int&gt; ## 1 B 767 ## 2 L 2653 ## 3 R 5351 ## 4 NA 658 # 排除NA career3 &lt;- career2 %&gt;% filter(!is.na(bats)) %&gt;% mutate(bats = relevel(bats, &quot;R&quot;)) # 重建模型 fit2 &lt;- gamlss(cbind(H, AB - H) ~ log(AB) + bats, data = career3, family = BB(mu.link = &quot;identity&quot;)) ## GAMLSS-RS iteration 1: Global Deviance = 88216 ## GAMLSS-RS iteration 2: Global Deviance = 69532 ## GAMLSS-RS iteration 3: Global Deviance = 65403 ## GAMLSS-RS iteration 4: Global Deviance = 65397 ## GAMLSS-RS iteration 5: Global Deviance = 65397 # 观察参数 tidy(fit2) ## parameter term estimate std.error statistic p.value ## 1 mu (Intercept) 0.14288 0.001651 86.55 0.00e+00 ## 2 mu log(AB) 0.01489 0.000223 66.79 0.00e+00 ## 3 mu batsB -0.00129 0.000998 -1.29 1.98e-01 ## 4 mu batsL 0.00987 0.000640 15.42 6.32e-53 ## 5 sigma (Intercept) -6.42525 0.025315 -253.82 0.00e+00 sigma &lt;- fitted(fit2, &quot;sigma&quot;)[1] crossing(bats = c(&quot;L&quot;, &quot;R&quot;), AB = c(1, 10, 100, 1000, 10000)) %&gt;% augment(fit2, newdata = .) %&gt;% rename(mu = .fitted) %&gt;% crossing(x = seq(.1, .36, .0005)) %&gt;% mutate(alpha = mu / sigma, beta = (1 - mu) / sigma, density = dbeta(x, alpha, beta)) %&gt;% ggplot(aes(x, density, color = factor(AB), lty = bats)) + geom_line() + labs(x = &quot;Batting average&quot;, y = &quot;Prior density&quot;, color = &quot;AB&quot;, lty = &quot;Batting hand&quot;) 存在先验概率的情况下，可以考虑考察随着击球数增长左右手的不同 crossing(bats = c(&quot;L&quot;, &quot;R&quot;), AB = c(10, 100, 1000, 10000)) %&gt;% augment(fit2, newdata = .) %&gt;% mutate(H = .3 * AB, alpha0 = .fitted / sigma, beta0 = (1 - .fitted) / sigma, alpha1 = alpha0 + H, beta1 = beta0 + AB - H, estimate = alpha1 / (alpha1 + beta1), conf.low = qbeta(.025, alpha1, beta1), conf.high = qbeta(.975, alpha1, beta1), record = paste(H, AB, sep = &quot; / &quot;)) %&gt;% ggplot(aes(estimate, record, color = bats)) + geom_point() + geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) + labs(x = &quot;Estimate w/ 95% credible interval&quot;, y = &quot;Batting record&quot;, color = &quot;Batting hand&quot;) 另一个要考虑的因素是不同年份的平均击球率可能也有起伏 career3 %&gt;% mutate(decade = factor(round(year - 5, -1))) %&gt;% filter(AB &gt;= 500) %&gt;% ggplot(aes(decade, average)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Batting average&quot;) # 用样条插值来进行拟合 library(splines) fit3 &lt;- gamlss(cbind(H, AB - H) ~ 0 + ns(year, df = 5) + bats + log(AB), data = career3, family = BB(mu.link = &quot;identity&quot;)) ## GAMLSS-RS iteration 1: Global Deviance = 88204 ## GAMLSS-RS iteration 2: Global Deviance = 69289 ## GAMLSS-RS iteration 3: Global Deviance = 64841 ## GAMLSS-RS iteration 4: Global Deviance = 64832 ## GAMLSS-RS iteration 5: Global Deviance = 64832 # 观察在击球数1000上先验概率的变化 plot_gamlss_fit &lt;- function(f) { career3 %&gt;% dplyr::select(year, bats) %&gt;% distinct() %&gt;% filter(bats != &quot;B&quot;) %&gt;% mutate(AB = 1000) %&gt;% augment(f, newdata = .) %&gt;% rename(mu = .fitted) %&gt;% mutate(sigma = fitted(fit3, &quot;sigma&quot;)[1], alpha0 = mu / sigma, beta0 = (1 - mu) / sigma, conf_low = qbeta(.025, alpha0, beta0), conf_high = qbeta(.975, alpha0, beta0)) %&gt;% ggplot(aes(year, mu, color = bats, group = bats)) + geom_line() + geom_ribbon(aes(ymin = conf_low, ymax = conf_high), linetype = 2, alpha = .1) + labs(x = &quot;Year&quot;, y = &quot;Prior distribution (median + 95% quantiles)&quot;, color = &quot;Batting hand&quot;) } plot_gamlss_fit(fit3) 同时另一个问题是这些因素会交互影响 fit4 &lt;- gamlss(cbind(H, AB - H) ~ 0 + ns(year, 5) * bats + log(AB), data = career3, family = BB(mu.link = &quot;identity&quot;)) ## GAMLSS-RS iteration 1: Global Deviance = 88201 ## GAMLSS-RS iteration 2: Global Deviance = 69241 ## GAMLSS-RS iteration 3: Global Deviance = 64708 ## GAMLSS-RS iteration 4: Global Deviance = 64698 ## GAMLSS-RS iteration 5: Global Deviance = 64698 plot_gamlss_fit(fit4) Pitching %&gt;% dplyr::select(playerID, yearID, GS) %&gt;% distinct() %&gt;% inner_join(dplyr::select(Master, playerID, throws)) %&gt;% count(yearID, throws, wt = GS) %&gt;% filter(!is.na(throws)) %&gt;% mutate(percent = n / sum(n)) %&gt;% filter(throws == &quot;L&quot;) %&gt;% ggplot(aes(yearID, percent)) + geom_line() + geom_smooth() + scale_y_continuous(labels = scales::percent_format()) + xlab(&quot;Year&quot;) + ylab(&quot;% of games with left-handed pitcher&quot;) 左右手之间的差距伴随年份在逐渐减少 players &lt;- crossing(year = c(1915, 1965, 2015), bats = c(&quot;L&quot;, &quot;R&quot;), H = 30, AB = 100) players_posterior &lt;- players %&gt;% mutate(mu = predict(fit4, what = &quot;mu&quot;, newdata = players), sigma = predict(fit4, what = &quot;sigma&quot;, newdata = players, type = &quot;response&quot;), alpha0 = mu / sigma, beta0 = (1 - mu) / sigma, alpha1 = alpha0 + H, beta1 = beta0 + AB - H) players_posterior %&gt;% crossing(x = seq(.15, .3, .001)) %&gt;% mutate(density = dbeta(x, alpha1, beta1)) %&gt;% ggplot(aes(x, density, color = bats)) + geom_line() + facet_wrap(~ year) + xlab(&quot;Batting average&quot;) + ylab(&quot;Posterior density&quot;) + ggtitle(&quot;Posterior distributions for batters with 30 / 100&quot;) 经验贝叶斯对先验概率的估计类似频率学派，但进行的又是贝叶斯分析 19.14 混合概率模型 用击球概率为例，击球手跟非击球手的概率分布是不一样的，那么实际看到的总体球员概率分布应该是一个混合在一起的两个独立分布 # 找出投球3次以上的人 pitchers &lt;- Pitching %&gt;% group_by(playerID) %&gt;% summarize(gamesPitched = sum(G)) %&gt;% filter(gamesPitched &gt; 3) # 参考上一章节的发现找出击球率稳定的选手 career &lt;- Batting %&gt;% filter(AB &gt; 0, lgID == &quot;NL&quot;, yearID &gt;= 1980) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB), year = mean(yearID)) %&gt;% mutate(average = H / AB, isPitcher = playerID %in% pitchers$playerID) # 链接上名字 career &lt;- Master %&gt;% tbl_df() %&gt;% dplyr::select(playerID, nameFirst, nameLast, bats) %&gt;% unite(name, nameFirst, nameLast, sep = &quot; &quot;) %&gt;% inner_join(career, by = &quot;playerID&quot;) 19.14.1 期望最大算法 将一个分布拆成两个，可以使用期望最大算法 set.seed(2017) # 先随机分为两组 starting_data &lt;- career %&gt;% filter(AB &gt;= 20) %&gt;% dplyr::select(-year, -bats, -isPitcher) %&gt;% mutate(cluster = factor(sample(c(&quot;A&quot;, &quot;B&quot;), n(), replace = TRUE))) # 观察效果 starting_data %&gt;% ggplot(aes(average, color = cluster)) + geom_density() library(VGAM) fit_bb_mle &lt;- function(x, n) { # dbetabinom.ab 是用n、alpha与beta作为参数的二项贝塔分布的似然度函数 ll &lt;- function(alpha, beta) { -sum(dbetabinom.ab(x, n, alpha, beta, log = TRUE)) } m &lt;- stats4::mle(ll, start = list(alpha = 3, beta = 10), method = &quot;L-BFGS-B&quot;, lower = c(0.001, .001)) ab &lt;- stats4::coef(m) data_frame(alpha = ab[1], beta = ab[2], number = length(x)) } # 看下初始参数 fit_bb_mle(starting_data$H, starting_data$AB) ## # A tibble: 1 × 3 ## alpha beta number ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 12.7 45.3 3310 # 看下随机分拆后的参数并生成各分组样本数的先验概率 fits &lt;- starting_data %&gt;% group_by(cluster) %&gt;% do(fit_bb_mle(.$H, .$AB)) %&gt;% ungroup() %&gt;% mutate(prior = number / sum(number)) fits ## # A tibble: 2 × 5 ## cluster alpha beta number prior ## &lt;fctr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 A 12.6 45.0 1644 0.497 ## 2 B 12.9 45.6 1666 0.503 算法优化的期望是将这两个分布分拆开，前面一次分拆已经产生微弱差异，下面就通过贝叶斯思想对数据更新这个差异重新分组让两者分开 assignments &lt;- starting_data %&gt;% dplyr::select(-cluster) %&gt;% crossing(fits) %&gt;% mutate(likelihood = prior * VGAM::dbetabinom.ab(H, AB, alpha, beta)) %&gt;% group_by(playerID) %&gt;% top_n(1, likelihood) %&gt;% ungroup() # 去除掉原有分组，根据更新的后验概率重新分组 assignments ## # A tibble: 3,310 × 11 ## playerID name H AB average cluster alpha beta ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;fctr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 abbotje01 Jeff Abbott 11 42 0.2619 B 12.9 45.6 ## 2 abbotji01 Jim Abbott 2 21 0.0952 A 12.6 45.0 ## 3 abbotku01 Kurt Abbott 475 1860 0.2554 B 12.9 45.6 ## 4 abbotky01 Kyle Abbott 3 31 0.0968 A 12.6 45.0 ## 5 abercre01 Reggie Abercrombie 86 386 0.2228 B 12.9 45.6 ## 6 abnersh01 Shawn Abner 110 531 0.2072 B 12.9 45.6 ## 7 abreubo01 Bobby Abreu 1607 5395 0.2979 B 12.9 45.6 ## 8 abreuto01 Tony Abreu 129 509 0.2534 B 12.9 45.6 ## 9 acevejo01 Jose Acevedo 8 101 0.0792 A 12.6 45.0 ## 10 aceveju01 Juan Acevedo 6 65 0.0923 A 12.6 45.0 ## # ... with 3,300 more rows, and 3 more variables: number &lt;int&gt;, ## # prior &lt;dbl&gt;, likelihood &lt;dbl&gt; # 观察更新后概率分布 ggplot(assignments, aes(average, fill = cluster)) + geom_histogram() 不断重复这个过程，最终分拆数据（其实就是第一步分拆最重要，后面直接收敛了） set.seed(1987) iterate_em &lt;- function(state, ...) { fits &lt;- state$assignments %&gt;% group_by(cluster) %&gt;% do(mutate(fit_bb_mle(.$H, .$AB), number = nrow(.))) %&gt;% ungroup() %&gt;% mutate(prior = number / sum(number)) assignments &lt;- assignments %&gt;% dplyr::select(playerID:average) %&gt;% crossing(fits) %&gt;% mutate(likelihood = prior * VGAM::dbetabinom.ab(H, AB, alpha, beta)) %&gt;% group_by(playerID) %&gt;% top_n(1, likelihood) %&gt;% ungroup() list(assignments = assignments, fits = fits) } library(purrr) # 使用purrr包存储中间结果 iterations &lt;- accumulate(1:5, iterate_em, .init = list(assignments = starting_data)) assignment_iterations &lt;- iterations %&gt;% map_df(&quot;assignments&quot;, .id = &quot;iteration&quot;) # 观察收敛过程 assignment_iterations %&gt;% ggplot(aes(average, fill = cluster)) + geom_histogram() + facet_wrap(~ iteration) fit_iterations &lt;- iterations %&gt;% map_df(&quot;fits&quot;, .id = &quot;iteration&quot;) # 两个分布的收敛过程 fit_iterations %&gt;% crossing(x = seq(.001, .4, .001)) %&gt;% mutate(density = prior * dbeta(x, alpha, beta)) %&gt;% ggplot(aes(x, density, color = iteration, group = iteration)) + geom_line() + facet_wrap(~ cluster) 19.14.2 分配 得到每个选手在两个分布中后验概率后要对其进行分配，这里我们认为拆分出的两个分布其实就是是否是击球手的两个分组，由于两组重叠较多，直接分配会有困难 # 找6个击球数100的选手进行分配 batter_100 &lt;- career %&gt;% filter(AB == 100) %&gt;% arrange(average) batter_100 ## # A tibble: 5 × 8 ## playerID name bats H AB year average isPitcher ## &lt;chr&gt; &lt;chr&gt; &lt;fctr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 dejesjo01 Jose de Jesus R 11 100 1990 0.11 TRUE ## 2 mahonmi02 Mike Mahoney R 18 100 2002 0.18 FALSE ## 3 cancero01 Robinson Cancel R 20 100 2007 0.20 FALSE ## 4 buschmi01 Mike Busch R 22 100 1996 0.22 FALSE ## 5 shealry01 Ryan Shealy R 32 100 2006 0.32 FALSE # 前面算法得到的最终结果 final_parameters &lt;- fit_iterations %&gt;% filter(iteration == max(iteration)) final_parameters ## # A tibble: 2 × 6 ## iteration cluster alpha beta number prior ## &lt;chr&gt; &lt;fctr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 5 A 36.4 255 851 0.257 ## 2 5 B 111.4 328 2459 0.743 # 观察球员位置 final_parameters %&gt;% crossing(x = 0:45) %&gt;% mutate(density = prior * VGAM::dbetabinom.ab(x, 100, alpha, beta)) %&gt;% ggplot(aes(x, density)) + geom_line(aes(color = cluster)) + geom_vline(aes(xintercept = H), data = batter_100, lty = 2) + geom_text(aes(x = H, y = -.022, label = name), data = batter_100, hjust = 1, vjust = 1, angle = 270) + labs(x = &quot;H (out of 100 at-bats)&quot;, y = &quot;Likelihood of this H out of 100 hits&quot;) # 根据贝叶斯理论，我们可以用在A分组的似然度比上两个分组似然度的和得到后验概率 final_parameters %&gt;% crossing(H = 1:40) %&gt;% transmute(H, cluster, likelihood = prior * VGAM::dbetabinom.ab(H, 100, alpha, beta)) %&gt;% spread(cluster, likelihood) %&gt;% mutate(probability_A = A / (A + B)) %&gt;% ggplot(aes(H, probability_A)) + geom_line() + geom_vline(aes(xintercept = H), data = batter_100, lty = 2) + geom_text(aes(x = H, y = 0, label = name), data = batter_100, hjust = 1, vjust = 1, angle = 270) + labs(x = &quot;H (out of 100 at-bats)&quot;, y = &quot;(Likelihood if pitcher) / (Likelihood if pitcher + Likelihood if not)&quot;, title = &quot;Posterior probability a player is in the pitcher cluster&quot;) 通过构建后验概率，我们可以直接对结果基于概率进行分组 career_likelihoods &lt;- career %&gt;% filter(AB &gt; 20) %&gt;% crossing(final_parameters) %&gt;% mutate(likelihood = prior * VGAM::dbetabinom.ab(H, AB, alpha, beta)) %&gt;% group_by(playerID) %&gt;% mutate(posterior = likelihood / sum(likelihood)) career_assignments &lt;- career_likelihoods %&gt;% top_n(1, posterior) %&gt;% ungroup() # 对比这种分组与实际数据的结果 career_assignments %&gt;% filter(posterior &gt; .8) %&gt;% count(isPitcher, cluster) %&gt;% spread(cluster, n) ## Source: local data frame [2 x 3] ## Groups: isPitcher [2] ## ## isPitcher A B ## * &lt;lgl&gt; &lt;int&gt; &lt;int&gt; ## 1 FALSE 30 2043 ## 2 TRUE 546 141 这样基于对概率分布的观察，我们可以实现有现实意义的分组，对分组的改进则需要对数据的进一步理解 19.14.3 经验贝叶斯收缩 混合模型下前面所做的工作都需要重新考虑 # 观察击球数100选手的后验概率分布 batting_data &lt;- career_likelihoods %&gt;% ungroup() %&gt;% filter(AB == 100) %&gt;% mutate(name = paste0(name, &quot; (&quot;, H, &quot;/&quot;, AB, &quot;)&quot;), name = reorder(name, H), alpha1 = H + alpha, beta1 = AB - H + beta) batting_data %&gt;% crossing(x = seq(0, .4, .001)) %&gt;% mutate(posterior_density = posterior * dbeta(x, alpha1, beta1)) %&gt;% group_by(name, x) %&gt;% summarize(posterior_density = sum(posterior_density)) %&gt;% ggplot(aes(x, posterior_density, color = name)) + geom_line(show.legend = FALSE) + geom_vline(aes(xintercept = average), data = batting_data, lty = 2) + facet_wrap(~ name) + labs(x = &quot;Batting average (actual average shown as dashed line)&quot;, y = &quot;Posterior density after updating&quot;) 此时不太好判断属于哪一分布，可采用后验概率对平均分布进行加权 eb_shrinkage &lt;- career_likelihoods %&gt;% mutate(shrunken_average = (H + alpha) / (AB + alpha + beta)) %&gt;% group_by(playerID) %&gt;% summarize(shrunken_average = sum(posterior * shrunken_average)) # 观察加权分布 eb_shrinkage %&gt;% inner_join(career) %&gt;% filter(AB &gt; 50) %&gt;% gather(type, value, average, shrunken_average) %&gt;% mutate(type = ifelse(type == &quot;average&quot;, &quot;Raw batting average&quot;, &quot;Average posterior&quot;), type = relevel(factor(type), &quot;Raw batting average&quot;)) %&gt;% ggplot(aes(AB, value)) + geom_point() + facet_wrap(~ type) + scale_x_log10() + ylab(&quot;Estimate&quot;) - 收敛后的分布会朝向两个中心而不是一个，并非所有之前的方法（例如区间估计）都可以适用到混合模型里，需要根据实际情况进行分析 19.15 模拟验证 上面的经验贝叶斯推断大都是给出的结果，我们需要对其进行模拟验证 pitchers &lt;- Pitching %&gt;% group_by(playerID) %&gt;% summarize(gamesPitched = sum(G)) %&gt;% filter(gamesPitched &gt; 3) career &lt;- Batting %&gt;% filter(AB &gt; 0) %&gt;% anti_join(pitchers, by = &quot;playerID&quot;) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB)) # 从数据中找到贝塔分布的两个参数 library(ebbr) prior &lt;- career %&gt;% ebb_fit_prior(H, AB) prior ## Empirical Bayes binomial fit with method mle ## Parameters: ## # A tibble: 1 × 2 ## alpha beta ## &lt;dbl&gt; &lt;dbl&gt; ## 1 72.4 216 # 用这两个参数生成球员的击球概率 alpha0 &lt;- tidy(prior)$alpha beta0 &lt;- tidy(prior)$beta qplot(rbeta(10000, alpha0, beta0)) # 击球数使用原始数据 ggplot(career, aes(AB)) + geom_histogram() + scale_x_log10() # 构建仿真数据 set.seed(2017) career_sim &lt;- career %&gt;% mutate(p = rbeta(n(), alpha0, beta0), H = rbinom(n(), AB, p)) career_sim ## # A tibble: 10,492 × 4 ## playerID H AB p ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 aaronha01 3618 12364 0.299 ## 2 aaronto01 229 944 0.249 ## 3 abadan01 7 21 0.274 ## 4 abadijo01 14 49 0.198 ## 5 abbated01 762 3044 0.249 ## 6 abbeych01 464 1751 0.264 ## 7 abbotda01 2 7 0.191 ## 8 abbotfr01 125 513 0.251 ## 9 abbotje01 145 596 0.243 ## 10 abbotku01 554 2044 0.261 ## # ... with 10,482 more rows 19.15.1 模拟对分布参数的估计 生产数据后我们可以估计分布参数，看能否与模拟值对应 career_sim_eb &lt;- career_sim %&gt;% add_ebb_estimate(H, AB) career_sim_gathered &lt;- career_sim_eb %&gt;% rename(Shrunken = .fitted, Raw = .raw) %&gt;% gather(type, estimate, Shrunken, Raw) # 观察是否能收敛数据 career_sim_gathered %&gt;% filter(AB &gt;= 10) %&gt;% ggplot(aes(p, estimate, color = AB)) + geom_point() + geom_abline(color = &quot;red&quot;) + geom_smooth(method = &quot;lm&quot;, color = &quot;white&quot;, lty = 2, se = FALSE) + scale_color_continuous(trans = &quot;log&quot;, breaks = c(10, 100, 1000, 10000)) + facet_wrap(~ type) + labs(x = &quot;True batting average (p)&quot;, y = &quot;Raw or shrunken batting average&quot;, title = &quot;Empirical Bayes shrinkage reduces variance, but causes bias&quot;, subtitle = &quot;Red line is x = y; dashed white line is a linear fit&quot;) 我们可以看到，估计方差有了一定收敛，但出现了一定偏差，可参考统计学习中方差-偏差权衡的描述 可以用均方误来衡量，此处虽牺牲了偏差，但整体误差降低了 \\[\\mbox{MSE}=\\frac{1}{n}\\sum_{1}^{n}(p-\\hat{p})^2\\] career_sim_gathered %&gt;% group_by(type) %&gt;% summarize(mse = mean((estimate - p) ^ 2)) ## # A tibble: 2 × 2 ## type mse ## &lt;chr&gt; &lt;dbl&gt; ## 1 Raw 0.014971 ## 2 Shrunken 0.000352 注意到击球数可能影响收敛，所以可以探索其对均方误的影响 metric_by_bin &lt;- career_sim_gathered %&gt;% group_by(type, AB = 10 ^ (round(log10(AB)))) %&gt;% summarize(mse = mean((estimate - p) ^ 2)) ggplot(metric_by_bin, aes(AB, mse, color = type)) + geom_line() + scale_x_log10() + scale_y_log10() + labs(x = &quot;Number of at-bats (AB)&quot;, y = &quot;Mean-squared-error within this bin (note log scale)&quot;, title = &quot;Mean squared error is higher with raw estimate, especially for low AB&quot;) 击球数越多，均方误越低，此时可进一步探索 library(scales) # 观察斜率p值变化 career_sim_gathered %&gt;% mutate(AB = 10 ^ (round(log10(AB)))) %&gt;% filter(AB &gt; 1) %&gt;% nest(-type, -AB) %&gt;% unnest(map(data, ~ tidy(lm(estimate ~ p, .)))) %&gt;% filter(term == &quot;p&quot;) %&gt;% ggplot(aes(AB, estimate, color = type)) + geom_line() + scale_x_log10(breaks = c(10, 100, 1000, 10000)) + geom_hline(yintercept = 1, lty = 2) + labs(x = &quot;Number of at-bats (AB)&quot;, y = &quot;Slope of estimate/p within this bin&quot;, title = &quot;Shrunken estimates introduce bias for low AB&quot;, subtitle = &quot;Note that an unbiased estimate would have a slope of 0&quot;) # 分层 career_sim_gathered %&gt;% mutate(ab_bin = cut(AB, c(0, 10, 100, 1000, Inf), labels = c(&quot;1-10&quot;, &quot;11-100&quot;, &quot;101-1000&quot;, &quot;1000+&quot;))) %&gt;% ggplot(aes(p, estimate, color = AB)) + geom_point() + geom_abline(color = &quot;red&quot;) + geom_smooth(method = &quot;lm&quot;, color = &quot;gray&quot;, lty = 2, se = FALSE) + scale_color_continuous(trans = &quot;log&quot;, breaks = c(10, 100, 1000, 10000)) + facet_grid(ab_bin ~ type, scales = &quot;free_y&quot;) + labs(x = &quot;True batting average (p)&quot;, y = &quot;Raw or shrunken estimate&quot;, title = &quot;Empirical Bayes shrinkage reduces variance, but introduces bias&quot;, subtitle = &quot;Red line is x = y; dashed white line is a linear fit&quot;) 击球数越多，越接近真相 19.15.2 区间估计 检验区间估计是否覆盖95%的真值 career_sim_eb %&gt;% summarize(coverage = mean(.low &lt;= p &amp; p &lt;= .high)) ## # A tibble: 1 × 1 ## coverage ## &lt;dbl&gt; ## 1 0.943 观察不同区间的覆盖范围 sim_prior &lt;- ebb_fit_prior(career_sim, H, AB) estimate_by_cred_level &lt;- data_frame(level = seq(.5, .98, .02)) %&gt;% unnest(map(level, ~ augment(sim_prior, career_sim, cred_level = .))) estimate_by_cred_level %&gt;% group_by(level) %&gt;% mutate(cover = .low &lt;= p &amp; p &lt;= .high) %&gt;% summarize(coverage = mean(cover)) %&gt;% ggplot(aes(level, coverage)) + geom_point() + geom_abline(color = &quot;red&quot;) + labs(x = &quot;Level of credible interval&quot;, y = &quot;Probability credible interval contains the true value&quot;) 结果基本吻合，说明区间估计也比较准 19.15.3 错误发现率 看一下进入名人堂的人 pt &lt;- career_sim_eb %&gt;% add_ebb_prop_test(.3, sort = TRUE) # 错误发现率控制为10% hall_of_fame &lt;- pt %&gt;% filter(.qvalue &lt;= .1) mean(hall_of_fame$p &lt; .3) ## [1] 0.136 # 观察整体错误发现率的变动 pt %&gt;% mutate(true_fdr = cummean(p &lt; .3)) %&gt;% ggplot(aes(.qvalue, true_fdr)) + geom_line() + geom_abline(color = &quot;red&quot;) + labs(x = &quot;q-value&quot;, y = &quot;True FDR at this q-value threshold&quot;) 19.15.4 贝塔-二项回归 看下影响因素 # 回归值 bb_reg &lt;- career %&gt;% ebb_fit_prior(H, AB, method = &quot;gamlss&quot;, mu_predictors = ~ log10(AB)) tidy(bb_reg) ## # A tibble: 3 × 6 ## parameter term estimate std.error statistic p.value ## &lt;fctr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 mu (Intercept) -1.686 0.00902 -186.9 0 ## 2 mu log10(AB) 0.192 0.00279 68.8 0 ## 3 sigma (Intercept) -6.299 0.02306 -273.1 0 set.seed(2017) career_sim_ab &lt;- augment(bb_reg, career) %&gt;% dplyr::select(playerID, AB, true_alpha0 = .alpha0, true_beta0 = .beta0) %&gt;% mutate(p = rbeta(n(), true_alpha0, true_beta0), H = rbinom(n(), AB, p)) # 真实值 career_ab_prior &lt;- career_sim_ab %&gt;% ebb_fit_prior(H, AB, method = &quot;gamlss&quot;, mu_predictors = ~ log10(AB)) # 对比 tidy(career_ab_prior) ## # A tibble: 3 × 6 ## parameter term estimate std.error statistic p.value ## &lt;fctr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 mu (Intercept) -1.686 0.00909 -185 0 ## 2 mu log10(AB) 0.191 0.00281 68 0 ## 3 sigma (Intercept) -6.252 0.02528 -247 0 # 观察击球数影响 career_flat_prior &lt;- career_sim_ab %&gt;% ebb_fit_prior(H, AB) data_frame(method = c(&quot;Flat prior&quot;, &quot;Prior depending on AB&quot;), model = list(career_flat_prior, career_ab_prior)) %&gt;% unnest(map(model, augment, data = career_sim_ab)) %&gt;% ggplot(aes(p, .fitted, color = AB)) + geom_point() + scale_color_continuous(trans = &quot;log&quot;) + geom_abline(color = &quot;red&quot;) + facet_wrap(~ method) + labs(x = &quot;True batting average (p)&quot;, y = &quot;Shrunken batting average estimate&quot;) 19.15.5 重复模拟 为防止意外或运气可以重复模拟看看 set.seed(2017) sim_replications &lt;- career %&gt;% crossing(replication = 1:50) %&gt;% mutate(p = rbeta(n(), alpha0, beta0), H = rbinom(n(), AB, p)) sim_replications ## # A tibble: 524,600 × 5 ## playerID H AB replication p ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 aaronha01 3762 12364 1 0.299 ## 2 aaronha01 3021 12364 2 0.249 ## 3 aaronha01 3419 12364 3 0.274 ## 4 aaronha01 2475 12364 4 0.198 ## 5 aaronha01 3045 12364 5 0.249 ## 6 aaronha01 3296 12364 6 0.264 ## 7 aaronha01 2376 12364 7 0.191 ## 8 aaronha01 3069 12364 8 0.251 ## 9 aaronha01 2927 12364 9 0.243 ## 10 aaronha01 3320 12364 10 0.261 ## # ... with 524,590 more rows sim_replication_models &lt;- sim_replications %&gt;% nest(-replication) %&gt;% mutate(prior = map(data, ~ ebb_fit_prior(., H, AB))) # 估计参数 sim_replication_priors &lt;- sim_replication_models %&gt;% unnest(map(prior, tidy), .drop = TRUE) sim_replication_priors ## # A tibble: 50 × 4 ## replication alpha beta mean ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 74.1 221 0.251 ## 2 2 73.2 218 0.251 ## 3 3 72.7 217 0.251 ## 4 4 73.1 218 0.251 ## 5 5 69.5 207 0.251 ## 6 6 75.4 224 0.252 ## 7 7 74.3 221 0.252 ## 8 8 72.7 216 0.252 ## 9 9 76.9 229 0.251 ## 10 10 72.2 215 0.252 ## # ... with 40 more rows true_values &lt;- data_frame(parameter = c(&quot;alpha&quot;, &quot;beta&quot;, &quot;mean&quot;), true = c(alpha0, beta0, alpha0 / (alpha0 + beta0))) sim_replication_priors %&gt;% gather(parameter, value, -replication) %&gt;% inner_join(true_values, by = &quot;parameter&quot;) %&gt;% ggplot(aes(1, value)) + geom_boxplot() + geom_hline(aes(yintercept = true), color = &quot;red&quot;, lty = 2) + facet_wrap(~ parameter, scales = &quot;free_y&quot;) + labs(x = &quot;&quot;, y = &quot;Estimated parameter (true value shown as red line)&quot;, title = &quot;Estimated hyperparameters across 50 replications&quot;) # 估计区间与假设检验 ## 估计均方误 sim_replication_au &lt;- sim_replication_models %&gt;% unnest(map2(prior, data, augment)) sim_replication_mse &lt;- sim_replication_au %&gt;% rename(Raw = .raw, Shrunken = .fitted) %&gt;% gather(type, estimate, Raw, Shrunken) %&gt;% group_by(type, replication) %&gt;% summarize(mse = mean((estimate - p) ^ 2)) ggplot(sim_replication_mse, aes(type, mse)) + geom_boxplot() + ylab(&quot;Mean squared error across 50 replications&quot;) ## 估计区间 sim_replication_au %&gt;% mutate(cover = .low &lt;= p &amp; p &lt;= .high) %&gt;% group_by(replication) %&gt;% summarize(coverage = mean(cover)) %&gt;% ggplot(aes(coverage)) + geom_histogram(binwidth = .001) + labs(x = &quot;% of time true value was in a 95% confidence interval&quot;, title = &quot;95% credible interval is well calibrated across replications&quot;) sim_replication_intervals &lt;- sim_replication_models %&gt;% crossing(cred_level = c(seq(.5, .9, .05), .95)) %&gt;% unnest(pmap(list(prior, data, cred_level = cred_level), augment)) %&gt;% dplyr::select(replication, cred_level, p, .low, .high) sim_replication_intervals %&gt;% mutate(cover = .low &lt;= p &amp; p &lt;= .high) %&gt;% group_by(replication, cred_level) %&gt;% summarize(coverage = mean(cover)) %&gt;% ggplot(aes(cred_level, coverage, group = replication)) + geom_line(alpha = .3) + geom_abline(color = &quot;red&quot;) + labs(x = &quot;Credibility level&quot;, y = &quot;% of credible intervals in this replication that contain the true parameter&quot;, title = &quot;Credible intervals are well calibrated across 50 replications&quot;, subtitle = &quot;Red line is x = y&quot;) ## q值的稳定性 sim_replication_prop_tests &lt;- sim_replication_au %&gt;% nest(-replication) %&gt;% unnest(map(data, add_ebb_prop_test, threshold = .3, sort = TRUE)) sim_replication_prop_tests %&gt;% group_by(replication) %&gt;% mutate(fdr = cummean(p &lt; .3)) %&gt;% ggplot(aes(.qvalue, fdr, group = replication)) + geom_line(alpha = .3) + geom_abline(color = &quot;red&quot;) + labs(x = &quot;Q-value threshold&quot;, y = &quot;Proportion of false discoveries below this threshold&quot;, title = &quot;Q-value successfully controls FDR across 50 replications&quot;) "],
["python.html", "笔记 20 数据科学与python简介 20.1 数据科学 20.2 工作流程 20.3 PYTHON 入门 20.4 Python 工具包 20.5 探索性数据分析 20.6 常见模型 20.7 参考", " 笔记 20 数据科学与python简介 20.1 数据科学 核心：数据处理 研究对象：实际问题（跨学科） 方法：统计学 计算机科学 专业领域 数据科学家： 统计学水平高的程序员 编程水平高的统计学家 学术好奇心 沟通交流能力 产品经理 20.2 工作流程 数据收集 数据整理 数据探索 数据建模 模型评价 结果交流 20.3 PYTHON 入门 基础数据类型 NULL 数值类型 int float bool(逻辑运算) 列表 从0开始 元素可变 ()赋值为Tuples类型 元素不可变 字符串 文本处理 python专长 字典 {}包含 : 指定属性值 python中对象均有类型 可自定义 20.4 Python 工具包 Numpy 数值计算包 Pandas 数据清洗 缺失值 切分 MatPlotLib 数据可视化 sklearn 机器学习包 20.5 探索性数据分析 ACES model Letter Step Notes A Acquire the data and Assemble the data frame Find data, import into Pandas C Clean the data frame Identify and limit columns, rows, indices, dates, etc. E Explore global properties Visualize! Basic plots and stats appropriate to the data set S Subset comparisons Look at (visualize!) initial emergenet variable relationships and subsets 20.6 常见模型 线性模型 分类问题：logistic模型与朴素贝叶斯模型 无监督主成分分析 无监督聚类 20.6.1 高级模型 模型打包组合技术：bagging boosting 随机森林 支持向量机 深度神经网络 20.7 参考 课程 "],
["section-21.html", "笔记 21 生存分析 21.1 Concepts 21.2 Notation 21.3 Cox proportional-hazards regression model 21.4 Case: Recidivism 21.5 further 21.6 Time-Dependent Covariates 21.7 Model Diagnostics 21.8 Reference", " 笔记 21 生存分析 21.1 Concepts examines and models the time it takes for events to occur the distribution of survival times Popular: Cox proportional-hazards regression model 21.2 Notation T as a random variable with cumulative distribution function \\(P (t) = Pr(T ≤ t)\\) and probability density function \\(p(t) = \\frac{dP (t)}{dt}\\) survival function S(t) is the complement of the distribution function, \\(S(t) = Pr(T &gt; t) = 1 − P (t)\\) hazard function \\(log h(t) = ν + ρt\\) 21.3 Cox proportional-hazards regression model \\(log h_i(t)=α+_1x_{i1} +β_2x_{ik} +···+β_kx_{ik}\\) Cox model \\(log h_i(t)=α(t)+β_1x_{i1} +β_2x_{ik} +···+β_kx_{ik}\\) the Cox model is a proportional-hazards model \\(\\frac{h_i(t)}{h_{i&#39;}(t)} = \\frac{e^{\\eta_i}}{e^{\\eta&#39;}}\\) 21.4 Case: Recidivism Target: recidivism of 432 male prisoners, who were observed for a year after being released from prison arrest means the male prisoners who rearrested 52 weeks factors: financial aid after release from prison, affected，release ages，race，work experience，marriage，parole，prior convictions, education library(survival) library(car) # perform survival analysis Rossi &lt;- read.table(&#39;http://ftp.auckland.ac.nz/software/CRAN/doc/contrib/Fox-Companion/Rossi.txt&#39;, header=T) Rossi[1:5, 1:10] ## week arrest fin age race wexp mar paro prio educ ## 1 20 1 0 27 1 0 0 1 3 3 ## 2 17 1 0 18 1 0 0 1 8 4 ## 3 25 1 0 19 0 1 0 1 13 3 ## 4 52 0 1 23 1 1 1 1 1 5 ## 5 52 0 0 19 0 1 0 1 3 3 mod.allison &lt;- coxph(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data=Rossi) summary(mod.allison) ## Call: ## coxph(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = Rossi) ## ## n= 432, number of events= 114 ## ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## fin -0.3794 0.6843 0.1914 -1.98 0.0474 * ## age -0.0574 0.9442 0.0220 -2.61 0.0090 ** ## race 0.3139 1.3688 0.3080 1.02 0.3081 ## wexp -0.1498 0.8609 0.2122 -0.71 0.4803 ## mar -0.4337 0.6481 0.3819 -1.14 0.2561 ## paro -0.0849 0.9186 0.1958 -0.43 0.6646 ## prio 0.0915 1.0958 0.0286 3.19 0.0014 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## exp(coef) exp(-coef) lower .95 upper .95 ## fin 0.684 1.461 0.470 0.996 ## age 0.944 1.059 0.904 0.986 ## race 1.369 0.731 0.748 2.503 ## wexp 0.861 1.162 0.568 1.305 ## mar 0.648 1.543 0.307 1.370 ## paro 0.919 1.089 0.626 1.348 ## prio 1.096 0.913 1.036 1.159 ## ## Concordance= 0.64 (se = 0.027 ) ## Rsquare= 0.074 (max possible= 0.956 ) ## Likelihood ratio test= 33.3 on 7 df, p=2.36e-05 ## Wald test = 32.1 on 7 df, p=3.87e-05 ## Score (logrank) test = 33.5 on 7 df, p=2.11e-05 # plot time vs survival prob plot(survfit(mod.allison), ylim=c(.7, 1), xlab=&#39;Weeks&#39;, ylab=&#39;Proportion Not Rearrested&#39;) 21.4.1 result The covariates age and prio (prior convictions) have highly statistically significant coefficients, while the coefficient for fin (financial aid) is marginally significant holding the other covariates constant, an additional year of age reduces the weekly hazard of rearrest by a factor of \\(e^b = 0.944\\) on average – that is, by 5.6 likelihood-ratio, Wald, and score chi-square statistics: null hypothesis all of the β’s are zero. 21.5 further assess the impact of financial aid on rearrest new data frame with two rows, one for each value of fin; the other covariates are fixed to their average values attach(Rossi) Rossi.fin &lt;- data.frame(fin=c(0,1), age=rep(mean(age),2), race=rep(mean(race),2), wexp=rep(mean(wexp),2), mar=rep(mean(mar),2), paro=rep(mean(paro),2), prio=rep(mean(prio),2)) detach() plot(survfit(mod.allison, newdata=Rossi.fin), conf.int=T, lty=c(1,2), ylim=c(.6, 1)) legend(&quot;bottomleft&quot;, legend=c(&#39;fin = 0&#39;, &#39;fin = 1&#39;), lty=c(1,2)) the higher estimated ‘survival’ of those receiving financial aid, but the two confidence envelopes overlap substantially, even after 52 weeks 21.6 Time-Dependent Covariates treat the employed variable as a tim-dependent covariates with 52 weeks’ record sum(!is.na(Rossi[,11:62])) # record count ## [1] 19809 Rossi2 &lt;- matrix(0, 19809, 14) # to hold new data set colnames(Rossi2) &lt;- c(&#39;start&#39;, &#39;stop&#39;, &#39;arresttime&#39;, names(Rossi)[1:10], &#39;employed&#39;) row&lt;-0 for (i in 1:nrow(Rossi)) { for (j in 11:62) { if (is.na(Rossi[i, j])) next else { row &lt;- row + 1 # increment row counter start &lt;- j - 11 # start time (previous week) stop &lt;- start + 1 # stop time (current week) arresttime &lt;- if (stop == Rossi[i, 1] &amp;&amp; Rossi[i, 2] ==1) 1 else 0 Rossi2[row,] &lt;- c(start, stop, arresttime, unlist(Rossi[i, c(1:10, j)])) } } } Rossi2 &lt;- as.data.frame(Rossi2) remove(i, j, row, start, stop, arresttime) modallison2 &lt;- coxph(Surv(start, stop, arresttime) ~ fin + age + race + wexp + mar + paro + prio + employed, data=Rossi2) summary(modallison2) ## Call: ## coxph(formula = Surv(start, stop, arresttime) ~ fin + age + race + ## wexp + mar + paro + prio + employed, data = Rossi2) ## ## n= 19809, number of events= 114 ## ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## fin -0.3567 0.7000 0.1911 -1.87 0.0620 . ## age -0.0463 0.9547 0.0217 -2.13 0.0330 * ## race 0.3387 1.4031 0.3096 1.09 0.2740 ## wexp -0.0256 0.9748 0.2114 -0.12 0.9038 ## mar -0.2937 0.7455 0.3830 -0.77 0.4431 ## paro -0.0642 0.9378 0.1947 -0.33 0.7416 ## prio 0.0851 1.0889 0.0290 2.94 0.0033 ** ## employed -1.3283 0.2649 0.2507 -5.30 1.2e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## exp(coef) exp(-coef) lower .95 upper .95 ## fin 0.700 1.429 0.481 1.018 ## age 0.955 1.047 0.915 0.996 ## race 1.403 0.713 0.765 2.574 ## wexp 0.975 1.026 0.644 1.475 ## mar 0.745 1.341 0.352 1.579 ## paro 0.938 1.066 0.640 1.374 ## prio 1.089 0.918 1.029 1.152 ## employed 0.265 3.775 0.162 0.433 ## ## Concordance= 0.708 (se = 0.027 ) ## Rsquare= 0.003 (max possible= 0.066 ) ## Likelihood ratio test= 68.7 on 8 df, p=9.11e-12 ## Wald test = 56.1 on 8 df, p=2.63e-09 ## Score (logrank) test = 64.5 on 8 df, p=6.1e-11 21.7 Model Diagnostics Checking Proportional Hazards modallison3 &lt;- coxph(Surv(week, arrest) ~ fin + age + prio, data=Rossi) modallison3 ## Call: ## coxph(formula = Surv(week, arrest) ~ fin + age + prio, data = Rossi) ## ## coef exp(coef) se(coef) z p ## fin -0.3470 0.7068 0.1902 -1.82 0.06820 ## age -0.0671 0.9351 0.0209 -3.22 0.00129 ## prio 0.0969 1.1017 0.0273 3.56 0.00038 ## ## Likelihood ratio test=29.1 on 3 df, p=2.19e-06 ## n= 432, number of events= 114 cox.zph(modallison3) ## rho chisq p ## fin -0.00657 0.00507 0.9433 ## age -0.20976 6.54147 0.0105 ## prio -0.08004 0.77288 0.3793 ## GLOBAL NA 7.13046 0.0679 par(mfrow=c(2,2)) plot(cox.zph(modallison3)) there appears to be a trend in the plot for age, with the age effect declining with time modallison4 &lt;- coxph(Surv(start,stop,arresttime)~fin+age+age:stop:stop+prio, data = Rossi2) modallison4 ## Call: ## coxph(formula = Surv(start, stop, arresttime) ~ fin + age + age:stop:stop + ## prio, data = Rossi2) ## ## coef exp(coef) se(coef) z p ## fin -0.34856 0.70570 0.19023 -1.83 0.06690 ## age 0.03228 1.03280 0.03943 0.82 0.41301 ## prio 0.09818 1.10316 0.02726 3.60 0.00032 ## age:stop -0.00383 0.99617 0.00147 -2.61 0.00899 ## ## Likelihood ratio test=36 on 4 df, p=2.85e-07 ## n= 19809, number of events= 114 the coefficient for the interaction is negative and highly statistically significant: The effect of age declines with time use residual to find influential observations 21.8 Reference Cox Proportional-Hazards Regression for Survival Data Real Cases "],
["section-22.html", "笔记 22 因果分析 22.1 Introduction 22.2 Causal Information 22.3 Theoretical Background 22.4 Methods for Identification and Estimation", " 笔记 22 因果分析 22.1 Introduction “Impact assessment, simply defined, is the process of identifying the future consequences of a current or proposed action.” (IAIA, 2009) “Policy assessment seeks to inform decision-makers by predicting and evaluating the potential impacts of policy options.” (Adelle and Weiland, 2012) “… I see no greater impediment to scientific progress than the prevailing practice of focusing all our mathematical resources on probabilistic and statistical inferences while leaving causal considerations to the mercy of intuition and good judgment.” (Pearl, 1999) 22.2 Causal Information 22.2.1 Target practical framework for causal effect estimation in the context of policy assessment and impact analysis, and in the absence of experimental data 22.2.2 Causal sources Causal Inference by Experiment: Randomized experiments Causal Inference from Observational Data and Theory: Existing data or Big data 22.2.3 Identification and Estimation Process Causal Identification: domain knowledge based Computing the Effect Size: Bayesian networks 22.3 Theoretical Background 22.3.1 Potential Outcomes Framework \\(Y_{i,1}\\) Potential outcome of individual i given treatment T=1 (e.g. taking two Aspirins) \\(Y_{i,0}\\) Potential outcome of individual i given treatment T=0 (e.g. drinking a glass of water) individual-level causal effect (ICE) \\(ICE=Y_{i,1} −Y_{i,0}\\) average causal effect (ACE) \\(ACE = E[Y_{i,1}] −E[Y_{i,0}]\\) 22.3.2 Causal Identification \\(Y_{i,1}\\) (treatment) and \\(Y_{i,0}\\) (non-treatment) can never be both observed for the same individual at the same time Association S \\(S = E[Y_1|T = 1] - E[Y_0|T = 0]\\) S is not the same with ACE association does not imply causation randomized experiment 22.3.2.1 Ignorability \\((Y_1,Y_0) \\upmodels T\\) \\(Y_1\\) and \\(Y_0\\) must be jointly independent of the treatment assignment \\((Y_1,Y_0) \\upmodels T|X\\) for realobservational studies, conditional on variables X, \\(Y_1\\), and \\(Y_0\\) are jointly independent of T, the assignment mechanism \\(ACE|X = E[Y_1|X] - E[Y_0|X] = E[Y_1|T=1,X] - E[Y_0|􏰀T = 0,X] = E[Y|􏰀T = 1,X] - E[Y|􏰀T =0,X] = S|􏰀X\\) 22.3.2.2 Assumptions Causal inference requires causal assumptions 22.4 Methods for Identification and Estimation 22.4.1 Directed Acyclic Graphs(DAG) for Identification DAGs Are Nonparametric A Node represents a variable in a domain, regardless of whether it is observable or unobservable A Directed Arc has the appearance of an arrow and represents a potential causal effect. The arc direction indicates the assumed causal direction, i.e. “A→B” means “A causes B.” A Missing Arc encodes the definitive absence of a direct causal effect, i.e. no arc between A and B means that there exists no direct causal relationship between A and B and vice versa. As such, a missing arc repre- sents an assumption 22.4.2 Indirect Connection A causes B via node C \\(A \\nupmodels B\\) and \\(A \\upmodels B|C\\) 22.4.3 Common Cause C causes both A and B \\(A \\nupmodels B\\) and \\(A \\upmodels B|C\\) 22.4.4 Common Effect C is the common effect of A and B \\(A \\upmodels B\\) and \\(A \\nupmodels B|C\\) 22.4.5 Example: Simpson’s Paradox "],
["section-23.html", "笔记 23 系统思维与公共健康 23.1 导论 23.2 系统抽象与映射－因果环路图 23.3 系统抽象与映射－汇流图 23.4 系统思维与决策", " 笔记 23 系统思维与公共健康 23.1 导论 系统思考来源广泛，并非单一理论而是复合理论，是关注自调控与涌现的跨学科方法。 系统是有单一目的相互作用的各部分与之间联系的总和。 健康系统是目的为健康的系统。 简单系统元素少，关系明确，有理论机制或精细的统计模式 复杂系统元素多，关系不明或不稳，不能适应，无法统计预测 混沌系统元素多，存在动态关系，对初始值敏感，不能适应，表面无序，可用数学函数预测 复杂适应性系统（CAS）元素多，复合关系，可预测不可描述，存在涌现（例如适应、学习、自组织），非线性，多样性（同一输入多个输出），收敛（多个途径出现一个结果） 传统公共健康改善方法： 选择健康干预方法 设定目标 资助 实施设计好的干预方法 问题： 干预不符合实情 很多策略无法重复 策略影响有限 策略结果不可预期 结果不好评价改善 CAS路径 反馈，可能是加强，可能是制衡 路径依赖，方向单一，不会盘根错节 无量纲网络，非线性，临界点 涌现 相变 利益相关者（stakeholder） 利益相关者分析：按照兴趣与能力还有同意度等几个维度分析参与者，对不同参与者使用不同策略 knitr::include_graphics(&#39;http://yufree.cn/blogcn/figure/sh.png&#39;) 网络分析：包括节点、边、属性及方向，探索节点人物、网络密度、分离程度、相似性及交互性 参与影响通路分析：项目设计管理评价方法，找到关键利益相关者，展示，找出属性关系并给出现在与未来的映射，找出阻断通路的地方 23.2 系统抽象与映射－因果环路图 系统动态方法用来开发定性的系统描述 因果环路图： 因果关系 A -&gt; B A导致了B 极性 ＋／－ 两者变化方向一致为正，反之为负 反馈环路 A 变化引起其它变化，最终又形成对A的增强或制衡 延迟 A对B的影响有延迟|| 制衡状态通常有延迟 环形符号 R表示增强 B表示制衡 knitr::include_graphics(&#39;http://yufree.cn/blogcn/figure/cld.png&#39;) group-based causal mapping workshop Elicit variables for a causal map from stakeholders Use these variables to build a causal map with stakeholders Size of stakeholder group: - At least 3–5 people - A group size of 5–12 is ideal - Any group bigger than 20 people is best split up into separate workshops The session is planned by the core modeling team that is made up of 3–5 staff members and stakeholders The facilitator team may overlap with your core modeling team—for the causal mapping session we will need: - Head facilitator - Wall builder - Recorder Steps: Problem scoping - Identify problem and assess if problem is suitable for causal mapping - Develop one-pager that describes project, purpose, audience, and resources needed - Time necessary for this stage ranges from 1–3 hours to several meetings Core modeling team planning and capacity building Design group model building workshop including the process and agenda Prepare recruitment and training of additional facilitation team members if needed Time necessary for this stage several 1- to 2-hour meetings Actual group modeling workshop Session length varies from one or two 90 minute sessions to five-day workshops Evaluation and reporting Scripts: “playbooks” that outline the process of a particular group modeling activity step-by-step Peter Hovmand’s “Scriptapedia” 23.3 系统抽象与映射－汇流图 展示变化的累计状态，所有动态过程都源于累积，状态都有记忆，可以中断过程，可以产生延迟 knitr::include_graphics(&#39;http://yufree.cn/blogcn/figure/sf.png&#39;) 因果环路图表明事物是联系的，汇流图说明如何联系 knitr::include_graphics(&#39;http://yufree.cn/blogcn/figure/cldsf.png&#39;) 23.4 系统思维与决策 Ecostructure 包括所有利益相关者 找到关键的人，政策有利益得失，让大赢家赢得比大输家多 解释的时候用他们的话，让他们自己得到结论 从上到下的决策 明智的决策者拯救世界 解决大问题 用复杂科学解释决策 公共健康铁三角：技术专家 政治家 公民权利领导者 技术专家的角色类似权威的父母：我喜欢你，让我们阐释问题 从下到上的决策 设立规范自动转换的系统 使用agent-based models 根据规模，规模越大，越需要自上而下的系统设计 "],
["section-24.html", "笔记 24 博弈论 24.1 术语 24.2 支配策略（dominate strategy） 24.3 最佳回应（Best respinse） 24.4 纳什均衡（Nash Equilibrium） 24.5 帕累托最优（Pareto Optimality） 24.6 混合策略（Mixed stratergies） 24.7 寻找纳什均衡 24.8 被支配策略（dominated strategy） 24.9 最大最小策略（Maxmin strategies） 24.10 扩展形式博弈 24.11 完美子博弈 24.12 信息不对称扩展形式博弈 24.13 混合与行为策略 24.14 重复博弈 24.15 随机博弈（stochastic game） 24.16 虚拟行动（fictitious play） 24.17 无悔学习（No-regret learning） 24.18 无限重复博弈的平衡 24.19 贝叶斯博弈 24.20 联盟博弈 24.21 夏普利值（Shapley Value） 24.22 核心 24.23 选举 24.24 机制设计 24.25 VCG机制 24.26 拍卖", " 笔记 24 博弈论 24.1 术语 博弈论说白了就是讲两方势力在一件事上为了自己的最大利益所采取的行动或决策的理论 参与者（players） \\(N= {1,...,n}\\) 参与者 \\(i\\) 有一组行动（Actions），行动的集合 \\(a=(a_1,...,a_n) \\in A=A_1 \\times A_2 \\times ... \\times A_n\\) 参与者 \\(i\\) 的每个行为的收益（Payoffs）都可以用 \\(u_i:A \\rightarrow \\Re\\) 这个函数表示 \\(u_i(a)\\) 表示某个行为产生的收益，\\(u = (u_i,...,u_n)\\)是效用函数的集合 n个参与者的标准博弈（normal form） \\(\\langle N,A,u \\rangle\\) 两人博弈可以用矩阵（matrix）来描述，行代表选手1，列代表选手2，行对应选手1的行动 \\(a_1 \\in A_1\\)，列对应选手2的行动 \\(a_2 \\in A_2\\)，每个单元列出每个参与者的收益，先行选手，后列选手 纯竞争博弈（Games of Pure competition）：两个参与者收益对立且对于所有行动集合 \\(a \\in A, u_1(a)+u_2(a) = c\\)，\\(c\\)是常数，零和博弈是一个常数为0的纯竞争博弈，此时我们只用考虑一个参与者的收益函数就可以了 24.2 支配策略（dominate strategy） 行动单一称为纯策略（pure strategies）有一定概率分布的行动策略称为混合策略（mixed strategies） 对于一个参与者，不论其它参与者采取任何策略，某策略都会得到最大的收益 \\(a_i \\in a_i\\) 为强支配策略当且仅当参与者\\(i\\) 的收益 \\(u_i(a_i,a_{-i}) &gt; u_i(a&#39;_i,a_{-i})\\)，如果 \\(a&#39;_i = a_i\\)，那么为弱支配策略 24.3 最佳回应（Best respinse） 对于一个参与者，当已知其他参与者的行为后，收益最大的策略 参与者\\(i\\)，对于其它参与者的策略\\(a_{-i} \\in a_{-i}\\) 的策略如果\\(u_i(a_i,a_{-i}) \\geqslant u_i(a&#39;_i,a_{-i})\\) 24.4 纳什均衡（Nash Equilibrium） \\(a = \\langle a_1,...,a_n\\rangle\\) 是一个纯策略纳什均衡当且仅当对于任何一个行为i，有\\(a_i \\in BR(a_{-i})\\) 如果任何参与者改变行为的收益都不会增加，那么此时进入纳什均衡 纳什均衡是一系列行为的列表，这些行为都是稳定的 支配策略是纳什均衡但反过来不一定对 任何有限博弈都存在一个纳什均衡（纳什1950年提出） 24.5 帕累托最优（Pareto Optimality） 某个结果是帕累托最优当且仅当没有其他结果可以全局帕累托支配这个结果 帕累托最优表示某个博弈结果不差于其他博弈结果 纳什均衡不一定是帕累托最优（囚徒困境） 24.6 混合策略（Mixed stratergies） 策略\\(S_i\\)指对于每个参与者行动的概率分布集合 概率 \\(Pr(a|s) = \\prod_{j \\in N}s_j(a_j)\\) 期望收益函数 \\(u_i(s) = \\sum_{a \\in A} u_i(a)Pr(a|s)\\) 随机策略会使对手混乱进入动态，很多博弈只存在混合策略纳什均衡而没有纯策略纳什均衡（石头剪子布） 混合策略的目的在于不论你使用哪一种行动，对方的收益都不变 选手 甲 乙 丙 a,b c,d 丁 e,f g,h 对于选手1而言，采取丙行动的收益是\\(aq+c(1-q)\\)，采取丁行动的收益是\\(eq+g(1-q)\\)，q代表选手2采取甲行动概率 如果要达到双方均衡，那么不论采取什么行动收益应该一致，不会因为对方概率的变化而偏离，那么我们就可以求解均衡时选手2的行动概率： \\[aq+c(1-q) = eq+g(1-q)\\] \\[q = \\frac{g-c}{a+g-c-e}\\] 这个结果表明选手2采取行动主要要参考选手1的行动收益差 同理，对选手2而言，采取甲行动收益是\\(bp+f(1-p)\\)，采取乙行动收益是\\(dp+h(1-p)\\)，p为选手1采取丙行动的概率，求解的到： \\[p=\\frac{h-f}{b+h-d-f}\\] - 要达到混合策略纳什均衡，博弈双方的行动概率主要参考对方的行动收益差；同时因为概率已知，我们也可以给出纳什均衡时双方的期望收益 - 应用：守门员博弈，当攻守双方达到纳什均衡时，其概率分布十分接近现实的统计数据，通过策略调整，博弈双方收益会逐渐收敛到纳什均衡，然后就不再变化 24.7 寻找纳什均衡 两人博弈可以用线性互补算法（Linear Complementarity）求解 严格说因为一定存在纳什均衡，寻找它不是NPC问题，但是是PPAD问题，后来人证明纳什均衡是PPAD问题 PPAD问题包括P问题的同时属于NP问题，指存在多项式的解，但不好找 P问题指多项式时间可解决的问题 NP问题指多项式时间可验证一个解的问题 NPC问题指NP问题的归约问题，同时也是NP问题，复杂度不断提高，NPC问题的存在让\\(P = NP\\) 问题很难有答案 NP-hard问题指NP问题的归约问题，但不一定是NP问题 24.8 被支配策略（dominated strategy） 指不论其他参与者采取任何策略，该策略劣于其他策略 被支配策略永远不会是最佳回应 排除法：把被支配策略删除，从剩下的行动方案中选择，交互地去除掉每个选手的被支配策略 24.9 最大最小策略（Maxmin strategies） 指其他参与者对某参与者最小收益策略下的最大收益策略\\(arg max_{s_i}min_{s_{-i}}u_i(s_1,s_2)\\) 最小最大策略指让对方收益最大而自己收益最小的策略\\(arg min_{s_i}max_{s_{-i}}u_{-i}i(s_1,s_2)\\) 在有限两人零和博弈的纳什均衡中，参与者的最大最小值与最小最大值一致 最大最小可用来线性求解纳什均衡 24.10 扩展形式博弈 正常形式博弈不涉及行动顺序与时间 扩展形式博弈考虑时序影响，是一个层级结构，双方根据对方已经使用的策略来使用自己的策略，包括信息对称与不对称两种 有限信息对称博弈用（N, A, H, Z, χ, ρ, σ, u）来表示 N代表n个参与者 A代表一组行动 H代表一组非终点的选择节点 行动函数 $:H 2^A $ 表示每个选择节点的可能行动 参与者函数 \\(\\rho:H \\rightarrow N\\) 表示在节点h上采取行动的选手 \\(i\\in N\\) Z代表终止节点 后继者函数 \\(\\sigma:H\\times A\\rightarrow H \\cup Z\\)映射一个选择节点和一个行动对于所有的节点与行动，如果后继者函数相同，那么节点与行动相同 效用函数\\(u=(u_1,...,u_n);u_i:Z\\rightarrow R\\) 表示在终止节点上参与者的效用 信息对称扩展形式博弈里参与者的纯策略是行动函数的乘积\\(\\prod_{h\\in H,\\rho(h)=i}\\chi(h)\\) 扩展形式博弈可以转为正常形式博弈，但是有大量冗余，正常形式博弈不一定可转化为扩展形式博弈 信息对称扩展形式博弈都有纯策略纳什均衡 求解扩展形式博弈要从完美子博弈开始，从最小的分支倒推，记录策略，实际上也是最小最大值的求解 24.11 完美子博弈 在节点h的子博弈G是节点集合H对博弈G的限制 完美子博弈均衡也是纳什均衡，但不考虑无信用恐吓 倒推法：从最低层寻找纳什均衡，逐层反推排除掉其他选择得到策略 对于零和博弈，倒推法实际就是最小最大算法 24.12 信息不对称扩展形式博弈 参与者选择节点被分配到不同信息集合里，个体无法区分选择节点 信息不对称博弈用（N, A, H, Z, χ, ρ, σ, u, I）来表示 对于\\(I = (I_1,...,I_n)\\)，\\(I_i = (I_{i,1},...,I_{i,k_i})\\)是依赖于\\({h\\in H: \\pho (h) = i}\\)的平衡，具有当存在j在节点\\(h\\in I_{i,j}\\)与\\(h&#39;\\in I_{i,j}\\)时，有\\(\\chi(h) = \\chi(h&#39;)\\)与\\(\\rho(h) = \\rho(h&#39;)\\)的属性 24.13 混合与行为策略 混合策略随机化纯策略 行为策略是遇到每个信息集后的抛硬币 24.14 重复博弈 参与者\\(i\\)给定一个无限序列\\(r_1,r_2,...\\)，其平均回报是\\(\\lim_{k\\rightarrow\\infty}\\sum_{j=1}^k\\frac{r_j}{k}\\) 考虑折扣因子\\(\\beta\\)，未来折扣回报是\\(\\sum_{j=1}^{\\infty}\\beta^jr_j\\)，一般人会更关注当下，对未来关注不会超过当下，但以\\(1-\\beta\\)的概率终止博弈 重复博弈中，当前收益跟未来收益权重不一致，未来收益一般小于当前收益权重： \\[U = U_1 + \\sigma U_2+ ...\\] \\(\\sigma\\)介于0，1之间 有限重复博弈可以用倒推法得到解，基本收敛于子博弈均衡 无限重复博弈要分别计算不同策略下收益，当无限重复博弈概率不断增加，有可能打破子博弈均衡，此时会发生偏移 24.15 随机博弈（stochastic game） 随机博弈是重复博弈的泛化，每一次都取决于上一次博弈结果 用(Q, N, A, P, R)来表示 Q代表有限状态集 N代表有限参与者集合 \\(A = A_1 \\times ... \\times A_n\\) 其中\\(A_i\\)是参与者i的有限行动集 \\(P:Q \\times A \\times Q \\rightarrow[0,1]\\)表示转移概率函数，从状态Q采取行动A变化另一个状态Q \\(R = r_1,...,r_n\\)中\\(r_i:Q\\times A\\rightarrow R\\) 表示参与者i的效用函数 24.16 虚拟行动（fictitious play） 对于行动\\(a\\in A\\)，用\\(w(a)\\)表示对手行动次数，可以非零初始化 用这个数字评价对手策略 \\(\\sigma(a) = \\frac{w(a)}{\\sum_{a&#39; \\in A}w(a&#39;)}\\) 在虚拟行动中每一个参与者的策略经验分布收敛，那么一定收敛到纳什均衡 24.17 无悔学习（No-regret learning） 后悔表示参与者在时间t上没有采用策略s\\(R^t(s) = max(\\alpha^t(s)-\\alpha^t,0)\\) 无悔学习表现出对任何纯策略有\\(Pr([\\lim \\inf R^t(s)]\\leq0)\\) 在每一步每个行为正比于其后悔\\(\\sigma_i^{t+1}(s) = \\frac{R^t(s)}{\\sum_{s&#39;\\in S_i}R^t(s&#39;)}\\) 对有限博弈收敛到均衡 24.18 无限重复博弈的平衡 著名的策略包括以牙还牙（tit-for-tat）跟扳机（trigger） 纳什均衡只适用于有限博弈 无限策略里有无限个纯策略均衡 对于n个参与者的博弈\\(G = (N,A,u)\\)其收益向量\\(r = (r_1,r_2,...,r_n)\\)，让\\(v_i = min_{s_{-i} \\in S_{-i}max_{s_i \\in S_i}} u_i(s_{-i},s_i)\\) i的最小最大值是对方使用最小最大策略时其收益 一个收益向量r是增强的如果\\(r_i\\geq v_i\\) 一个收益向量是可行的当存在非负值\\(\\alpha_a\\)对于所有i，有\\(\\sum_{a\\in A}\\alpha_au_i(a)\\)且\\(\\sum_{a\\in A}\\alpha_a = 1\\) 无名氏定理（folk theorem）：如果收益向量对无限博弈的纳什均衡是平均回报，那么对每个参与者都是增强的，如果可行且增强，收益向量就是有平均回报的无限纳什均衡 24.19 贝叶斯博弈 贝叶斯博弈\\((N,G,P,I)\\)里，N代表参与者集合，G代表博弈集合，P代表对某个博弈集合的先验概率，I代表G里面对每个参与者的组成部分 也可以用认知类型来定义\\(N,A,\\Theta,p,u\\)，A表示行为集合，\\(\\Theta\\)表示对参与者i的类型空间，p表示没中类型的先验概率，u表示某类型某行动对参与者i的收益 贝叶斯纳什均衡：最大化每个参与者每种行动类型收益的策略，可以是纯策略，也可以是混合策略 三种类型：对自己对方都不知道（现存），知道自己不知道对方(过渡)，都知道（过后） 过渡态期望收益：\\(EU_i(s|\\theta_i) = \\sum_{\\theta_{-i}\\in\\Theta_{-i}}p(\\theta_{-i}|\\theta_i)\\sum_{a\\in A}(\\prod_{j\\in N}s_j(a_j|\\theta_j))u_i(a,\\theta_i,\\theta_{-i})\\) 现存期望收益：\\(EU_i(s) = \\sum_{\\theta_i\\in \\Theta_i}p(\\theta_i)EU_i(s|\\theta_i)\\) 贝叶斯均衡混合策略\\(s_i\\in arg max_{s&#39;_i}EU_i(s&#39;_i,s_{-i}|\\theta_i)\\) 给定一方行为，考虑先验概率另一方收益最大时的博弈平衡 双方信息不对称，一方知道结果，另一方只能通过概率猜测是否对方是某种类型 计算不同行动的收益期望，求解概率，如果认为概率高于某个值，则选择对应行动，此时达到收益与概率的均衡 24.20 联盟博弈 收益可转移的联盟博弈（N,v）N代表有限的参与者，\\(v:2^N \\rightarrow R\\) 里每个联盟 \\(S\\subseteq N\\) 里的能够分配的收益，假定\\(v(\\varnothing)=0\\) 联盟博弈解决的问题是哪些联盟会生成及收益如何分配 超加性博弈\\(G=(N,v)\\)表示对于所有的\\(S,T\\subset N\\)，如果\\(S\\cap T = \\varnothing\\)，那么有\\(v(S\\cup T\\geq v(S)+v(T))\\)，这种情况下整体绑定为一个联盟收益最高 24.21 夏普利值（Shapley Value） 如何公平分割收益，Lloyd Shapley认为参与者要按照边际贡献的比例获得收益 公理 - 对于每一种收益方法如果两个人可相互交换\\(v(S\\cup \\{i\\}) = v(S\\cup \\{j\\}))\\)，那么其收益相等\\(\\psi_i(N,v)=\\psi_j(N,v)\\) - 如果某个人不产生收益\\(v(S\\cup \\{i\\} = v(S))\\)，那么不分成\\(\\psi_i(N,v)=0\\) - 对于\\(v_1\\)和\\(v_2\\)，博弈\\((N,v_1+v_2)\\)用\\((v_1+v_2)(S)=v_1(S)+v_2(S)\\)定义，有\\(\\psi_i(N,v_1+v_2)=\\psi_i(N,v_1)+\\psi_i(N,v2)\\) 夏普利值按照$i(N,v) = {SN_i} |S|!(|N|-|S|-1[v(S{i})-v(S)]) $ 分配收益，也就是满足上面三个公理的分配方式 24.22 核心 夏普利值分配比较公平，但不一定稳定，不容易形成大联盟 核心指对于\\(S\\subseteq N\\)，有\\(\\sum_{i\\in S} x_i \\geq v(S)\\) ，总和收益至少不低于内部小联盟收益 核心可能是空的且不唯一 对于简单博弈核心是空的当且仅当没有否决参与者，如果有否决参与者，核心包括所有非否决参与者收益0的收益向量 凸博弈：\\(v(S\\cup T)\\geq v(S)+v(T)-v(S\\cap T)\\)，每个凸博弈有一个非空核心且是夏普利值 24.23 选举 选举结果\\(O\\) 参与者的选择 \\(\\succ\\) 线性排序 \\(L\\) 选择顺序，可传递；非强制选择\\(L_{NS}\\) \\(\\succeq\\) 可传递 社会选择函数 \\(C:L_{NS}^n \\rightarrow O\\)，期中L是非强制选择偏好 社会福利函数 \\(W:L_{NS}^n \\rightarrow L_{NS}\\) 多数票制：选择大多数人选最多的 累计投票：每个人多张票，可以重复投给一个人 同意投票：每个人可随意投，投多个人或不投都可以 淘汰制多数票：得票最多获胜，否则淘汰得票少的重新投直到有结果 波达投票：每个结果分配一个有排序的数字，最后选择总和最高的那个 连续消除：设定顺序，然后前两个投票，输的淘汰，之后赢的跟第三个再投票直到出结果 孔多塞连续性：如果有个结果在所有对比中都胜出，那么这个候选人可以当选（不一定总是有这样的人，有时会出现循环） 不同投票方法结果可能不一样 帕累托有效（PE）如果所有参与者都同意某两个结果的顺序，那么社会福利函数也会使用那个顺序 无关选择独立性（IIA）两个结果间顺序指依赖于参与者给出的相对顺序 独裁者（dictator）某可决定社会排序的参与者 Arrow理论 任何超过三人的具有PE与IIA的社会福利函数都是独裁的 证明 弱帕累托有效：没有出现过被支配的结果 单调：一个获胜的结果再拿到更高的排序也是获胜者 独裁：存在某参与者的选择与总体选择顺序一致 弱帕累托有效且单调的社会选择函数是独裁的 单峰选择：每个投票的人都有最想选跟最不想选的候选人，选择上会避免极端 24.24 机制设计 直接形式：参与者同时传递信息到中心 间接形式：参与者传递一系列信息，这些信息前后相关 启示原则（Revelation Principle）：任何社会选择函数都可以用真实直接的机制来实施 Gibbard-Satterthwaite 理论：有限选择空间里三个元素以上的支配策略都是独裁的，非独裁策略需要转移函数 转移函数：集体对个体的税收或补贴，个人私人收益与转移函数之和是个体的整体结果收益，个人私人收益不考虑其他人的选择 真实性：对于每个参与者平衡策略里转移收益机制是真实的党是直接的且个体接受个人收益函数 有效性：有效的机制会选择最大化个体的收益，转移函数的和小于等于0 预算平衡：所有人转移函数的和为0，大于等于0是弱预算平衡 个体理性：没有人会因为参与某个机制得到负收益 可处理：收益与转移函数的计算可在多项式时间内完成 税收最大化：满足所有限制条件下最大化转移函数总和期望的机制 税收最小化：满足所有限制条件下最小化转移函数总和期望的机制 公平性：让最不开心的参与者也开心最大化 设计政策时要考虑支出补贴税收对所有人都无害或达到均衡 24.25 VCG机制 存在货币补偿时自私参与者选择社会福利最大化的通用方法 一个直接机制包括选择规则跟补偿规则，VCG作为支配策略是真实有效的，在额外假设下可以满足弱预算平衡跟个体理性 Groves机制 \\((\\chi,p)\\) \\[\\chi (\\hat v) \\in arg max_x \\sum_i \\hat v_i(x)\\] \\[p_i(\\hat v) = h_i(\\hat v_{-i}) - \\sum_{j\\neq i} \\hat v_j(\\chi(\\hat v))\\] VCG机制 \\((\\chi,p)\\) \\[\\chi (\\hat v) \\in arg max_x \\sum_i \\hat v_i(x)\\] \\[p_i(\\hat v) = max_x\\sum_{j\\neq i} \\hat v_j(x) - \\sum_{j\\neq i} \\hat v_j(\\chi(\\hat v))\\] 在VCG机制下，计算你自己存在时社会受益最大时其他人收益总和，然后计算没有你且社会收益最大时其他人收益总和，你的补偿是它们的差值 不影响最后结果的人不需要补偿，其存在导致他人收益减少的要付出，其存在导致他人收益增加的要补偿 其真实性有效性可以数学证明 VCG需要个体真实汇报个人信息，但个体间的勾结可以消除补偿，同时VCG会导致开支暴涨，增加参与人也会增加财政支出，个人可能伪装多个人，同时返还机制也不允许所有人返还所有收益 价值隐私信息需要损失效率，是动机效率的平衡 24.26 拍卖 自私参与者分配资源的机制 英国人拍卖：从保留值开始拍卖，参与人喊价，价高的得到物品并付出对应价格 日本人拍卖：所有参与者先站着，价格提升，当价格不合适就坐下，最后一个站着的人得到物品 荷兰人拍卖：设定一个高价然后开始逐渐降低，当有人说我接受时拍卖结束，价格就是当时价格 第一价格拍卖：参与者将价格写好封装，然后拍卖人开封，价高的人得到物品，付对应价格 第二价格拍卖：同上，但付第二高的价格 付费拍卖：同上，但所有人都要支出自己写的价格，彩票？ 拍卖三种规则：竞拍规则，信息释放规则，清场规则 在第二价格拍卖里，讲真话是支配策略，符合VCG机制，也可以直观证明 在英国人日本人拍卖里，独立私有价值模型下的支配策略是用真实值 在第一价格拍卖与荷兰人拍卖实质等同，前者可以异步进行，后者交流快，参与者竞拍价要低于价值，无支配策略 两个中等风险的参与者参与第一价格竞拍，分布是均匀分布，贝叶斯纳什均衡是各自价格的一半 更多的参与人参加后，价格会不断提升接近真实价格，如果是均匀分布，系数是\\(\\frac{n-1}{n}\\) 收益均等理论：n个风险中等的参与者对于单一物品有独立私有价值，参与竞拍时每个人都从风险分布F里报价，当均衡时分配总是一样的，价值为0其期望也是0，所有有效拍卖产生的收益是一样的 最优化拍卖，参与人的虚拟价值\\(\\psi_i(v_i) = v_i - \\frac{1-F_i(v_i)}{f_i(v_i)}\\)在保留价格处为0，并非VCG "],
["section-25.html", "笔记 25 复杂系统 25.1 复杂系统的特征 25.2 动力学 25.3 分形 25.4 信息论 25.5 进化 25.6 细胞自动机 25.7 自组织 25.8 网络 25.9 尺度", " 笔记 25 复杂系统 25.1 复杂系统的特征 组成部分或个体相对简单 各部分非线性相互作用 没有中心控制 涌现行为，例如层级结构、信息处理、动态、进化学习 缺少数学工具统一整合理论 25.2 动力学 系统随时间的变化 混沌系统，初始条件与运行规则已知，长期预测不可知，对初始值敏感但存在可预测的全局特性 Logistic Map 25.3 分形 自我相似性，整体与局部相似 分形的维度，D维对象的边被反复切割为M个部分，每一切割水平有\\(M^D\\)个副本，假如副本个数为N，也就是说\\(N=M^D\\)，其维度\\(D = logN/logM\\) 数盒子测维度，计算有多少盒子与盒子的边长，改变盒子的边长，计算盒子的个数 \\(log[NumberOfBoxes] = D log[1/BoxSize]\\) 25.4 信息论 麦克斯韦妖 热动力学的墒测量做功时的热损失，热损失就是无序；统计学的墒测量能出现宏观状态的微观状态的数量，微观状态越少墒越低，越混合越无序。统计意义上热力学第二定律本质是宏观状态下微观状态数目趋向于最大 玻尔兹曼认为宏观状态的墒S是微观状态数W的自然对数的k倍，k是玻尔兹曼常数。更多的微观状态会提高宏观状态出现的可能，墒提高。 香农认为信息含量表示让人吃惊的程度 信息量\\(H = log_2 M\\) M 表示以字节传递信息的可能性 信息整体\\(H = - \\sum_{i=1}^{M}p_ilog_{2}p_i\\) p 表示出现的概率 Hffman编码可节省信息传递字节，进行压缩 25.5 进化 遗传算法，首先生成随机策略，对于随机策略计算适应性，然后对策略进行杂交与突变，重复这个过程直到足够好的策略产生 难预测，会产生过度适应，但会有新东西产生 编程上用if-else生成的树来进行突变 25.6 细胞自动机 Conway的game of life Stanislaw Ulam 和 John von Neumann的细胞自动机，机器中的繁殖 元细胞自动机，一维仅考虑左右邻居，两个状态，共计256种模式，用二进制编码（Wolfram编码） 规则30被用作伪随机数生成器 四种分类：固定的，周期的，混沌的，局部的 作为动态系统考察，与 logistic map 同构 控制参数lambda，规则里黑色的比例，从固定到周期到混沌到周期到固定，存在混沌的边缘 第四种可以用来进行通用计算，但第四类很难定义，规则110可以作为通用计算机 细胞自动机可以用遗传算法来筛选规则演进 细胞自动机也可以用来理解信息交换，通过定义模式来进行 25.7 自组织 系统内部分组分的局部去中心交流产生的有组织模式 群聚（flocking），存在进化意义上的解释，个体规则为避免碰撞，与周围人同速，保持在一起 同步包括萤火虫同步、蟋蟀鸣叫、蝉鸣、神经放电、心脏跳、月经同步，存在进化上解释，个体规则为只对周围的行为进行模仿 蚁群觅食，随机寻找食物，当找到食物源返巢时留下信息素，其他蚂蚁得到信息素就会跟随，没有加强信息素会挥发，这会适应环境 工蚁只对环境变化及同类多数行为采取行动，如果蚁巢被破坏，觅食工蚁数量就会减少，个体交流用信息素或触角 较大的蚁巢自组织化更高，有可能是经验产生更好的统计信息与信息交换速率 生物行为也是一种分布去中心的编程方法，考虑了随机性与适应 囚徒悖论：没有中心控制的条件下如何促进合作？以牙还牙，不首先作恶、可原谅、有报复且规则清晰 复杂经济学：自私个体存在有限理性且策略有限，不可分析，没有平衡，需要个体适应 酒馆问题：100个人阈值60以下舒适，每个人根据之前的历史判断，该模型认为自组织合作可以实现整体有效而不用完全理性知识及演绎法 25.8 网络 基本结构是节点和连接，有方向的话要考虑连入和连出度 连接度分布与联通路径是考察网络的基本视角 网络中的聚类用节点的邻居之间的联系占理论所有连接的比例来定义 小世界理论（六度分割）：网络中很少有长距离连接，但节点间短连接比例很高 现实世界中网络结构既不是长距离高聚类的齐整网络，也不是低距离低聚类的随机网络，而是有较低距离但高聚类的网络 现实网络的形成过程可以用齐整网络间部分节点的随机连接度来模拟 无标度网络，网络中节点的连接度分布近似于幂律分布 形成原因是偏好依附 大节点出问题出现的系统崩溃或级联效应是值得关注的，对网络的随机攻击则不会产生太大的问题 25.9 尺度 很多现象在不同尺度上等比例放大／缩小 多数尺度效应符合幂律分布 \\(attribute = c(size)^\\alpha\\) 幂律分布可写成对数线性方程 地震的震级与发生频率 动物的代谢速率与体积：考虑代谢散热，代谢率应该跟体表面积成正比，则代谢率是体积的2/3次方；然而实际数据是3/4次方，更高，60年无解，新理论认为代谢率应该跟能量分布有关，也就是分形维度，人体结果近似4维 城市人口密度与犯罪率／收入 "]
]
